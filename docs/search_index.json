[
["index.html", "R for Data Science Solution Set Preface", " R for Data Science Solution Set Preface This is a solution guide to the exercises in R for Data Science by Hadley Wickham and Garret Grolemund. This guide is a work in progress, and all are welcome to contribute. The complete source for this book is available on github; full instructions on how to contribute are available in the README. "],
["chapter-3-data-visualisation.html", "Chapter 3 - Data Visualisation 3.2 - First Steps 3.3 - Aesthetic Mappings 3.5 - Facets 3.6 - Geometric Objects 3.7 - Statistical Transformations 3.8 - Position Adjustments 3.9 - Coordinate Systems", " Chapter 3 - Data Visualisation Load the libraries needed for these exercises. library(tidyverse) library(maps) 3.2 - First Steps Problem 1 Run ggplot(data = mpg). What do you see? The initial ggplot() call creates a a blank plot without any aesthetics. ggplot(data = mpg) Problem 2 How many rows are in mpg? How many columns? Use the nrow() and ncol() functions from base to determine that there are 234 rows and 11 columns in the mpg data set. nrow(mpg) ## [1] 234 ncol(mpg) ## [1] 11 Problem 3 What does the drv variable describe? Read the help for ?mpg to find out. The variable drv describes the drive of the vehicle: f = front-wheel drive, r = rear wheel drive, 4 = 4wd. Problem 4 Make a scatter plot of hwy vs cyl. Set hwy and cyl as the x and y variables within aes(), and use geom_point() to create a scatterplot. ggplot(data = mpg, mapping = aes(x = cyl, y = hwy)) + geom_point() Problem 5 What happens if you make a scatter plot of class vs drv? Why is the plot not useful? Since class and drv are categorical variables, there isn’t much of a meaningful relationship in the scatter plot. ggplot(data = mpg, mapping = aes(x = class, y = drv)) + geom_point() 3.3 - Aesthetic Mappings Problem 1 What’s gone wrong with this code? Why are the points not blue? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;)) To set an aesthetic manually, it must go outside of aes(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) Problem 2 Which variables in mpg are categorical? Which variables are continuous? (Hint: type ?mpg to read the documentation for the data set). How can you see this information when you run mpg? Use str() to see the structure of a dataset. str(mpg) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 234 obs. of 11 variables: ## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... Problem 3 Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables? Continuous variables will use a gradient to scale color and size, but will throw an error when applied to shape. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ)) + geom_point() ggplot(data = mpg, mapping = aes(x = cty, y = hwy, size = displ)) + geom_point() p &lt;- ggplot(data = mpg, mapping = aes(x = cty, y = hwy, shape = displ)) + geom_point() Problem 4 What happens if you map the same variable to multiple aesthetics? Mapping displ to color and size results in the following graph. Not necessarily helpful, but two ways of displaying the some variation. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ, size = displ)) + geom_point() Problem 5 What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point) The stroke aesthetic will modify the width of the border of a shape. Taking the example from the ggplot2 documentation: ggplot(data = mtcars, mapping = aes(x = wt, y = mpg)) + geom_point(shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 5, stroke = 5) Problem 6 What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ &lt; 5)? In this case the condition passed to color returns a boolean that will map to color. ggplot(data = mtcars, mapping = aes(wt, mpg, color = disp &lt; 100)) + geom_point() 3.5 - Facets Problem 1 What happens if you facet on a continuous variable? The facet_wrap feature will still produce plots for each unique value, but the result is not necessarily helpful. ggplot(data = mtcars, mapping = aes(disp, mpg)) + geom_point() + facet_wrap(~ wt) Problem 2 What do the empty cells in plot with facet_grid(drv ~ cyl) mean? How do they relate to this plot? Empty cells occur when there are no observations within a specific combination of facet variables. For instance, in the given plot there are no vehicles with 4wd and 5 cylinders, which matches the empty cell with facet_grid(drv ~ cyl). ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = cyl)) Problem 3 What plots does the following code make? What does . do? In the first example, using . creates a facet_grid() plot without a column variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ .) This can be easier than trying to hack together a similar plot using facet_wrap(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ drv, nrow = n_distinct(mpg$drv)) The . can also be used to make a facet_grid() while omitting a row variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl) Problem 4 Take the first faceted plot in this section. What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset? Faceting can make it easier to see the variation by class than using the color aesthetic, but can be unwieldy when the number of distinct values in class is large. For a larger dataset, faceting may be necessary, as the increased number of points may make it difficult to see a variation by color. Compare the following plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) Problem 5 Read ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments? The nrow and ncol arguments allow you to control the number of rows or columns in the panel. There are a number of other arguments in facet_wrap(): * scales: can fix scales or allow them to vary * shrink: shrink scales to fit output of statistics, not raw data * labeller: takes one data frame of labels and returns a list or data frame of character vectors * as.table: display facets as a table or a plot * switch: flip the labels * drop: drop unused factor lebels * dir: control direction of the panel * strip.position: control where to place the labels The facet_grid() function has nrow and ncol predefined by the faceting variables. Problem 6 When using facet_grid() you should usually put the variable with more unique levels in the columns. Why? This will expand the panel vertically, making it easier to scroll through the grid. Compare the following two plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(trans ~ drv) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ trans) 3.6 - Geometric Objects Problem 1 What geom would you use to draw a line chart? A boxplot? A histogram? An area chart? Use geom_line() to draw a line chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line() Use geom_boxplot() to create a boxplot. ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() Use geom_histogram() to create a histogram. ggplot(data = mpg, mapping = aes(x = hwy)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. And use geom_area() to create an area chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_area() Problem 2 Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions. Be sure to think through the initial ggplot call and consider what will be passed to geom_point() and geom_smooth(). ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 3 What does show.legend = FALSE do? What happens if you remove it? Why do you think I used it earlier in the chapter? The show.legend argument can be used to map a layer to a legend. Setting to FALSE will remove that layer from the plot. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE, show.legend = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; But note that this only works by geom: ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 4 What does the se argument to geom_smooth() do? The se argument controls whether a confidence band is displayed around the smoothed line. Note that the argument is set to TRUE by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; The level argument is used to control the confidence interval, and is set to 0.95 by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(level = 0.9999) ## `geom_smooth()` using method = &#39;loess&#39; Problem 5 Will these two graphs look different? Why/why not? The graphs should look the same, as data and aes are inherited by geom_point() and geom_smooth() in the first example. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; ggplot() + geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; Problem 6 Recreate the R code necessary to generate the following graphs. Be sure to think through how each aes is set and inherited. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, grp = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() 3.7 - Statistical Transformations Problem 1 What is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function? The default geom associated with stat_summary() is pointrange. Recreate the last plot using: ggplot(data = diamonds) + geom_pointrange( mapping = aes(x = cut, y = depth), stat = &#39;summary&#39;, fun.ymin = min, fun.ymax = max, fun.y = median ) Problem 2 What does geom_col() do? How is it different to geom_bar()? From the ggplot2 documentation: geom_bar() makes the height of the bar proportional to the number of cases in each group, while geom_col() will map directly to the data. Make a simple bar chart using geom_bar which will transform the data under the hood: ggplot(mpg, aes(class)) + geom_bar() Or do the transformation manually and map directly using geom_col: mpg %&gt;% group_by(class) %&gt;% count() %&gt;% ggplot(aes(class, n)) + geom_col() Problem 3 Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common? Some examples from the ggplot2 documentation include: geom_bar –&gt; stat_count geom_bin2d –&gt; stat_bin_2d geom_boxplot –&gt; stat_boxplot geom_contour –&gt; stat_contour geom_count –&gt; stat_sum geom_density –&gt; stat_density geom_density_2d –&gt; stat_density_2d geom_histogram –&gt; stat_bin geom_hex –&gt; stat_bin_hex Problem 4 What variables does stat_smooth() compute? What parameters control its behavior? stat_smooth computes the following: y - the predicted value ymin - lower pointwise confidence interval around the mean ymax - upper pointwise confidence interval around the mean se - standard error The behaviour of stat_smooth can be controled using: method to adjust the smoothing method used formula to adjust the smoothing formula used span to adjust the amount of smoothing level to set the confidence level used Problem 5 In our proportion bar chart, we need to set group = 1. Why? In other words what is the problem with these two graphs? The first chart displays a proportion = 1 for all groups. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop..)) While the second plot does something similar, multiplied by the number of categories in color. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..)) geom_bar() will compute prop - the groupwise proportion. So pass in an argument to group for prop to be calculated properly. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1)) ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., fill = color, group = color)) 3.8 - Position Adjustments Problem 1 What is the problem with this plot? How could you improve it? ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() Use geom_jitter() to correct the overplotting in the original. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter() Problem 2 What parameters to geom_jitter() control the amount of jittering? The width and height arguments control the amount of jittering and defaults to 40% of the resolution of the data. So values less than 0.4 will make a graph more compact than the default geom_jitter() and values greater than 0.4 will make the graph more spread out. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.20, height = 0.20) While values greater than 0.4 will make a smoother graph. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.60, height = 0.60) Problem 3 Compare and contrast geom_jitter() with geom_count(). geom_jitter() and geom_count() are both useful when dealing with overplotting. While geom_jitter will add a small amount of noise to each point to spread them out, geom_count will count the number of observations at each (x,y) point, and then map the count. geom_jitter() is equivalent to geom_point(position = 'jitter') geom_count() is equivalent to geom_point(stat = 'sum') ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_count() Problem 4 What’s the default position adjustment for geom_boxplot()? Create a visualisation of the mpg dataset that demonstrates it. The default position adjustment for geom_boxplot() is dodge. ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot() ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot(position = &#39;identity&#39;) 3.9 - Coordinate Systems Problem 1 Turn a stacked bar chart into a pie chart using coord_polar(). From the documentation for coord_polar() - first make a stacked bar chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar() And then turn it into a pie chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar(width = 1) + coord_polar(theta = &#39;y&#39;) Problem 2 What does labs() do? Read the documentation. labs() controls the labels of a plot, axis, or legend. ggplot(mpg, aes(cty, hwy)) + geom_point() + labs(title = &#39;Title&#39;, subtitle = &#39;Subtitle&#39;, caption = &#39;Caption&#39;) Problem 3 What’s the difference between coord_quickmap() and coord_map()? coord_quickmap() preserves straight lines when projecting onto a two dimensional surface and requires less computation. ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_map() ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_quickmap() Problem 4 What does the plot below tell you about the relationship between city and highway mpg? Why is coord_fixed() important? What does geom_abline() do? coord_fixed() (with no arguments) ensures that a unit on the x-axis is the same length as a unit on the y-axis. geom_abline() (with no arguments) adds a reference line with an intercept of 0 and a slope of 1. One can quickly see that every observation in the mpg dataset has better highway than city fuel efficiency. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + geom_abline() + coord_fixed() "],
["chapter-5-data-transformation.html", "Chapter 5 - Data Transformation 5.2 - Filter Rows with filter() 5.3 - Arrange Rows with arrange() 5.4 - Select Columns with select() 5.5 - Add New Variables with mutate() 5.6 - Grouped summaries with summarise() 5.7 - Grouped Mutates (and Filters)", " Chapter 5 - Data Transformation Load the libraries needed for these exercises. library(tidyverse) library(nycflights13) 5.2 - Filter Rows with filter() Problem 1 Find all flights that: Had an arrival delay of two or more hours flights %&gt;% filter(arr_delay &gt;= 120) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 10200 Flew to Houston (IAH or HOU) flights %&gt;% filter(dest %in% c(&#39;IAH&#39;, &#39;HOU&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9313 Were operated by United, American, or Delta flights %&gt;% filter(carrier %in% c(&#39;UA&#39;, &#39;AA&#39;, &#39;DL&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 139504 Departed in summer (July, August, and September) flights %&gt;% filter(month %in% c(7, 8, 9)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 86326 Arrived more than two hours late, but didn’t leave late flights %&gt;% filter(arr_delay &gt;= 120, dep_delay &lt;= 0) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 29 Were delayed by at least an hour, but made up over 30 minutes in flight flights %&gt;% filter(dep_delay &gt;= 60, arr_delay &lt;= dep_delay - 30) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 2074 Departed between midnight and 6am (inclusive) flights %&gt;% filter(dep_time &gt;= 0, dep_time &lt;= 600) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 2 Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges? between() is a shortcut for x &gt;= left &amp; x &lt;= right. We can simplify the last answer to Problem 1 as: flights %&gt;% filter(between(dep_time, 0, 600)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 3 How many flights have a missing dep_time? What other variables are missing? What might these rows represent? We use is.na() to filter the flights with a missing departure time. flights %&gt;% filter(is.na(dep_time)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 8255 Using summary() to see the breakout of the other variables, there appear to be flights that were cancelled. flights %&gt;% filter(is.na(dep_time)) %&gt;% summary() ## year month day dep_time ## Min. :2013 Min. : 1.000 Min. : 1.0 Min. : NA ## 1st Qu.:2013 1st Qu.: 3.000 1st Qu.: 8.0 1st Qu.: NA ## Median :2013 Median : 6.000 Median :12.0 Median : NA ## Mean :2013 Mean : 5.927 Mean :14.6 Mean :NaN ## 3rd Qu.:2013 3rd Qu.: 8.000 3rd Qu.:23.0 3rd Qu.: NA ## Max. :2013 Max. :12.000 Max. :31.0 Max. : NA ## NA&#39;s :8255 ## sched_dep_time dep_delay arr_time sched_arr_time ## Min. : 106 Min. : NA Min. : NA Min. : 1 ## 1st Qu.:1159 1st Qu.: NA 1st Qu.: NA 1st Qu.:1330 ## Median :1559 Median : NA Median : NA Median :1749 ## Mean :1492 Mean :NaN Mean :NaN Mean :1669 ## 3rd Qu.:1855 3rd Qu.: NA 3rd Qu.: NA 3rd Qu.:2049 ## Max. :2359 Max. : NA Max. : NA Max. :2359 ## NA&#39;s :8255 NA&#39;s :8255 ## arr_delay carrier flight tailnum ## Min. : NA Length:8255 Min. : 1 Length:8255 ## 1st Qu.: NA Class :character 1st Qu.:1577 Class :character ## Median : NA Mode :character Median :3535 Mode :character ## Mean :NaN Mean :3063 ## 3rd Qu.: NA 3rd Qu.:4373 ## Max. : NA Max. :6177 ## NA&#39;s :8255 ## origin dest air_time distance ## Length:8255 Length:8255 Min. : NA Min. : 17.0 ## Class :character Class :character 1st Qu.: NA 1st Qu.: 292.0 ## Mode :character Mode :character Median : NA Median : 583.0 ## Mean :NaN Mean : 695.4 ## 3rd Qu.: NA 3rd Qu.: 872.0 ## Max. : NA Max. :4963.0 ## NA&#39;s :8255 ## hour minute time_hour ## Min. : 1.00 Min. : 0.00 Min. :2013-01-01 06:00:00 ## 1st Qu.:11.00 1st Qu.: 5.00 1st Qu.:2013-03-07 07:00:00 ## Median :15.00 Median :27.00 Median :2013-06-12 18:00:00 ## Mean :14.67 Mean :25.61 Mean :2013-06-13 06:42:11 ## 3rd Qu.:18.00 3rd Qu.:42.00 3rd Qu.:2013-08-22 15:30:00 ## Max. :23.00 Max. :59.00 Max. :2013-12-31 20:00:00 ## Problem 4 Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE &amp; NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!) Working through these examples: * Anything to the zero power is 1 * Anything OR TRUE is TRUE * Anything AND FALSE is FALSE These results apply no matter what the LHS side, and so will apply to NA as well. NA ^ 0 ## [1] 1 NA | TRUE ## [1] TRUE NA &amp; FALSE ## [1] FALSE However operations on NA will return NA. NA * 0 is counter intuitive since you would think that anything multiplied by 0 would be 0. NA * 0 ## [1] NA NA ^ 2 ## [1] NA NA + 1 ## [1] NA 5.3 - Arrange Rows with arrange() Problem 1 How could you use arrange() to sort all missing values to the start? (Hint: use is.na()). We can sort missing values using the format: flights %&gt;% arrange(desc(is.na(dep_time))) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 NA 1630 NA NA ## 2 2013 1 1 NA 1935 NA NA ## 3 2013 1 1 NA 1500 NA NA ## 4 2013 1 1 NA 600 NA NA ## 5 2013 1 2 NA 1540 NA NA ## 6 2013 1 2 NA 1620 NA NA ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 2 Sort flights to find the most delayed flights. Find the flights that left earliest. The most delayed flights (by arr_delay) are: flights %&gt;% arrange(desc(arr_delay)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 ## 2 2013 6 15 1432 1935 1137 1607 ## 3 2013 1 10 1121 1635 1126 1239 ## 4 2013 9 20 1139 1845 1014 1457 ## 5 2013 7 22 845 1600 1005 1044 ## 6 2013 4 10 1100 1900 960 1342 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The flights that left earliest (by dep_delay) are: flights %&gt;% arrange(dep_delay) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 12 7 2040 2123 -43.0 40 ## 2 2013 2 3 2022 2055 -33.0 2240 ## 3 2013 11 10 1408 1440 -32.0 1549 ## 4 2013 1 11 1900 1930 -30.0 2233 ## 5 2013 1 29 1703 1730 -27.0 1947 ## 6 2013 8 9 729 755 -26.0 1002 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 3 Sort flights to find the fastest flights. We first calculate average speed in MPH as distance / hours in the air, and sort on the calculated variable. flights %&gt;% mutate(speed = distance / (air_time / 60)) %&gt;% arrange(desc(speed)) %&gt;% select(speed) %&gt;% head() ## # A tibble: 6 x 1 ## speed ## &lt;dbl&gt; ## 1 703 ## 2 650 ## 3 648 ## 4 641 ## 5 591 ## 6 564 Problem 4 Which flights traveled the longest? Which traveled the shortest? The longest flights are: flights %&gt;% arrange(desc(distance)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 857 900 - 3.00 1516 ## 2 2013 1 2 909 900 9.00 1525 ## 3 2013 1 3 914 900 14.0 1504 ## 4 2013 1 4 900 900 0 1516 ## 5 2013 1 5 858 900 - 2.00 1519 ## 6 2013 1 6 1019 900 79.0 1558 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The shortest flights are: flights %&gt;% arrange(distance) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 7 27 NA 106 NA NA ## 2 2013 1 3 2127 2129 - 2.00 2222 ## 3 2013 1 4 1240 1200 40.0 1333 ## 4 2013 1 4 1829 1615 134 1937 ## 5 2013 1 4 2128 2129 - 1.00 2218 ## 6 2013 1 5 1155 1200 - 5.00 1241 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 5.4 - Select Columns with select() Problem 1 Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights. We can put all the variables directly into our select() statement: flights %&gt;% select(dep_time, dep_delay, arr_time, arr_delay) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2.00 830 11.0 ## 2 533 4.00 850 20.0 ## 3 542 2.00 923 33.0 ## 4 544 -1.00 1004 -18.0 ## 5 554 -6.00 812 -25.0 ## 6 554 -4.00 740 12.0 Or this would be a good place to try the starts_with() function: flights %&gt;% select(starts_with(&quot;dep&quot;), starts_with(&quot;arr&quot;)) ## # A tibble: 336,776 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2.00 830 11.0 ## 2 533 4.00 850 20.0 ## 3 542 2.00 923 33.0 ## 4 544 -1.00 1004 -18.0 ## 5 554 -6.00 812 -25.0 ## 6 554 -4.00 740 12.0 ## 7 555 -5.00 913 19.0 ## 8 557 -3.00 709 -14.0 ## 9 557 -3.00 838 - 8.00 ## 10 558 -2.00 753 8.00 ## # ... with 336,766 more rows Or we can try a regex using matches() flights %&gt;% select(matches(&quot;^dep&quot;), matches(&quot;^arr&quot;)) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2.00 830 11.0 ## 2 533 4.00 850 20.0 ## 3 542 2.00 923 33.0 ## 4 544 -1.00 1004 -18.0 ## 5 554 -6.00 812 -25.0 ## 6 554 -4.00 740 12.0 Problem 2 What happens if you include the name of a variable multiple times in a select() call? Duplicating a variable within select() will still just return that variable one time: flights %&gt;% select(dep_time, dep_time) %&gt;% head() ## # A tibble: 6 x 1 ## dep_time ## &lt;int&gt; ## 1 517 ## 2 533 ## 3 542 ## 4 544 ## 5 554 ## 6 554 Problem 3 What does the one_of() function do? Why might it be helpful in conjunction with this vector? one_of() allows you select variables from within a character vector. We can pass vars to select everything from the vector: vars &lt;- c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;dep_delay&quot;, &quot;arr_delay&quot;) flights %&gt;% select(one_of(vars)) ## # A tibble: 336,776 x 5 ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2.00 11.0 ## 2 2013 1 1 4.00 20.0 ## 3 2013 1 1 2.00 33.0 ## 4 2013 1 1 -1.00 -18.0 ## 5 2013 1 1 -6.00 -25.0 ## 6 2013 1 1 -4.00 12.0 ## 7 2013 1 1 -5.00 19.0 ## 8 2013 1 1 -3.00 -14.0 ## 9 2013 1 1 -3.00 - 8.00 ## 10 2013 1 1 -2.00 8.00 ## # ... with 336,766 more rows Problem 4 Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default? select(flights, contains(&quot;TIME&quot;)) %&gt;% head() ## # A tibble: 6 x 6 ## dep_time sched_dep_time arr_time sched_arr_time air_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 830 819 227 ## 2 533 529 850 830 227 ## 3 542 540 923 850 160 ## 4 544 545 1004 1022 183 ## 5 554 600 812 837 116 ## 6 554 558 740 728 150 ## # ... with 1 more variable: time_hour &lt;dttm&gt; contains() contains an argument ignore.case which defaults to TRUE, we can set this to FALSE if needed: select(flights, contains(&quot;TIME&quot;, ignore.case = FALSE)) %&gt;% head() ## # A tibble: 6 x 0 5.5 - Add New Variables with mutate() Problem 1 Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. Use the modular arithmetic operators to break the time into its hours and minute components: flights %&gt;% select(dep_time, sched_dep_time) %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100))) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time sched_dep_time dep_time_cont sched_dep_time_cont ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 517 515 317 315 ## 2 533 529 333 329 ## 3 542 540 342 340 ## 4 544 545 344 345 ## 5 554 600 354 360 ## 6 554 558 354 358 Problem 2 Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it? The issue is that air_time is in minutes, while arr_time and dep_time are not: flights %&gt;% mutate(air_time_derived = arr_time - dep_time) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;int&gt; ## 1 227 313 ## 2 227 317 ## 3 160 381 ## 4 183 460 ## 5 116 258 ## 6 150 186 Instead use the mutate() statement from Problem 1, however the two differ: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), arr_time_cont = ((arr_time %/% 100) * 60 + (arr_time %% 100)), air_time_derived = arr_time_cont - dep_time_cont) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 227 193 ## 2 227 197 ## 3 160 221 ## 4 183 260 ## 5 116 138 ## 6 150 106 Problem 3 Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related? We would expect dep_delay to be the difference between the dep_time and the sched_dep_time. But be sure to convert from time to continuous first: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100)), dep_delay_derived = dep_time_cont - sched_dep_time_cont) %&gt;% select(dep_delay, dep_delay_derived) %&gt;% head() ## # A tibble: 6 x 2 ## dep_delay dep_delay_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2.00 2.00 ## 2 4.00 4.00 ## 3 2.00 2.00 ## 4 -1.00 -1.00 ## 5 -6.00 -6.00 ## 6 -4.00 -4.00 Problem 4 Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank(). We’ll use min_rank() to rank the flights by arr_delay: flights %&gt;% select(arr_delay) %&gt;% mutate(most_delayed = min_rank(-arr_delay)) %&gt;% filter(most_delayed &lt;= 10) %&gt;% arrange(most_delayed) ## # A tibble: 10 x 2 ## arr_delay most_delayed ## &lt;dbl&gt; &lt;int&gt; ## 1 1272 1 ## 2 1127 2 ## 3 1109 3 ## 4 1007 4 ## 5 989 5 ## 6 931 6 ## 7 915 7 ## 8 895 8 ## 9 878 9 ## 10 875 10 Problem 5 What does 1:3 + 1:10 return? Why? We get an error because 1:3 + 1:10 are not multiples of each other: 1:3 + 1:10 ## Warning in 1:3 + 1:10: longer object length is not a multiple of shorter ## object length ## [1] 2 4 6 5 7 9 8 10 12 11 Think through what is happening under the hood. This operation is recycling the shorter vector: 1 + 1 2 + 2 3 + 3 4 + 1 5 + 2 6 + 3 7 + 1 8 + 2 9 + 3 10 + 1 - error because 1:3 has not been fully cycled through So the following will not return an error: 1:3 + 1:12 ## [1] 2 4 6 5 7 9 8 10 12 11 13 15 Problem 6 What trigonometric functions does R provide? R has the following trig functions within base: cos(x) sin(x) tan(x) acos(x) asin(x) atan(x) atan2(y, x) cospi(x) sinpi(x) tanpi(x) Note that angles are given in radians: cos(pi * 0.25) ## [1] 0.7071068 # cospi(x) is equivalent to cos(pi * x) cospi(0.25) ## [1] 0.7071068 5.6 - Grouped summaries with summarise() Problem 1 Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios: A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(fifteen_early = mean(arr_delay &lt;= -15, na.rm = TRUE), fifteen_late = mean(arr_delay &gt;= 15, na.rm = TRUE)) %&gt;% filter(fifteen_early == 0.50, fifteen_late == 0.50) ## # A tibble: 21 x 3 ## flight fifteen_early fifteen_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 107 0.500 0.500 ## 2 2072 0.500 0.500 ## 3 2366 0.500 0.500 ## 4 2500 0.500 0.500 ## 5 2552 0.500 0.500 ## 6 3495 0.500 0.500 ## 7 3505 0.500 0.500 ## 8 3518 0.500 0.500 ## 9 3544 0.500 0.500 ## 10 3651 0.500 0.500 ## # ... with 11 more rows A flight is always 10 minutes late. flights %&gt;% group_by(flight) %&gt;% summarise(ten_late = mean(arr_delay == 10, na.rm = TRUE)) %&gt;% filter(ten_late == 1.00) ## # A tibble: 5 x 2 ## flight ten_late ## &lt;int&gt; &lt;dbl&gt; ## 1 2254 1.00 ## 2 3656 1.00 ## 3 3785 1.00 ## 4 3880 1.00 ## 5 5854 1.00 A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(thirty_early = mean(arr_delay &lt;= -30, na.rm = TRUE), thirty_late = mean(arr_delay &gt;= 30, na.rm = TRUE)) %&gt;% filter(thirty_early == 0.50, thirty_late == 0.50) ## # A tibble: 3 x 3 ## flight thirty_early thirty_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3651 0.500 0.500 ## 2 3916 0.500 0.500 ## 3 3951 0.500 0.500 99% of the time a flight is on time. 1% of the time it’s 2 hours late. flights %&gt;% group_by(flight) %&gt;% summarise(on_time = mean(arr_delay &lt;= 0, na.rm = TRUE), late = mean(arr_delay &gt;= 120, na.rm = TRUE)) %&gt;% filter(on_time == 0.99, late == 0.01) ## # A tibble: 0 x 3 ## # ... with 3 variables: flight &lt;int&gt;, on_time &lt;dbl&gt;, late &lt;dbl&gt; Problem 2 Come up with another approach that will give you the same output as not_cancelled %&gt;% count(dest) and not_cancelled %&gt;% count(tailnum, wt = distance) (without using count()). First setup the not_cancelled data set. not_cancelled &lt;- flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) The first chunk of code gives us the following output: not_cancelled %&gt;% count(dest) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows We can replicate this without using count() by doing a group_by() on dest: not_cancelled %&gt;% group_by(dest) %&gt;% summarise(n = n()) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows The second chunk of code gives us: not_cancelled %&gt;% count(tailnum, wt = distance) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Again we can avoid using count by doing a group_by() on tailnum. Since wt = distance gives the total number of miles flown, we use sum() instead: not_cancelled %&gt;% group_by(tailnum) %&gt;% summarise(n = sum(distance)) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Problem 3 Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column? arr_delay is the more important of the two columns - filtering on arr_delay alone will give the same subset: flights %&gt;% summarise(suboptimal = sum(is.na(dep_delay) | is.na(arr_delay)), optimal = sum(is.na(arr_delay))) ## # A tibble: 1 x 2 ## suboptimal optimal ## &lt;int&gt; &lt;int&gt; ## 1 9430 9430 Problem 4 Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay? There is a generally positive trend between average delay and the proportion of cancelled flights, with a couple of outliers. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(avg_delay, cancelled)) + geom_point() A lot of flights were cancelled on February 8th and 9th, although the average delays those days were not that large - a snowstorm hit the region that weekend, with a lot of flights preemptively cancelled. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(cancelled)) %&gt;% head() ## # A tibble: 6 x 3 ## date cancelled avg_delay ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013-02-09 0.575 6.64 ## 2 2013-02-08 0.511 24.2 ## 3 2013-05-23 0.235 62.0 ## 4 2013-09-12 0.229 58.9 ## 5 2013-12-10 0.216 44.5 ## 6 2013-12-14 0.189 46.4 Problem 5 Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %&gt;% group_by(carrier, dest) %&gt;% summarise(n()) At first glance, Frontier and AirTran seem to have the worst delays. flights %&gt;% group_by(carrier) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(median_delay)) ## # A tibble: 16 x 2 ## carrier median_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 F9 6.00 ## 2 FL 5.00 ## 3 EV - 1.00 ## 4 MQ - 1.00 ## 5 YV - 2.00 ## 6 B6 - 3.00 ## 7 WN - 3.00 ## 8 UA - 6.00 ## 9 US - 6.00 ## 10 9E - 7.00 ## 11 OO - 7.00 ## 12 DL - 8.00 ## 13 AA - 9.00 ## 14 VX - 9.00 ## 15 HA -13.0 ## 16 AS -17.0 We can try to get a better sense of bad airlines vs bad airports by grouping by both, but this will be thrown off by carrier-dest combinations that occur infrequently. flights %&gt;% group_by(carrier, dest) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(carrier, median_delay)) + geom_boxplot() ## Warning: Removed 2 rows containing non-finite values (stat_boxplot). Problem 6 What does the sort argument to count() do. When might you use it? The sort argument will arrange count() in descending order. If we quickly wanted to find the most popular destinations, we could do: flights %&gt;% group_by(dest) %&gt;% count(sort = TRUE) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: dest [6] ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ORD 17283 ## 2 ATL 17215 ## 3 LAX 16174 ## 4 BOS 15508 ## 5 MCO 14082 ## 6 CLT 14064 5.7 - Grouped Mutates (and Filters) Problem 1 Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping. Problem 2 Which plane (tailnum) has the worst on-time record? We do a familiar group_by()-summarise() to calculate the proportion of flights with an arr_delay less than or equal to 0, and then apply a filter to see the on-time performance of planes with more than twenty flights. flights %&gt;% group_by(tailnum) %&gt;% summarise(flights = n(), on_time = mean(arr_delay &lt;= 0, na.rm = TRUE)) %&gt;% select(tailnum, flights, on_time) %&gt;% filter(flights &gt; 20) %&gt;% arrange(on_time) %&gt;% head() ## # A tibble: 6 x 3 ## tailnum flights on_time ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 N988AT 37 0.200 ## 2 N983AT 32 0.250 ## 3 N980AT 47 0.255 ## 4 N969AT 34 0.265 ## 5 N932AT 30 0.267 ## 6 N149AT 22 0.273 Problem 3 What time of day should you fly if you want to avoid delays as much as possible? It appears that flights later in day have a greater chance of being delayed than those early in the morning. flights %&gt;% group_by(hour) %&gt;% filter(!is.na(dep_delay)) %&gt;% summarise(delayed = mean(dep_delay &gt; 0, na.rm = TRUE)) %&gt;% ggplot(aes(x = hour, y = delayed)) + geom_col() Problem 4 For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination. A grouped mutate comes in handy here, as we can first calculate the total minutes of delay for each destination and then use that value to compute the proportion of the total delay attributable to each flight. flights %&gt;% group_by(dest) %&gt;% filter(arr_delay &gt; 0) %&gt;% mutate(total_delay = sum(arr_delay), prop_delay = arr_delay / sum(arr_delay)) %&gt;% select(dest, flight, total_delay, prop_delay) %&gt;% arrange(desc(total_delay)) %&gt;% head() ## # A tibble: 6 x 4 ## # Groups: dest [1] ## dest flight total_delay prop_delay ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ATL 4650 300299 0.0000400 ## 2 ATL 1547 300299 0.0000167 ## 3 ATL 346 300299 0.0000566 ## 4 ATL 4654 300299 0.0000200 ## 5 ATL 347 300299 0.00000666 ## 6 ATL 4876 300299 0.0000366 Problem 5 Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag() explore how the delay of a flight is related to the delay of the immediately preceding flight. First group by origin and the perform a mutate() with lag() to get the delay of the immediately preceding flight. We then use summarise to get the correlation between the delay and lagged delay for each airport. flights %&gt;% group_by(origin) %&gt;% filter(!is.na(dep_delay)) %&gt;% arrange(year, month, day, hour, minute) %&gt;% mutate(lag_delay = lag(dep_delay)) %&gt;% summarise(delay_correlation = cor(dep_delay, lag_delay, use = &#39;complete.obs&#39;)) ## # A tibble: 3 x 2 ## origin delay_correlation ## &lt;chr&gt; &lt;dbl&gt; ## 1 EWR 0.265 ## 2 JFK 0.242 ## 3 LGA 0.302 Problem 6 Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air? A grouped mutate is helpful here, as we can calculate the mean air time by destination and then immediately use that value to calculate a flight’s deviation from it. Note that we filtered out flights less than an hour long. deviation &lt;- flights %&gt;% group_by(dest) %&gt;% filter(!is.na(air_time)) %&gt;% mutate(mean_air_time = mean(air_time), deviation = (air_time - mean_air_time) / mean_air_time) %&gt;% filter(mean_air_time &gt; 60) %&gt;% arrange(deviation) %&gt;% select(air_time, mean_air_time, deviation, origin, dest) deviation %&gt;% head() ## # A tibble: 6 x 5 ## # Groups: dest [6] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 65.0 113 -0.424 LGA ATL ## 2 55.0 93.4 -0.411 EWR GSP ## 3 70.0 114 -0.388 EWR BNA ## 4 93.0 151 -0.382 EWR MSP ## 5 62.0 96.0 -0.354 EWR CVG ## 6 40.0 61.5 -0.349 LGA PIT deviation %&gt;% tail() ## # A tibble: 6 x 5 ## # Groups: dest [5] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 147 86.2 0.706 EWR CLT ## 2 198 116 0.713 EWR ORD ## 3 185 106 0.741 EWR SDF ## 4 138 70.9 0.947 JFK RDU ## 5 170 84.8 1.00 LGA DTW ## 6 170 84.8 1.00 JFK DTW Problem 7 Find all destinations that are flown by at least two carriers. Use that information to rank the carriers. We first use a group_by with mutate() and filter() to subset the destinations serviced by at least 2 carriers, followed by a second group_by to rank the carriers by total destinations served. We also merge data from the airlines data set to get the full carrier names. ExpressJet and Endeavor Air are regional airlines which operate as American Eagle, United Express, and Delta Connection. flights %&gt;% group_by(dest) %&gt;% mutate(carriers = n_distinct(carrier)) %&gt;% filter(carriers &gt;= 2) %&gt;% group_by(carrier) %&gt;% summarise(destinations = n_distinct(dest)) %&gt;% arrange(desc(destinations)) %&gt;% left_join(airlines) %&gt;% select(carrier, name, destinations) %&gt;% head() ## Joining, by = &quot;carrier&quot; ## # A tibble: 6 x 3 ## carrier name destinations ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 EV ExpressJet Airlines Inc. 51 ## 2 9E Endeavor Air Inc. 48 ## 3 UA United Air Lines Inc. 42 ## 4 DL Delta Air Lines Inc. 39 ## 5 B6 JetBlue Airways 35 ## 6 AA American Airlines Inc. 19 Problem 8 For each plane, count the number of flights before the first delay of greater than 1 hour. First group_by() tailnum and then apply a filter() using the cumall window function to subset everything before the first delay of more than 1 hour. flights %&gt;% arrange(year, month, day, hour, minute) %&gt;% group_by(tailnum) %&gt;% filter(cumall(dep_delay &lt;= 60)) %&gt;% count() %&gt;% arrange(desc(n)) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: tailnum [6] ## tailnum n ## &lt;chr&gt; &lt;int&gt; ## 1 N954UW 206 ## 2 N952UW 163 ## 3 N957UW 142 ## 4 N5FAAA 117 ## 5 N38727 99 ## 6 N3742C 98 "],
["chapter-7-exploratory-data-analysis.html", "Chapter 7 - Exploratory Data Analysis 7.3 - Variation 7.4 - Missing Values", " Chapter 7 - Exploratory Data Analysis Load the libraries needed for these exercises. library(tidyverse) 7.3 - Variation Problem 1 Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth. The distribution of x, y, and z generally seems to fall between 0 and 10mm, although the distributions of y and z both have much longer tails. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = x), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = z), binwidth = 0.5) Problem 2 Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.) The price of diamonds appears to peak around $2000, followed by a long tail for the much more expensive diamonds. Narrowing the value of binwidth shows that some values are not very populated. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 1000) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 500) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 100) Problem 3 How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference? People may prefer to buy a diamond that is a full carat rather than almost a carat large. There appears to be significant rounding in the data set: diamonds %&gt;% filter(between(carat, 0.99, 1.00)) %&gt;% group_by(carat) %&gt;% count() ## # A tibble: 2 x 2 ## # Groups: carat [2] ## carat n ## &lt;dbl&gt; &lt;int&gt; ## 1 0.990 23 ## 2 1.00 1558 Problem 4 Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows? Compare and contrast the following three graphs: while coord_cartesian() will preserve data, ylim() will drop rows that fall outside of the limits. ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0,60)) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + ylim(0,60) ## Warning: Removed 11 rows containing missing values (geom_bar). 7.4 - Missing Values Problem 1 What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference? Missing values are plotted in a bar chart but not a histogram. Remember that histograms are generally used to display numeric data, while bar charts are used for categorical data. Missing values can be considered another category to plot in a bar chart, but there is not necessarily an intuitive way to place missing values in a histogram. diamonds %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1610 rows containing non-finite values (stat_bin). diamonds %&gt;% mutate(cut = as.character(cut)) %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_bar() Problem 2 What does na.rm = TRUE do in mean() and sum()? Setting na.rm = TRUE will remove missing values before executing the function. x &lt;- c(1, 2, 3, NA) mean(x) ## [1] NA mean(x, na.rm = TRUE) ## [1] 2 "],
["chapter-10-tibbles.html", "Chapter 10 - Tibbles 10.5 - Exercises", " Chapter 10 - Tibbles Load the libraries needed for these exercises. library(tidyverse) 10.5 - Exercises Problem 1 How can you tell if an object is a tibble? (Hint: try printing mtcars, which is a regular data frame). Use the is.tibble() function to determine if an object is a tibble. A tibble will also have a heading if printed to the console. is.tibble(mtcars) ## [1] FALSE is.tibble(diamonds) ## [1] TRUE diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.230 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 ## 2 0.210 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 ## 3 0.230 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 ## 5 0.310 Good J SI2 63.3 58.0 335 4.34 4.35 2.75 ## 6 0.240 Very Good J VVS2 62.8 57.0 336 3.94 3.96 2.48 ## 7 0.240 Very Good I VVS1 62.3 57.0 336 3.95 3.98 2.47 ## 8 0.260 Very Good H SI1 61.9 55.0 337 4.07 4.11 2.53 ## 9 0.220 Fair E VS2 65.1 61.0 337 3.87 3.78 2.49 ## 10 0.230 Very Good H VS1 59.4 61.0 338 4.00 4.05 2.39 ## # ... with 53,930 more rows Problem 2 Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration? A data frame will attempt to auto-complete, while a tibble will not: df &lt;- data.frame(abc = 1, xyz = &quot;a&quot;) tib &lt;- tibble(abc = 1, xyz = &quot;a&quot;) df$x ## [1] a ## Levels: a tib$x ## Warning: Unknown or uninitialised column: &#39;x&#39;. ## NULL Data frames will sometimes simplify: is.data.frame(df[, &quot;xyz&quot;]) ## [1] FALSE is.tibble(tib[, &quot;xyz&quot;]) ## [1] TRUE Tibble will display useful information on the data: df[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## abc xyz ## 1 1 a tib[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## # A tibble: 1 x 2 ## abc xyz ## &lt;dbl&gt; &lt;chr&gt; ## 1 1.00 a Problem 3 If you have the name of a variable stored in an object, e.g. var &lt;- &quot;mpg&quot;, how can you extract the reference variable from a tibble? Use [] to extract the variable and [[]] to extract the vector: var &lt;- &#39;mpg&#39; as.tibble(mtcars)[var] ## # A tibble: 32 x 1 ## mpg ## &lt;dbl&gt; ## 1 21.0 ## 2 21.0 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ... with 22 more rows as.tibble(mtcars)[[var]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 ## [15] 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 ## [29] 15.8 19.7 15.0 21.4 Problem 4 Practice referring to non-syntactic names in the following data frame by: Extracting the variable called 1. annoying &lt;- tibble( `1` = 1:10, `2` = `1` * 2 + rnorm(length(`1`)) ) annoying %&gt;% select(`1`) ## # A tibble: 10 x 1 ## `1` ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 7 ## 8 8 ## 9 9 ## 10 10 Plotting a scatterplot of 1 vs 2. ggplot(annoying, aes(`1`, `2`)) + geom_point() Creating a new column called 3 which is 2 divided by 1. annoying &lt;- annoying %&gt;% mutate(`3` = `2` / `1`) Renaming the columns to one, two and three. annoying %&gt;% select(one = `1`, two = `2`, three = `3`) ## # A tibble: 10 x 3 ## one two three ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3.48 3.48 ## 2 2 4.11 2.06 ## 3 3 5.69 1.90 ## 4 4 7.45 1.86 ## 5 5 8.95 1.79 ## 6 6 10.2 1.71 ## 7 7 14.2 2.03 ## 8 8 17.4 2.18 ## 9 9 20.1 2.24 ## 10 10 20.2 2.02 Problem 5 What does tibble::enframe() do? When might you use it? enframe() can be used to convert a vector or list to a tibble: enframe(c(a = 5, b = 10)) ## # A tibble: 2 x 2 ## name value ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 5.00 ## 2 b 10.0 Problem 6 What option controls how many additional column names are printed at the footer of a tibble? The tibble.max_extra_cols option controls this behavior, with a default of 100. "],
["chapter-11-data-import.html", "Chapter 11 - Data Import 11.2 - Getting Started 11.3 - Parsing a Vector", " Chapter 11 - Data Import Load the libraries needed for these exercises. library(tidyverse) 11.2 - Getting Started Problem 1 What function would you use to read a file where fields were separated with “|”? Use read_delim(), using | as the delimiter: data &lt;- &#39;a|b|c\\n1|2|3&#39; read_delim(data, delim = &#39;|&#39;) ## # A tibble: 1 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 Problem 2 Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common? read_csv() and read_tsv() are essentially just read_delim with the delimiter preset to either a comma or a tab. All of their other arguments are the same. Problem 3 What are the most important arguments to read_fwf()? The most important argument to read_fwf() is col_positions, as this determines how data is read: fwf_sample &lt;- readr_example(&quot;fwf-sample.txt&quot;) cat(read_lines(fwf_sample)) ## John Smith WA 418-Y11-4111 Mary Hartford CA 319-Z19-4341 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA 418-Y11-4111 ## 2 Mary Hartford CA 319-Z19-4341 ## 3 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(5, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA ## 2 Mary Hartford CA ## 3 Evan Nolan IL Problem 4 Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like &quot; or '. By convention, read_csv() assumes that the quoting character will be &quot;, and if you want to change it you’ll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame? &quot;x,y\\n1,'a,b'&quot; Since read_delim() must be used instead of read_csv(), the delimiter must be set. The quote argument can be set to a single quote instead of a double quote: data &lt;- &quot;x,y\\n1,&#39;a,b&#39;&quot; read_delim(data, delim = &#39;,&#39;, quote = &#39;\\&#39;&#39;) ## # A tibble: 1 x 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a,b Problem 5 Identify what is wrong with each of the following inline CSV files. What happens when you run the code? There are more data than columns, which results in a parsing failure. The extra data are dropped from the data frame: read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 2 columns 3 columns literal data file 2 2 &lt;NA&gt; 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 4 5 There is too little data in row 2 and too much data in row 3 - row 2 is filled in with a missing value while row 3 drops data: read_csv(&quot;a,b,c\\n1,2\\n1,2,3,4&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 3 columns 2 columns literal data file 2 2 &lt;NA&gt; 3 columns 4 columns literal data ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 NA ## 2 1 2 3 There are two variables but only one data point - b is filled in with a missing value: read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 a closing quote at end of file &quot;&quot; literal data file 2 1 &lt;NA&gt; 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; Appears that the header was entered twice, so the data are parsed as character instead of a string. Or if the goal here was to enter a missing value NA, note that the n was processed as a new line \\n. read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b read_csv(&quot;a,b\\n1,2\\nna,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 na b read_csv() has a delimiter set to ,, use read_csv2() instead: read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv2(&quot;a;b\\n1;3&quot;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 3 11.3 - Parsing a Vector Problem 1 What are the most important arguments to locale()? The date_names argument provides useful defaults for a locale() object: dutch &lt;- locale(&#39;nl&#39;) japanese &lt;- locale(&#39;ja&#39;) str(dutch) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;januari&quot; &quot;februari&quot; &quot;maart&quot; &quot;april&quot; ... ## ..$ mon_ab: chr [1:12] &quot;jan.&quot; &quot;feb.&quot; &quot;mrt.&quot; &quot;apr.&quot; ... ## ..$ day : chr [1:7] &quot;zondag&quot; &quot;maandag&quot; &quot;dinsdag&quot; &quot;woensdag&quot; ... ## ..$ day_ab: chr [1:7] &quot;zo&quot; &quot;ma&quot; &quot;di&quot; &quot;wo&quot; ... ## ..$ am_pm : chr [1:2] &quot;a.m.&quot; &quot;p.m.&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; str(japanese) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ mon_ab: chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ day : chr [1:7] &quot;日曜日&quot; &quot;月曜日&quot; &quot;火曜日&quot; &quot;水曜日&quot; ... ## ..$ day_ab: chr [1:7] &quot;日&quot; &quot;月&quot; &quot;火&quot; &quot;水&quot; ... ## ..$ am_pm : chr [1:2] &quot;午前&quot; &quot;午後&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Be sure to read the full documentation for locale(). Common data import issues can probably be solved with decimal_mark, grouping_mark, and/or encoding. Problem 2 What happens if you try and set decimal_mark and grouping_mark to the same character? What happens to the default value of grouping_mark when you set decimal_mark to “,”? What happens to the default value of decimal_mark when you set the grouping_mark to “.”? locale() requires that decimal_mark and grouping_mark be different: x &lt;- locale(decimal_mark = &#39;.&#39;, grouping_mark = &#39;.&#39;) ## Error: `decimal_mark` and `grouping_mark` must be different Setting decimal_mark to , will automatically update grouping_mark to .. Similarly setting grouping_mark to . will automatically update decimal_mark to ,: x &lt;- locale(decimal_mark = &#39;,&#39;) x$grouping_mark ## [1] &quot;.&quot; y &lt;- locale(grouping_mark = &#39;.&#39;) y$decimal_mark ## [1] &quot;,&quot; Problem 3 I didn’t discuss the date_format and time_format options to locale(). What do they do? Construct an example that shows when they might be useful. A specific date_format and time_format structure can be specified in a locale(). This can be useful for formatting data with non-standard formatting: parse_date(&#39;June/7/90&#39;, locale = locale(date_format = &#39;%B/%d/%y&#39;)) ## [1] &quot;1990-06-07&quot; parse_time(&#39;1:15PM&#39;, locale = locale(time_format = &#39;%I:%M%p&#39;)) ## 13:15:00 Problem 4 If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly. Create a locale with the time zone updated: str(locale(tz = &#39;US/Eastern&#39;)) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;January&quot; &quot;February&quot; &quot;March&quot; &quot;April&quot; ... ## ..$ mon_ab: chr [1:12] &quot;Jan&quot; &quot;Feb&quot; &quot;Mar&quot; &quot;Apr&quot; ... ## ..$ day : chr [1:7] &quot;Sunday&quot; &quot;Monday&quot; &quot;Tuesday&quot; &quot;Wednesday&quot; ... ## ..$ day_ab: chr [1:7] &quot;Sun&quot; &quot;Mon&quot; &quot;Tue&quot; &quot;Wed&quot; ... ## ..$ am_pm : chr [1:2] &quot;AM&quot; &quot;PM&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;US/Eastern&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Problem 5 What’s the difference between read_csv() and read_csv2()? read_csv() has a delimiter set to , while read_csv2 is set to ;, as some countries use , as the decimal_mark: read_csv(&#39;a,b\\n1,2&#39;) ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 read_csv2(&#39;a;b\\n1;2&#39;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 Problem 6 What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out. See this list of common encodings (via Wikipedia). Problem 7 Generate the correct format string to parse each of the following dates and times: d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 t1 &lt;- &quot;1705&quot; t2 &lt;- &quot;11:15:10.12 PM&quot; Build up a datetime format using the pieces described in the chapter: parse_date(d1, format = &#39;%B %d, %Y&#39;) ## [1] &quot;2010-01-01&quot; parse_date(d2, format = &#39;%Y-%b-%d&#39;) ## [1] &quot;2015-03-07&quot; parse_date(d3, format = &#39;%d-%b-%Y&#39;) ## [1] &quot;2017-06-06&quot; parse_date(d4, format = &#39;%B %d (%Y)&#39;) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; parse_date(d5, format = &#39;%m/%d/%y&#39;) ## [1] &quot;2014-12-30&quot; parse_time(t1, format = &#39;%H%M&#39;) ## 17:05:00 parse_time(t2, format = &#39;%I:%M:%OS %p&#39;) ## 23:15:10.12 "],
["chapter-12-tidy-data.html", "Chapter 12 - Tidy Data 12.2 - Tidy Data 12.3 - Spreading and Gathering 12.4 - Spreading and Uniting", " Chapter 12 - Tidy Data Load the libraries needed for these exercises. library(tidyverse) 12.2 - Tidy Data Problem 1 Using prose, describe how the variables and observations are organised in each of the sample tables. table1 is the ‘tidy’ dataset: each variable has its own column, each observation has its own row, and each value has its own cell: table1 ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table2 combines cases and population into one column called type, this means that each variable does not have its own column, and that each observation spans multiple rows: table2 ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 In table3 the variable rate violates a tidy principle, with multiple values contained in a cell, which also means that each variable does not have its own column: table3 ## # A tibble: 6 x 3 ## country year rate ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 table4a and table4b separate cases and population into their own tables across years, with multiple observations in each row: table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 table4b ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 19987071 20595360 ## 2 Brazil 172006362 174504898 ## 3 China 1272915272 1280428583 Problem 2 Compute the rate for table2, and table4a + table4b. You will need to perform four operations: Extract the number of TB cases per country per year. Extract the matching population per country per year. Divide cases by population, and multiply by 10000. Store back in the appropriate place. Which representation is easiest to work with? Which is hardest? Why? NOTE these exercises demonstrate the difficulties of working with non-tidy data, the methods to come later in this chapter will greatly simplify the below code. Create a tidy version of table2 by filtering type into two tables and using the dplyr full_join() function to recreate table1 table2a &lt;- table2 %&gt;% filter(type == &#39;cases&#39;) %&gt;% select(country, year, cases = count) table2b &lt;- table2 %&gt;% filter(type == &#39;population&#39;) %&gt;% select(country, year, population = count) full_join(table2a, table2b) %&gt;% mutate(rate = cases / population * 10000) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 5 ## country year cases population rate ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.373 ## 2 Afghanistan 2000 2666 20595360 1.29 ## 3 Brazil 1999 37737 172006362 2.19 ## 4 Brazil 2000 80488 174504898 4.61 ## 5 China 1999 212258 1272915272 1.67 ## 6 China 2000 213766 1280428583 1.67 Use similar logic on table4a and table4b - this ends up being a bit more work as the data are already stored across two tables: table4a_1 &lt;- table4a %&gt;% mutate(year = 1999) %&gt;% select(country, year, cases = `1999`) table4a_2 &lt;- table4a %&gt;% mutate(year = 2000) %&gt;% select(country, year, cases = `2000`) table4b_1 &lt;- table4b %&gt;% mutate(year = 1999) %&gt;% select(country, year, population = `1999`) table4b_2 &lt;- table4b %&gt;% mutate(year = 2000) %&gt;% select(country, year, population = `2000`) bind_rows(table4a_1, table4a_2) %&gt;% full_join(bind_rows(table4b_1, table4b_2)) %&gt;% mutate(rate = cases / population * 10000) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 5 ## country year cases population rate ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.373 ## 2 Brazil 1999 37737 172006362 2.19 ## 3 China 1999 212258 1272915272 1.67 ## 4 Afghanistan 2000 2666 20595360 1.29 ## 5 Brazil 2000 80488 174504898 4.61 ## 6 China 2000 213766 1280428583 1.67 Problem 3 Recreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first? Filter type so that only cases is plotted: table2 %&gt;% filter(type == &#39;cases&#39;) %&gt;% ggplot(aes(year, count)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) 12.3 - Spreading and Gathering Problem 1 Why are gather() and spread() not perfectly symmetrical? Carefully consider the following example: stocks &lt;- tibble( year = c(2015, 2015, 2016, 2016), half = c( 1, 2, 1, 2), return = c(1.88, 0.59, 0.92, 0.17) ) stocks ## # A tibble: 4 x 3 ## year half return ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 1.00 1.88 ## 2 2015 2.00 0.590 ## 3 2016 1.00 0.920 ## 4 2016 2.00 0.170 stocks %&gt;% spread(year, return) %&gt;% gather(&quot;year&quot;, &quot;return&quot;, `2015`:`2016`) ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1.00 2015 1.88 ## 2 2.00 2015 0.590 ## 3 1.00 2016 0.920 ## 4 2.00 2016 0.170 (Hint: look at the variable types and think about column names.) Both spread() and gather() have a convert argument. What does it do? In the above example gather() and spread() are not perfectly symmetrical as year is converted from a numeric to a character variable. Use the convert argument to automatically run type.convert() on the key column: stocks %&gt;% spread(year, return, convert = TRUE) %&gt;% gather(&quot;year&quot;, &quot;return&quot;, `2015`:`2016`, convert = TRUE) ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1.00 2015 1.88 ## 2 2.00 2015 0.590 ## 3 1.00 2016 0.920 ## 4 2.00 2016 0.170 Problem 2 Why does this code fail? table4a %&gt;% gather(1999, 2000, key = &quot;year&quot;, value = &quot;cases&quot;) ## Error in inds_combine(.vars, ind_list): Position must be between 0 and n Be sure to use backticks to include a nonstandard variable name within a tibble: table4a %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 Problem 3 Why does spreading this tibble fail? How could you add a new column to fix the problem? people &lt;- tribble( ~name, ~key, ~value, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Phillip Woods&quot;, &quot;age&quot;, 50, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156 ) Spreading the given tibble will fail because rows 1 and 3 are identical observations. Add a count variable to fix the problem: people$count &lt;- c(1,1,2,1,1) people %&gt;% spread(key, value) ## # A tibble: 3 x 4 ## name count age height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Jessica Cordero 1.00 37.0 156 ## 2 Phillip Woods 1.00 45.0 186 ## 3 Phillip Woods 2.00 50.0 NA Problem 4 Tidy the simple tibble below. Do you need to spread or gather it? What are the variables? preg &lt;- tribble( ~pregnant, ~male, ~female, &quot;yes&quot;, NA, 10, &quot;no&quot;, 20, 12 ) The given tibble is not tidy as one variable (sex) is spread across multiple columns. Use gather(): preg %&gt;% gather(male:female, key = sex, value = count) ## # A tibble: 4 x 3 ## pregnant sex count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 yes male NA ## 2 no male 20.0 ## 3 yes female 10.0 ## 4 no female 12.0 12.4 - Spreading and Uniting Problem 1 What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) ## Warning: Expected 3 pieces. Additional pieces discarded in 1 rows [2]. ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f ## 3 h i j tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) ## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 1 rows [2]. ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e &lt;NA&gt; ## 3 f g i extra controls what happens when separate() results in too many pieces. In the first example, the second row appears to have an extra observation, which is dropped by default. Using extra = 'merge' will preserve the value: tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), extra = &#39;merge&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f,g ## 3 h i j fill controls what happens when separate() results in not enough pieces. In the second example, the second row appears to be missing an observation, which will be filled from the right be default. Using fill = 'left' will fill from left instead. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), fill = &#39;left&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 &lt;NA&gt; d e ## 3 f g i Problem 2 Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE? remove will drop the original input column from the data frame. Set it to FALSE in order to keep it in the data: tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f&quot;, &quot;g,h,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), remove = FALSE) ## # A tibble: 3 x 4 ## x one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a,b,c a b c ## 2 d,e,f d e f ## 3 g,h,i g h i Problem 3 Compare and contrast separate() and extract(). Why are there three variations of separation (by position, by separator, and with groups), but only one unite? separate() will create columns using either a position or a separator, while extract() will create columns using a regular expression groups. Consider the differences in the following: df &lt;- data.frame(x = c(NA, &quot;a-b&quot;, &quot;a-d&quot;, &quot;b-c&quot;, &quot;d-e&quot;)) df %&gt;% separate(x, c(&quot;A&quot;, &quot;B&quot;)) ## A B ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 a b ## 3 a d ## 4 b c ## 5 d e df %&gt;% extract(x, c(&quot;A&quot;, &quot;B&quot;), &quot;([a-d]+)-([a-d]+)&quot;) ## A B ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 a b ## 3 a d ## 4 b c ## 5 &lt;NA&gt; &lt;NA&gt; There is only one variation of unite() since it is a many to one mapping. The arguments passed to unite() will always be concatenated to single result. "],
["chapter-13-relational-data.html", "Chapter 13 - Relational data 13.2 - nycflights13 13.3 - Keys 13.4 - Mutating joins 13.5 - Filtering joins", " Chapter 13 - Relational data library(nycflights13) library(tidyverse) 13.2 - nycflights13 Problem 1 Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine? Latitude and longitude from the airports table and origin and destination from the flights table would be needed. Problem 2 I forgot to draw the relationship between weather and airports. What is the relationship and how should it appear in the diagram? The relationship is between origin from weather and faa from airports. It should be drawn as an arrow around the the flights table. Problem 3 weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with flights? Destination. Problem 4 We know that some days of the year are “special”, and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables? It would create a table of observations for days that are special that could relate to the flights table through day, month, and year. 13.3 - Keys Problem 1 Add a surrogate key to flights. flights %&gt;% mutate(surrogate_key = row_number()) ## # A tibble: 336,776 x 20 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 544 545 -1.00 1004 ## 5 2013 1 1 554 600 -6.00 812 ## 6 2013 1 1 554 558 -4.00 740 ## 7 2013 1 1 555 600 -5.00 913 ## 8 2013 1 1 557 600 -3.00 709 ## 9 2013 1 1 557 600 -3.00 838 ## 10 2013 1 1 558 600 -2.00 753 ## # ... with 336,766 more rows, and 13 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, surrogate_key &lt;int&gt; Problem 2 Identify the keys in the following datasets Lahman::Batting babynames::babynames nasaweather::atmos fueleconomy::vehicles ggplot2::diamonds (You might need to install some packages and read some documentation.) Lahman::Batting - playerID, yearID, and stint library(Lahman) Batting &lt;- as_tibble(Batting) Batting %&gt;% count(playerID, yearID, stint) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 4 ## # ... with 4 variables: playerID &lt;chr&gt;, yearID &lt;int&gt;, stint &lt;int&gt;, n &lt;int&gt; babynames::babynames library(babynames) babynames &lt;- as_tibble(babynames) babynames %&gt;% count(year, sex, name) %&gt;% filter(nn &gt; 1) ## # A tibble: 0 x 4 ## # ... with 4 variables: year &lt;dbl&gt;, sex &lt;chr&gt;, name &lt;chr&gt;, nn &lt;int&gt; nasaweather::atmos - lat, long, year, month library(nasaweather) ## ## Attaching package: &#39;nasaweather&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## storms atmos &lt;- as_tibble(atmos) atmos %&gt;% count(lat, long, year, month) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 5 ## # ... with 5 variables: lat &lt;dbl&gt;, long &lt;dbl&gt;, year &lt;int&gt;, month &lt;int&gt;, ## # n &lt;int&gt; fueleconomy::vehicles - library(fueleconomy) vehicles &lt;- as_tibble(vehicles) vehicles %&gt;% count(id) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 2 ## # ... with 2 variables: id &lt;int&gt;, n &lt;int&gt; ggplot2::diamonds - none! diamonds &lt;- as_tibble(diamonds) diamonds %&gt;% count(carat, cut, color, clarity, depth, table, price, x, y, z) %&gt;% filter(n &gt; 1) ## # A tibble: 143 x 11 ## carat cut color clarity depth table price x y z n ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.300 Good J VS1 63.4 57.0 394 4.23 4.26 2.69 2 ## 2 0.300 Very Good G VS2 63.0 55.0 526 4.29 4.31 2.71 2 ## 3 0.300 Very Good J VS1 63.4 57.0 506 4.26 4.23 2.69 2 ## 4 0.300 Premium D SI1 62.2 58.0 709 4.31 4.28 2.67 2 ## 5 0.300 Ideal G VS2 63.0 55.0 675 4.31 4.29 2.71 2 ## 6 0.300 Ideal G IF 62.1 55.0 863 4.32 4.35 2.69 2 ## 7 0.300 Ideal H SI1 62.2 57.0 450 4.26 4.29 2.66 2 ## 8 0.300 Ideal H SI1 62.2 57.0 450 4.27 4.28 2.66 2 ## 9 0.310 Good D SI1 63.5 56.0 571 4.29 4.31 2.73 2 ## 10 0.310 Very Good D SI1 63.5 56.0 732 4.31 4.29 2.73 2 ## # ... with 133 more rows Problem 3 Draw a diagram illustrating the connections between the Batting, Master, and Salaries tables in the Lahman package. Draw another diagram that shows the relationship between Master, Managers, AwardsManagers. Problem 4 How would you characterise the relationship between the Batting, Pitching, and Fielding tables? 13.4 - Mutating joins Problem 1 Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States: airports %&gt;% semi_join(flights, c(&quot;faa&quot; = &quot;dest&quot;)) %&gt;% ggplot(aes(lon, lat)) + borders(&quot;state&quot;) + geom_point() + coord_quickmap() (Don’t worry if you don’t understand what semi_join() does — you’ll learn about it next.) You might want to use the size or colour of the points to display the average delay for each airport. flights %&gt;% group_by(dest) %&gt;% summarize(arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% ggplot(aes(lon, lat, size = arr_delay), alpha = 0.5) + borders(&quot;state&quot;) + geom_point(alpha = 0.3, color = &quot;blue&quot;) + coord_quickmap() ## ## Attaching package: &#39;maps&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## map ## Warning: Removed 5 rows containing missing values (geom_point). Problem 2 Add the location of the origin and destination (i.e. the lat and lon) to flights. airports2 &lt;- airports %&gt;% select(faa, lat, lon) flights %&gt;% left_join(airports2, c(&quot;origin&quot; = &quot;faa&quot;)) %&gt;% rename(origin_lat = lat, origin_lon = lon) %&gt;% left_join(airports2, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% rename(dest_lat = lat, dest_lon = lon) ## # A tibble: 336,776 x 23 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 544 545 -1.00 1004 ## 5 2013 1 1 554 600 -6.00 812 ## 6 2013 1 1 554 558 -4.00 740 ## 7 2013 1 1 555 600 -5.00 913 ## 8 2013 1 1 557 600 -3.00 709 ## 9 2013 1 1 557 600 -3.00 838 ## 10 2013 1 1 558 600 -2.00 753 ## # ... with 336,766 more rows, and 16 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, origin_lat &lt;dbl&gt;, origin_lon &lt;dbl&gt;, ## # dest_lat &lt;dbl&gt;, dest_lon &lt;dbl&gt; Problem 3 Is there a relationship between the age of a plane and its delays? flights %&gt;% left_join(planes, &quot;tailnum&quot;) %&gt;% ggplot(aes(year.y, dep_delay)) + geom_point(alpha = 0.2) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 61980 rows containing non-finite values (stat_smooth). ## Warning: Removed 61980 rows containing missing values (geom_point). flights %&gt;% left_join(planes, &quot;tailnum&quot;) %&gt;% ggplot(aes(year.y, arr_delay)) + geom_point(alpha = 0.2) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 62923 rows containing non-finite values (stat_smooth). ## Warning: Removed 62923 rows containing missing values (geom_point). Problem 4 What weather conditions make it more likely to see a delay? flight_weather &lt;- flights %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% select(year, month, day, arr_delay, dep_delay, temp:visib, -wind_dir) %&gt;% filter(complete.cases(.)) %&gt;% mutate(arr_delay_categorical = cut_number(arr_delay, 5)) flight_weather %&gt;% summarize_all(funs(sum(is.na(.)))) ## # A tibble: 1 x 14 ## year month day arr_delay dep_delay temp dewp humid wind_speed ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 0 0 0 ## # ... with 5 more variables: wind_gust &lt;int&gt;, precip &lt;int&gt;, ## # pressure &lt;int&gt;, visib &lt;int&gt;, arr_delay_categorical &lt;int&gt; flight_means &lt;- flight_weather %&gt;% select(arr_delay_categorical, temp:visib) %&gt;% group_by(arr_delay_categorical) %&gt;% summarize_all(funs(mean(.))) flight_means %&gt;% gather(key = weather_type, value = value, -arr_delay_categorical) %&gt;% ggplot(aes(arr_delay_categorical, value)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~weather_type, scales = &quot;free&quot;) lm(arr_delay ~ dewp + humid + precip + pressure + temp + visib + wind_gust + wind_speed, data = flight_weather) ## ## Call: ## lm(formula = arr_delay ~ dewp + humid + precip + pressure + temp + ## visib + wind_gust + wind_speed, data = flight_weather) ## ## Coefficients: ## (Intercept) dewp humid precip pressure ## 538.52374 0.85046 -0.44252 98.37679 -0.47439 ## temp visib wind_gust wind_speed ## -0.66531 -2.40736 0.08383 NA Problem 5 What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather. flight_weather &lt;- flights %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% select(year, month, day, arr_delay, dep_delay, temp:visib, -wind_dir) %&gt;% filter(complete.cases(.)) %&gt;% mutate(dep_delay_categorical = cut_number(dep_delay, 5)) airports2 &lt;- airports %&gt;% select(faa, lat, lon) flight_airports &lt;- flights %&gt;% left_join(airports2, c(&quot;origin&quot; = &quot;faa&quot;)) %&gt;% rename(origin_lat = lat, origin_lon = lon) %&gt;% left_join(airports2, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% rename(dest_lat = lat, dest_lon = lon) %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% filter(complete.cases(.)) %&gt;% filter(month == 6 &amp; day == 13) flight_airports %&gt;% ggplot(aes(dep_delay)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. flight_airports %&gt;% ggplot(aes(arr_delay)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. flight_airports %&gt;% ggplot(aes(dest_lon, dest_lat, size = dep_delay)) + borders(&quot;state&quot;) + geom_point(alpha = 0.2) + coord_quickmap() Two derechos hit the United States East Coast on June 13, 2013. This caused significant departure delays at several airports. 13.5 - Filtering joins Problem 1 What does it mean for a flight to have a missing tailnum? What do the tail numbers that don’t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.) planes &lt;- as_tibble(planes) flights &lt;- as_tibble(flights) no_tailnum &lt;- flights %&gt;% anti_join(planes, &quot;tailnum&quot;) count(no_tailnum, carrier) ## # A tibble: 10 x 2 ## carrier n ## &lt;chr&gt; &lt;int&gt; ## 1 9E 1044 ## 2 AA 22558 ## 3 B6 830 ## 4 DL 110 ## 5 F9 50 ## 6 FL 187 ## 7 MQ 25397 ## 8 UA 1693 ## 9 US 699 ## 10 WN 38 count(no_tailnum, origin) ## # A tibble: 3 x 2 ## origin n ## &lt;chr&gt; &lt;int&gt; ## 1 EWR 5908 ## 2 JFK 17137 ## 3 LGA 29561 Departures from LaGuardia (LGA), JFK, and Newark (EWR) account for 100 percent of the planes without tail numbers. American Airlines (AA) and Envoy Airline (MQ) account for 90 percent of the planes without tail numbers. Problem 2 Filter flights to only show flights with planes that have flown at least 100 flights. flights100 &lt;- flights %&gt;% group_by(tailnum) %&gt;% count(tailnum) %&gt;% filter(n &gt;= 100) semi_join(flights, flights100, &quot;tailnum&quot;) ## # A tibble: 230,902 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 544 545 -1.00 1004 ## 4 2013 1 1 554 558 -4.00 740 ## 5 2013 1 1 555 600 -5.00 913 ## 6 2013 1 1 557 600 -3.00 709 ## 7 2013 1 1 557 600 -3.00 838 ## 8 2013 1 1 558 600 -2.00 849 ## 9 2013 1 1 558 600 -2.00 853 ## 10 2013 1 1 558 600 -2.00 923 ## # ... with 230,892 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Problem 3 Combine fueleconomy::vehicles and fueleconomy::common to find only the records for the most common models. library(fueleconomy) semi_join(vehicles, common) ## Joining, by = c(&quot;make&quot;, &quot;model&quot;) ## # A tibble: 14,531 x 12 ## id make model year class trans drive cyl displ fuel hwy cty ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1833 Acura Inte… 1986 Subc… Auto… Fron… 4 1.60 Regu… 28 22 ## 2 1834 Acura Inte… 1986 Subc… Manu… Fron… 4 1.60 Regu… 28 23 ## 3 3037 Acura Inte… 1987 Subc… Auto… Fron… 4 1.60 Regu… 28 22 ## 4 3038 Acura Inte… 1987 Subc… Manu… Fron… 4 1.60 Regu… 28 23 ## 5 4183 Acura Inte… 1988 Subc… Auto… Fron… 4 1.60 Regu… 27 22 ## 6 4184 Acura Inte… 1988 Subc… Manu… Fron… 4 1.60 Regu… 28 23 ## 7 5303 Acura Inte… 1989 Subc… Auto… Fron… 4 1.60 Regu… 27 22 ## 8 5304 Acura Inte… 1989 Subc… Manu… Fron… 4 1.60 Regu… 28 23 ## 9 6442 Acura Inte… 1990 Subc… Auto… Fron… 4 1.80 Regu… 24 20 ## 10 6443 Acura Inte… 1990 Subc… Manu… Fron… 4 1.80 Regu… 26 21 ## # ... with 14,521 more rows Problem 4 Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns? daily_delay &lt;- flights %&gt;% filter(arr_delay &gt; 0) %&gt;% group_by(year, month, day) %&gt;% summarize(arr_delay = sum(arr_delay, na.rm = TRUE)) %&gt;% mutate(yesterday = arr_delay + lag(arr_delay), tomorrow = arr_delay + lead(arr_delay)) %&gt;% ungroup() %&gt;% filter(min_rank(-tomorrow) == 1 | min_rank(-yesterday) == 1) Problem 5 What does anti_join(flights, airports, by = c(“dest” = “faa”)) tell you? What does anti_join(airports, flights, by = c(“faa” = “dest”)) tell you? Problem 6 You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned above. "],
["chapter-14-strings.html", "Chapter 14 - Strings 14.2 String basics 14.3.2 - Anchors 14.3.2 - Character classes and alternatives 14.3.4 - Repetition 14.3.5 - Grouping and backreferences 14.4 Tools 14.4.3 - Extract Matches 14.4.4 Grouped matches 14.4.5 - Replacing matches 14.4.6 - Splitting 14.5 - Other types of pattern 14.6 - Other uses of regular expressions", " Chapter 14 - Strings library(tidyverse) 14.2 String basics Problem 1 In code that doesn’t use stringr, you’ll often see paste() and paste0(). What’s the difference between the two functions? What stringr function are they equivalent to? How do the functions differ in their handling of NA? paste() automatically includes a space between each character string it combines. paste0() does not include a space. They are ~equivalent to str_c() from library(stringr). paste() and paste0() include NA as text. str_c() returns an NA for the entire string if the string contains an NA. Problem 2 In your own words, describe the difference between the sep and collapse arguments to str_c(). sep is a character string to insert between input vectors. Its input vector and output vector always have the same length. length(str_c(&quot;Letter&quot;, letters, sep = &quot;: &quot;)) ## [1] 26 collapse is a character string to insert between input vectors and to turn the vector into a single string. collapse always returns a vector with length one. length(str_c(&quot;Letter&quot;, letters, collapse = &quot;: &quot;)) ## [1] 1 Problem 3 Use str_length() and str_sub() to extract the middle character from a string. What will you do if the string has an even number of characters. string_middle &lt;- function(string) { string_length &lt;- str_length(string) if (string_length %% 2 == 1) { str_sub(string, floor((string_length + 1) / 2), ceiling((string_length) / 2)) } else if (string_length %% 2 == 0) { NULL } else {&quot;Error!&quot;} } string_middle(&quot;abc&quot;) ## [1] &quot;b&quot; string_middle(&quot;abcd&quot;) ## NULL It returned a NULL if string_length() is even. Problem 4 What does str_wrap() do? When might you want to use it? It implements the Knuth-Plass paragraph wrapping algorithm. It “breaks text paragraphs into lines, of total width - if it is possible - of at most given width. graph &lt;- &quot;It implements the Knuth-Plass paragraph wrapping algorithm. It breaks text paragraphs into lines, of total width - if it is possible - of at most given width.&quot; str_wrap(graph, width = 20) ## [1] &quot;It implements\\nthe Knuth-Plass\\nparagraph wrapping\\nalgorithm. It breaks\\ntext paragraphs\\ninto lines, of total\\nwidth - if it is\\npossible - of at\\nmost given width.&quot; This could be useful for formatting in html and rmarkdown. Especially for graphics and sidebars. Custom width is useful - especially in reproducible documents. Problem 5 What does str_trim() do? What’s the opposite of str_trim()? It trims whitespace from the left, right, or both sides of a character string. It is the string version of trimws(). str_pad() is the opposite of str_trim(). It adds whitespace to the left, right, or both sides of a character string. Problem 6 Write a function that turns (e.g.) a vector c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) into a string a, b, and c. Think carefully about what it should do if given a vector of length 0, 1, or 2. list_maker &lt;- function(string) { if (length(string) &gt; 1) { stringa &lt;- string[1:length(string)-1] stringb &lt;- string[length(string)] stringa &lt;- str_c(stringa, collapse = &quot;, &quot;) str_c(stringa, &quot;, and &quot;, stringb, collapse = &quot;&quot;) } else { string } } string &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) list_maker(string) ## [1] &quot;a, b, c, d, and e&quot; 14.3 - Matching patterns with regular expressions {-} Problem 1 Explain why each of these strings don’t match a : “&quot;,”\\“,”\\&quot;. “&quot; escapes the quotation mark and isn’t a valid character string in R. “\\” returns a character string with two backslashes which doesn’t match one backslash. “\\&quot; escapes the quotation mark and isn’t a valid character string. Problem 2 How would you match the sequence “’? Problem 3 What patterns will the regular expression ...... match? How would you represent it as a string? It will match a string of three periods separated by characters. \\\\..\\\\..\\\\... str_view(&quot;.a.b.c&quot;, &quot;\\\\..\\\\..\\\\..&quot;) 14.3.2 - Anchors Problem 1 How would you match the literal string “\\(^\\)”? x &lt;- &quot;$^$&quot; str_view(x, &quot;\\\\$\\\\^\\\\$&quot;) Problem 2 Given the corpus of common words in stringr::words, create regular expressions that will find all words that: Start with “y” str_view(words, &quot;^y&quot;, match = TRUE) End with “x” table(str_detect(words, &quot;x$&quot;)) ## ## FALSE TRUE ## 976 4 Are exactly three letters long. (Don’t cheat by using str_length()!) table(str_detect(words, &quot;^...$&quot;)) ## ## FALSE TRUE ## 870 110 Have seven letters or more. table(str_detect(words, &quot;^.......&quot;)) ## ## FALSE TRUE ## 761 219 14.3.2 - Character classes and alternatives Problem 1 Create regular expressions to find all words that: Start with a vowel str_view(words[1:10], &quot;^[aeiou]&quot;, match = TRUE) Only contain consonants. (Hint: think about match “not”-vowels.) str_view(words, &quot;^[^aeiou]+$&quot;, match = TRUE) I’m not sure if this can be done with + which is introduced on page 204 after the exercises. End with ed, but not with eed. str_view(words, &quot;[^e]ed$&quot;, match = TRUE) End with ing or ize. str_view(words, &quot;ing$|ize$&quot;, match = TRUE) Problem 2 Empirically verify the rule “i before e except after c.” Let’s try this with proof by contradiction. We need to look for two conditions: ie after c ei str_view(words, &quot;ei|[c]ie&quot;, match = TRUE) Six words violate the rules. “i before e except after c” is and always will be rubbish. Problem 3 Is “q” always followed by a “u”? Proof by contradiction: look for a “q” not followed by a “u”. str_view(words, &quot;q^[u]&quot;, match = TRUE) Yes, “q” is always followed by a “u” in this data set. Problem 4 Write a regular expression that matches a word if it’s probably written in British English, not American English. str_view(words, &quot;our|ise|ogue&quot;, match = TRUE) Problem 5 Create a regular expression that will match telephone numbers as commonly written in your country. phone &lt;- c(&quot;212-555-7891&quot;, &quot;(212)-555-7891&quot;) str_view(phone, &quot;\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d\\\\d|\\\\(\\\\d\\\\d\\\\d\\\\)-\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d\\\\d&quot;, match = TRUE) 14.3.4 - Repetition Problem 1 Describe the equivalents of ?, +, and * in {n, m} form. ? == {1} + == {1,} * == {0,} Problem 2 Describe in words what these regular expressions match (read carefully to if I’m using a regular expression or a string that defines a regular expressions): ^.*$ matches an entire string. ^ matches the start of a string. . is any character which is repeated 0 or more times with *. $ matches the end of a string. &quot;\\\\{.+\\\\}&quot; 3.\\d{4}-\\d{2}-\\d{2} matches exactly 4 digits followed by a dash followed by exactly two digits followed by a dash followed by exactly two digits. This is the same as the ISO8601 date international standard. \\\\\\\\{4} matches exactly four backslashes. Problem 3 Create regular expressions to find all words that: Start with three consonants. string &lt;- c(&quot;scratch&quot;, &quot;apple&quot;) str_view(string, &quot;^[^aeiou]{3}&quot;) Have three or more vowels in a row. string &lt;- c(&quot;scratch&quot;, &quot;aaapple&quot;) str_view(string, &quot;^[aeiou]{3,}&quot;) Have two or more vowel consonant pairs in a row. string &lt;- c(&quot;banana&quot;, &quot;coconut&quot;) str_view(string, &quot;([aeiou][^aeiou]){2,}&quot;) Problem 4 Solve the beginner regexp crosswords at http://regexcrossword.com/challenges/beginner 14.3.5 - Grouping and backreferences Problem 1 Describe in words what these expressions will match: (.)\\1\\1 will match any string of three repeated letters or symbols. &quot;(.)(.)\\\\2\\\\1&quot; will match a four letter palindrome (spelled the same forwards and backwards). (..)\\1 will match a four letter string where the second half is a reptition of the first half. &quot;(.).\\\\1.\\\\1&quot; will match and repetition of the same character three times where each character is spearated by a character (ex. “ababa” and “&amp;&amp;&amp;&amp;&amp;”). &quot;(.)(.)(.)*\\\\3\\\\2\\\\1&quot; will match a string of characters where the first three characters are repeted in reverse and the middle character can be repeated multiple times (ex. “abccba” and “abcccccba”). Problem 2 0.0.0.0.1 2. Construct regular expressions to match words that: Start and end with the same character. &quot;^(.).*\\\\1$&quot; Contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice) &quot;.*(..).*\\\\1.*&quot; Contain one letter repeated in at least three places (e.g., “eleven” contains three “e”s). &quot;.*(.).*\\\\1.*\\\\1.*&quot; 14.4 Tools Problem 1 For each of the following challenges, try solving it by using both a singular regular expression, and a combination of multiple str_detect() calls: 1. Find all words that start of end with x. str_detect(words, &quot;^x.*x$&quot;) &amp; str_detect(str_detect(words, &quot;^x&quot;), &quot;x$&quot;) 2. Find all words that start with a vowel and end with a consonant. str_detect(words, &quot;^[aeiou].*[^aeiou]$&quot;) &amp; str_detect(str_detect(words, &quot;^[aeiou]&quot;), &quot;[^aeiou]$&quot;) 3. Are there any words that contain at least one of each different vowel? TODO(aaron): hmm? 4. What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator) as_tibble(words) %&gt;% mutate(vowels = str_count(value, &quot;[aeiou]&quot;)) %&gt;% filter(vowels == max(vowels)) ## # A tibble: 8 x 2 ## value vowels ## &lt;chr&gt; &lt;int&gt; ## 1 appropriate 5 ## 2 associate 5 ## 3 available 5 ## 4 colleague 5 ## 5 encourage 5 ## 6 experience 5 ## 7 individual 5 ## 8 television 5 as_tibble(words) %&gt;% mutate(letters = str_count(value), vowels = str_count(value, &quot;[aeiou]&quot;), proportion = vowels / letters) %&gt;% filter(proportion == max(proportion)) ## # A tibble: 1 x 4 ## value letters vowels proportion ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 1 1.00 14.4.3 - Extract Matches Problem 1 In the previous example, you might have noticed that the regular expression matched “flickered”, which is not a color. Modify the regex to fix the problem. colors &lt;- &quot;\\\\b(red|orange|yellow|green|blue|purple)\\\\b&quot; more &lt;- sentences[str_count(sentences, colors) &gt; 1] str_view_all(more, colors) Problem 2 From the Harvard sentences data, extract: 1. The first word from each sentence. str_extract(sentences, &quot;[^\\\\s]*&quot;) 2. All words ending in ing. str_extract_all(sentences, &quot;\\\\b[^\\\\s]*ing\\\\b&quot;) 3. All plurals. TODO(aaron): hmm? 14.4.4 Grouped matches Problem 1 Find all words that come after a “number” like “one”, “two”, “three”, etc. Pull out the number and the word. numbers &lt;- &quot;([Oo]ne|[Tt]wo|[Tt]hree|[Ff]our|[Ff]ive|[Ss]ix|[Ss]even|[Ee]ight|[Nn]ine|[Tt]en) ([^ ]+)&quot; tibble(sentence = sentences) %&gt;% extract( sentence, c(&quot;number&quot;, &quot;word&quot;), numbers, remove = FALSE ) %&gt;% filter(!is.na(number)) ## # A tibble: 46 x 3 ## sentence number word ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Rice is often served in round bowls. ten served ## 2 Four hours of steady work faced us. Four hours ## 3 Two blue fish swam in the tank. Two blue ## 4 Lift the square stone over the fence. one over ## 5 The rope will bind the seven books at once. seven books ## 6 The two met while playing on the sand. two met ## 7 There are more than two factors here. two factors ## 8 He lay prone and hardly moved a limb. one and ## 9 Ten pins were set in order. Ten pins ## 10 Type out three lists of orders. three lists ## # ... with 36 more rows Problem 2 Find all contractions. Separate out the pieces before and after the apostrophe. &quot;[^ ]*'[^ ]*&quot; could be used, but it returns possessive nouns. The following string of regular expressions gets around this problem. contractions &lt;- &quot;[^ ]*&#39;m|[^ ]*n&#39;t|[^ ]*&#39;ve|[^ ]*&#39;d|[^ ]*&#39;re|[^ ]*&#39;ll|[Ll]et&#39;s|[Ss]he&#39;s|[Hh]e&#39;s&quot; tibble(sentence = sentences) %&gt;% mutate(contraction = str_extract(sentences, contractions)) %&gt;% filter(!is.na(contraction)) %&gt;% extract(contraction, c(&quot;before&quot;, &quot;apostrophe&quot;, &quot;after&quot;), &quot;(.*)(&#39;)(.*)&quot;) ## # A tibble: 4 x 4 ## sentence before apostrophe after ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Open the crate but don&#39;t break the glass. don &#39; t ## 2 Let&#39;s all join as we sing the last chorus. Let &#39; s ## 3 We don&#39;t get much money but we have fun. don &#39; t ## 4 We don&#39;t like to admit our small faults. don &#39; t 14.4.5 - Replacing matches Problem 1 Replace all forward slashes in a string with backslashes. str_replace_all(&quot;a/b/c&quot;, &quot;/&quot;, &quot;\\\\\\\\&quot;) Problem 2 Implement a simple version of str_to_lower() using str_replace_all(). str_replace_all(&quot;AbC&quot;, &quot;[A-Z]&quot;, tolower) Problem 3 Switch the first and last letters in words. Which of those strings are still words? new.words &lt;- str_replace(words, &quot;(^.)(.*)(.$)&quot;, &quot;\\\\3\\\\2\\\\1&quot;) words[new.words %in% words] ## [1] &quot;a&quot; &quot;america&quot; &quot;area&quot; &quot;dad&quot; &quot;dead&quot; ## [6] &quot;deal&quot; &quot;dear&quot; &quot;depend&quot; &quot;dog&quot; &quot;educate&quot; ## [11] &quot;else&quot; &quot;encourage&quot; &quot;engine&quot; &quot;europe&quot; &quot;evidence&quot; ## [16] &quot;example&quot; &quot;excuse&quot; &quot;exercise&quot; &quot;expense&quot; &quot;experience&quot; ## [21] &quot;eye&quot; &quot;god&quot; &quot;health&quot; &quot;high&quot; &quot;knock&quot; ## [26] &quot;lead&quot; &quot;level&quot; &quot;local&quot; &quot;nation&quot; &quot;no&quot; ## [31] &quot;non&quot; &quot;on&quot; &quot;rather&quot; &quot;read&quot; &quot;refer&quot; ## [36] &quot;remember&quot; &quot;serious&quot; &quot;stairs&quot; &quot;test&quot; &quot;tonight&quot; ## [41] &quot;transport&quot; &quot;treat&quot; &quot;trust&quot; &quot;window&quot; &quot;yesterday&quot; 14.4.6 - Splitting Problem 1 Split up a string like “apples, pears, and bananas” into individual components. str_split(&quot;apples, pears, and bananas&quot;, boundary(&quot;word&quot;)) Problem 2 Why is it better to split up by boundary(“word”) than &quot; “? &quot; &quot; captures non-words like the space after the period while boundary(&quot;word&quot;) only captures words. Problem 3 What does splitting with an empty string (“”) do? Experiment and read the documentation. “An empty pattern,”“, is equivalent to boundary(”character“).” 14.5 - Other types of pattern Problem 1 How would you find all strings containing “&quot; with regex() versus fixed. regex(&quot;\\\\\\\\&quot;) &amp; fixed(&quot;\\&quot;) Problem 2 What are the five most common words in setences? The five most common words are “the”, “a”, “of”, “to”, and “and”. str_split(sentences, boundary(&quot;word&quot;)) %&gt;% flatten_chr() %&gt;% str_to_lower() %&gt;% as_tibble() %&gt;% group_by(value) %&gt;% count() %&gt;% arrange(-n) %&gt;% ungroup() %&gt;% top_n(5) ## Selecting by n ## # A tibble: 5 x 2 ## value n ## &lt;chr&gt; &lt;int&gt; ## 1 the 751 ## 2 a 202 ## 3 of 132 ## 4 to 123 ## 5 and 118 14.6 - Other uses of regular expressions Problem 1 Find the stringi function that: 1. Count the number of words stri_count_words 2. Find duplicated strings. stri_duplicated() 3. Generate random text. stri_rand_strings() Problem 2 How do you control the language that str_sort() uses for sorting? With the locale = argument in the opts_collator argument. "],
["chapter-15-factors.html", "Chapter 15 - Factors 15.3 - General Social Survey 15.4 - Modifying factor order 15.5 - Modifying factor levels", " Chapter 15 - Factors library(tidyverse) library(forcats) 15.3 - General Social Survey Problem 1 Explore the distribution of rincome (reported income). What makes the default bar chart hard to understand? How could you improve the plot? There are so many bars that the x-axis labels overlap. ggplot(gss_cat, aes(rincome)) + geom_bar() Let’s rotate the labels. ggplot(gss_cat, aes(rincome)) + geom_bar() + theme(axis.text.x = element_text(angle=90)) Problem 2 What is the most common relig in this survey? What’s the most common partyid? gss_cat %&gt;% count(relig) %&gt;% top_n(1) ## # A tibble: 1 x 2 ## relig n ## &lt;fct&gt; &lt;int&gt; ## 1 Protestant 10846 gss_cat %&gt;% count(partyid) %&gt;% top_n(1) ## # A tibble: 1 x 2 ## partyid n ## &lt;fct&gt; &lt;int&gt; ## 1 Independent 4119 Problem 3 Which relig does denom apply to? How can you find out without a table? How can you find out with a vizualization? denom applies to Protestant. gss_cat %&gt;% group_by(denom) %&gt;% count(relig) ## # A tibble: 47 x 3 ## # Groups: denom [30] ## denom relig n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 No answer No answer 93 ## 2 No answer Christian 2 ## 3 No answer Protestant 22 ## 4 Don&#39;t know Christian 11 ## 5 Don&#39;t know Protestant 41 ## 6 No denomination Christian 452 ## 7 No denomination Other 7 ## 8 No denomination Protestant 1224 ## 9 Other Protestant 2534 ## 10 Episcopal Protestant 397 ## # ... with 37 more rows gss_cat %&gt;% group_by(relig, denom) %&gt;% summarize(n = n()) %&gt;% ggplot(aes(relig, denom, size = n)) + geom_point() + theme(axis.text.x=element_text(angle = 90)) 15.4 - Modifying factor order Problem 1 There are some conspicuously high numbers in tvhours. Is the mean a good summary? Exteme values bias the mean. tvhours is skewed to the right and median may be a better summary statistic. gss_cat %&gt;% ggplot(aes(tvhours)) + geom_histogram() mean(gss_cat$tvhours, na.rm = TRUE) ## [1] 2.980771 median(gss_cat$tvhours, na.rm = TRUE) ## [1] 2 Problem 2 For each factor in gss_cat identify whether the order of the levels is arbitrary or principled. marital: arbitrary age: principled race: arbitrary rincome: principled partyid: arbitrary relig: arbitrary denom: arbitrary Problem 3 Why did moving “Not Applicable” to the front of the levels move it to the bottom of the plot? Factors are shown in reverse order from top to bottom when coord_flip is used. gss_cat %&gt;% mutate(race = fct_relevel(race, &quot;Not applicable&quot;)) %&gt;% ggplot(aes(race)) + geom_bar() + coord_flip() + scale_x_discrete(drop = FALSE) 15.5 - Modifying factor levels Problem 1 How have the proportions of people identifying as Democrat, Republican, and Independent changed over time? gss_cat %&gt;% mutate(partyid = fct_collapse(partyid, other = c(&quot;No answer&quot;, &quot;Don&#39;t know&quot;, &quot;Other party&quot;), rep = c(&quot;Strong republican&quot;, &quot;Not str republican&quot;), ind = c(&quot;Ind,near rep&quot;, &quot;Independent&quot;, &quot;Ind,near dem&quot;), dem = c(&quot;Not str democrat&quot;, &quot;Strong democrat&quot;))) %&gt;% filter(partyid != &quot;other&quot;) %&gt;% ggplot(aes(x = year, ..prop.., fill = partyid)) + geom_bar(position = &quot;dodge&quot;) + scale_x_continuous(breaks = c(2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014)) Problem 2 How could you collapse rincome into a small set of categories? gss_cat %&gt;% mutate(rincome = fct_collapse(rincome, `More than $10,000` = c(&quot;$10000 - 14999&quot;, &quot;$15000 - 19999&quot;, &quot;$20000 - 24999&quot;, &quot;$25000 or more&quot;), `Less than $10,000` = c(&quot;Lt $1000&quot;, &quot;$1000 to 2999&quot;, &quot;$3000 to 3999&quot;, &quot;$4000 to 4999&quot;, &quot;$5000 to 5999&quot;, &quot;$6000 to 6999&quot;, &quot;$7000 to 7999&quot;, &quot;$8000 to 9999&quot;))) %&gt;% mutate(rincome = fct_lump(rincome, n = 3)) %&gt;% count(rincome, sort = TRUE) ## # A tibble: 4 x 2 ## rincome n ## &lt;fct&gt; &lt;int&gt; ## 1 More than $10,000 10862 ## 2 Not applicable 7043 ## 3 Less than $10,000 2153 ## 4 Other 1425 "],
["chapter-16-dates-and-times.html", "Chapter 16 - Dates and times 16.2 - Creating date/times 16.3 - Date-time components 16.4 - Time spans", " Chapter 16 - Dates and times library(tidyverse) library(lubridate) library(nycflights13) 16.2 - Creating date/times Problem 1 What happens if you parse a string that contains invalid dates? ymd(c(&quot;2010-10-10&quot;, &quot;bananas&quot;)) Warning message: 1 failed to parse. Problem 2 What does the tzone argument to today() do? Why is it important? tzone controls the time zone used when finding the current date. It defaults to the system time zone. It is important because every hour a different time zone moves from today to tomorrow and when analyzing data from another time zone dates can change. Problem 3 Use the appropriate lubridate function to parse the following dates: d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 mdy(d1) ## [1] &quot;2010-01-01&quot; ymd(d2) ## [1] &quot;2015-03-07&quot; dmy(d3) ## [1] &quot;2017-06-06&quot; mdy(d4) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; mdy(d5) ## [1] &quot;2014-12-30&quot; 16.3 - Date-time components make_datetime_100 &lt;- function(year, month, day, time) { make_datetime(year, month, day, time %/% 100, time %% 100) } flights_dt &lt;- flights %&gt;% filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% mutate( dep_time = make_datetime_100(year, month, day, dep_time), arr_time = make_datetime_100(year, month, day, arr_time), sched_dep_time = make_datetime_100(year, month, day, sched_dep_time), sched_arr_time = make_datetime_100(year, month, day, sched_arr_time) ) %&gt;% select(origin, dest, ends_with(&quot;delay&quot;), ends_with(&quot;time&quot;)) Problem 1 How does the distribution of flight times within a day change over the course of the year? flights_dt %&gt;% mutate(dep_hour = update(dep_time, yday = 1), month = month(dep_time, label = TRUE)) %&gt;% ggplot(aes(dep_hour, color = month)) + geom_freqpoly(binwidth = 900) + labs(title = &quot;Distribution of Flight Times by Month&quot;) Problem 2 Compare dep_time, sched_dep_time, and dep_delay. Are they consistent? Explain your findings. dep_time, sched_dep_time, and dep_delay are mostly consistent. The only issue is when delays extend past midnight. The value for day doesn’t increase for dep_time when a a flight is delayed beyond its scheduled day. flights_dt %&gt;% mutate(dep_time2 = sched_dep_time + dep_delay * 60) %&gt;% filter(dep_time != dep_time2) %&gt;% select(sched_dep_time, dep_time, dep_time2) ## # A tibble: 1,205 x 3 ## sched_dep_time dep_time dep_time2 ## &lt;dttm&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 2013-01-01 18:35:00 2013-01-01 08:48:00 2013-01-02 08:48:00 ## 2 2013-01-02 23:59:00 2013-01-02 00:42:00 2013-01-03 00:42:00 ## 3 2013-01-02 22:50:00 2013-01-02 01:26:00 2013-01-03 01:26:00 ## 4 2013-01-03 23:59:00 2013-01-03 00:32:00 2013-01-04 00:32:00 ## 5 2013-01-03 21:45:00 2013-01-03 00:50:00 2013-01-04 00:50:00 ## 6 2013-01-03 23:59:00 2013-01-03 02:35:00 2013-01-04 02:35:00 ## 7 2013-01-04 23:59:00 2013-01-04 00:25:00 2013-01-05 00:25:00 ## 8 2013-01-04 22:45:00 2013-01-04 01:06:00 2013-01-05 01:06:00 ## 9 2013-01-05 23:59:00 2013-01-05 00:14:00 2013-01-06 00:14:00 ## 10 2013-01-05 22:30:00 2013-01-05 00:37:00 2013-01-06 00:37:00 ## # ... with 1,195 more rows Problem 3 Compare air_time with the duration between the departure and arrival. Explain your findings. (Hint: consider the location of the airport.) TODO(aaron): There is no way to explain my findings. flights_dt %&gt;% mutate(air_time_calc = as.numeric(arr_time - dep_time), air_time_diff = air_time - air_time_calc) %&gt;% select(origin, dest, air_time, air_time_calc, air_time_diff) ## # A tibble: 328,063 x 5 ## origin dest air_time air_time_calc air_time_diff ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EWR IAH 227 193 34.0 ## 2 LGA IAH 227 197 30.0 ## 3 JFK MIA 160 221 -61.0 ## 4 JFK BQN 183 260 -77.0 ## 5 LGA ATL 116 138 -22.0 ## 6 EWR ORD 150 106 44.0 ## 7 EWR FLL 158 198 -40.0 ## 8 LGA IAD 53.0 72.0 -19.0 ## 9 JFK MCO 140 161 -21.0 ## 10 LGA ORD 138 115 23.0 ## # ... with 328,053 more rows Problem 4 How does the average delay time change over the course of a day? Should you use dep_time or sched_dep_time? Why? The average delay time increases slightly over the course of a day. This makes sense. Events that delay flights, like weather, mechanical issues, and pilot flight limits, accumulate over the course of the day and increase the probability of a flight being delayed. sched_dep_time or dep_time could make sense. sched_dep_time is more useful if you’re planning on scheduling a flight and want to avoid delays! flights_dt %&gt;% mutate(sched_dep_time = update(sched_dep_time, yday = 1)) %&gt;% ggplot(aes(sched_dep_time, dep_delay)) + geom_point(alpha = 0.05) + geom_smooth() Problem 5 On what day of the week should you leave if you want to minimize the chance of a delay? Saturday boasts the lowest percentage of flights that have delayed departures and delayed arrivals. flights_dt %&gt;% mutate(day_of_week = wday(dep_time, label = TRUE), delayed = ifelse(dep_delay &gt; 0, 1, 0)) %&gt;% group_by(day_of_week) %&gt;% summarize(delay_prob = mean(delayed)) %&gt;% ggplot(aes(day_of_week, delay_prob)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label = scales::percent(delay_prob)), vjust = -0.25, size = 3) + scale_y_continuous(labels = scales::percent, limits = c(0, 0.6)) + labs(title = &quot;Percentage of Flight Departures Delayed By Day of the Week&quot;, subtitle = &quot;Flights are Delayed if They Depart &gt;= 1 Minute Behind Schedule&quot;, x = &quot;Day of the Week&quot;, y = &quot;Percentage of Flights Delayed&quot;) flights_dt %&gt;% mutate(day_of_week = wday(arr_time, label = TRUE), delayed = ifelse(arr_delay &gt; 0, 1, 0)) %&gt;% group_by(day_of_week) %&gt;% summarize(delay_prob = mean(delayed, na.rm = TRUE)) %&gt;% ggplot(aes(day_of_week, delay_prob)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label = scales::percent(delay_prob)), vjust = -0.25, size = 3) + scale_y_continuous(labels = scales::percent, limits = c(0, 0.6)) + labs(title = &quot;Percentage of Flight Arrivals Delayed By Day of the Week&quot;, subtitle = &quot;Flights are Delayed if They Arrive &gt;= 1 Minute Behind Schedule&quot;, x = &quot;Day of the Week&quot;, y = &quot;Percentage of Flights Delayed&quot;) Problem 6 What makes the distribution of diamonds$carat and flights_dep_time similar? Humans round. In the case of the diamonds, they always round up! ggplot(data = diamonds, mapping = aes(x = carat)) + geom_histogram(bins = 100) + scale_y_continuous(expand = c(0, 0), labels = scales::dollar) + labs(title = &quot;Diamond Prices Increase With Size&quot;, subtitle = &quot;Diamond Prices in Dollars and Sizes in Carats&quot;, caption = &quot;Urban Institute&quot;, x = &quot;Carat&quot;, y = &quot;Price&quot; ) flights_dt %&gt;% mutate(dep_time = update(dep_time, yday = 1)) %&gt;% ggplot(aes(dep_time)) + geom_histogram(bins = 100) Problem 7 Confirm my hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. Hint: create a binary variable that tells whether or not the flight was delayed. Early departures of scheduled flights in minutes 20-30 and minutes 50-60 is definitely a contributing factor to the disuniform distribution of average delay times on page 245. flights_dt %&gt;% mutate(Minute = minute(dep_time), dep_delay_dummy = ifelse(dep_delay &gt; 0, 1, 0), dep_delay_dummy = factor(dep_delay_dummy, labels = c(&quot;On Time&quot;, &quot;Delayed&quot;))) %&gt;% ggplot(aes(Minute, color = dep_delay_dummy)) + geom_freqpoly() + labs(title = &quot;Distribution of Minutes of Departure Times by Delay Status&quot;, y = &quot;Count&quot;) 16.4 - Time spans Problem 1 Why is there months() but no dmonths()? Unlike hours, days, and weeks, the number of months in a year never varies. Problem 2 Explaindays(overnight * 1) to someone who has just started learning R. How does it work? Overnight is a logical vector where TRUE == 1 and FALSE == 0. If it’s an overnight flight, days() add 23, 24, or 25 hours to the value depending on the day of the year. I am unsure why * 1 is necessary. Problem 3 Create a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year. ymd(&quot;2015-01-01&quot;) + months(0:11) ## [1] &quot;2015-01-01&quot; &quot;2015-02-01&quot; &quot;2015-03-01&quot; &quot;2015-04-01&quot; &quot;2015-05-01&quot; ## [6] &quot;2015-06-01&quot; &quot;2015-07-01&quot; &quot;2015-08-01&quot; &quot;2015-09-01&quot; &quot;2015-10-01&quot; ## [11] &quot;2015-11-01&quot; &quot;2015-12-01&quot; floor_date(today(), unit = &quot;year&quot;) + months(0:11) ## [1] &quot;2018-01-01&quot; &quot;2018-02-01&quot; &quot;2018-03-01&quot; &quot;2018-04-01&quot; &quot;2018-05-01&quot; ## [6] &quot;2018-06-01&quot; &quot;2018-07-01&quot; &quot;2018-08-01&quot; &quot;2018-09-01&quot; &quot;2018-10-01&quot; ## [11] &quot;2018-11-01&quot; &quot;2018-12-01&quot; Problem 4 Write a function that, given your birthday (as a date), returns how old you are in years. age &lt;- function(birthday) { (birthday %--% today()) / dyears(1) } age(ymd(&quot;1992-03-14&quot;)) ## [1] 25.96986 Problem 5 Why can’t (today() %--% (today() + years(1)) / months(1) work? There is an uneven number of parentheses. "]
]
