[
["index.html", "R for Data Science Solution Set Preface", " R for Data Science Solution Set Preface This is a solution guide to the exercises in R for Data Science by Hadley Wickham and Garret Grolemund. This guide is a work in progress, and all are welcome to contribute. The complete source for this book is available on github; full instructions on how to contribute are available in the README. "],
["chapter-3-data-visualisation.html", "Chapter 3 - Data Visualisation 3.2 - First Steps 3.3 - Aesthetic Mappings 3.5 - Facets 3.6 - Geometric Objects 3.7 - Statistical Transformations 3.8 - Position Adjustments 3.9 - Coordinate Systems", " Chapter 3 - Data Visualisation Load the libraries needed for these exercises. library(tidyverse) library(maps) 3.2 - First Steps Problem 1 Run ggplot(data = mpg). What do you see? The initial ggplot() call creates a a blank plot without any aesthetics. ggplot(data = mpg) Problem 2 How many rows are in mpg? How many columns? Use the nrow() and ncol() functions from base to determine that there are 234 rows and 11 columns in the mpg data set. nrow(mpg) ## [1] 234 ncol(mpg) ## [1] 11 Problem 3 What does the drv variable describe? Read the help for ?mpg to find out. The variable drv describes the drive of the vehicle: f = front-wheel drive, r = rear wheel drive, 4 = 4wd. Problem 4 Make a scatter plot of hwy vs cyl. Set hwy and cyl as the x and y variables within aes(), and use geom_point() to create a scatterplot. ggplot(data = mpg, mapping = aes(x = cyl, y = hwy)) + geom_point() Problem 5 What happens if you make a scatter plot of class vs drv? Why is the plot not useful? Since class and drv are categorical variables, there isn’t much of a meaningful relationship in the scatter plot. ggplot(data = mpg, mapping = aes(x = class, y = drv)) + geom_point() 3.3 - Aesthetic Mappings Problem 1 What’s gone wrong with this code? Why are the points not blue? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;)) To set an aesthetic manually, it must go outside of aes(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) Problem 2 Which variables in mpg are categorical? Which variables are continuous? (Hint: type ?mpg to read the documentation for the data set). How can you see this information when you run mpg? Use str() to see the structure of a dataset. str(mpg) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 234 obs. of 11 variables: ## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... Problem 3 Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables? Continuous variables will use a gradient to scale color and size, but will throw an error when applied to shape. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ)) + geom_point() ggplot(data = mpg, mapping = aes(x = cty, y = hwy, size = displ)) + geom_point() p &lt;- ggplot(data = mpg, mapping = aes(x = cty, y = hwy, shape = displ)) + geom_point() Problem 4 What happens if you map the same variable to multiple aesthetics? Mapping displ to color and size results in the following graph. Not necessarily helpful, but two ways of displaying the some variation. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ, size = displ)) + geom_point() Problem 5 What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point) The stroke aesthetic will modify the width of the border of a shape. Taking the example from the ggplot2 documentation: ggplot(data = mtcars, mapping = aes(x = wt, y = mpg)) + geom_point(shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 5, stroke = 5) Problem 6 What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ &lt; 5)? In this case the condition passed to color returns a boolean that will map to color. ggplot(data = mtcars, mapping = aes(wt, mpg, color = disp &lt; 100)) + geom_point() 3.5 - Facets Problem 1 What happens if you facet on a continuous variable? The facet_wrap feature will still produce plots for each unique value, but the result is not necessarily helpful. ggplot(data = mtcars, mapping = aes(disp, mpg)) + geom_point() + facet_wrap(~ wt) Problem 2 What do the empty cells in plot with facet_grid(drv ~ cyl) mean? How do they relate to this plot? Empty cells occur when there are no observations within a specific combination of facet variables. For instance, in the given plot there are no vehicles with 4wd and 5 cylinders, which matches the empty cell with facet_grid(drv ~ cyl). ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = cyl)) Problem 3 What plots does the following code make? What does . do? In the first example, using . creates a facet_grid() plot without a column variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ .) This can be easier than trying to hack together a similar plot using facet_wrap(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ drv, nrow = n_distinct(mpg$drv)) The . can also be used to make a facet_grid() while omitting a row variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl) Problem 4 Take the first faceted plot in this section. What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset? Faceting can make it easier to see the variation by class than using the color aesthetic, but can be unwieldy when the number of distinct values in class is large. For a larger dataset, faceting may be necessary, as the increased number of points may make it difficult to see a variation by color. Compare the following plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) Problem 5 Read ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments? The nrow and ncol arguments allow you to control the number of rows or columns in the panel. There are a number of other arguments in facet_wrap(): * scales: can fix scales or allow them to vary * shrink: shrink scales to fit output of statistics, not raw data * labeller: takes one data frame of labels and returns a list or data frame of character vectors * as.table: display facets as a table or a plot * switch: flip the labels * drop: drop unused factor lebels * dir: control direction of the panel * strip.position: control where to place the labels The facet_grid() function has nrow and ncol predefined by the faceting variables. Problem 6 When using facet_grid() you should usually put the variable with more unique levels in the columns. Why? This will expand the panel vertically, making it easier to scroll through the grid. Compare the following two plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(trans ~ drv) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ trans) 3.6 - Geometric Objects Problem 1 What geom would you use to draw a line chart? A boxplot? A histogram? An area chart? Use geom_line() to draw a line chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line() Use geom_boxplot() to create a boxplot. ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() Use geom_histogram() to create a histogram. ggplot(data = mpg, mapping = aes(x = hwy)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. And use geom_area() to create an area chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_area() Problem 2 Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions. Be sure to think through the initial ggplot call and consider what will be passed to geom_point() and geom_smooth(). ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 3 What does show.legend = FALSE do? What happens if you remove it? Why do you think I used it earlier in the chapter? The show.legend argument can be used to map a layer to a legend. Setting to FALSE will remove that layer from the plot. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE, show.legend = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; But note that this only works by geom: ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 4 What does the se argument to geom_smooth() do? The se argument controls whether a confidence band is displayed around the smoothed line. Note that the argument is set to TRUE by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; The level argument is used to control the confidence interval, and is set to 0.95 by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(level = 0.9999) ## `geom_smooth()` using method = &#39;loess&#39; Problem 5 Will these two graphs look different? Why/why not? The graphs should look the same, as data and aes are inherited by geom_point() and geom_smooth() in the first example. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; ggplot() + geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; Problem 6 Recreate the R code necessary to generate the following graphs. Be sure to think through how each aes is set and inherited. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, grp = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() 3.7 - Statistical Transformations Problem 1 What is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function? The default geom associated with stat_summary() is pointrange. Recreate the last plot using: ggplot(data = diamonds) + geom_pointrange( mapping = aes(x = cut, y = depth), stat = &#39;summary&#39;, fun.ymin = min, fun.ymax = max, fun.y = median ) Problem 2 What does geom_col() do? How is it different to geom_bar()? From the ggplot2 documentation: geom_bar() makes the height of the bar proportional to the number of cases in each group, while geom_col() will map directly to the data. Make a simple bar chart using geom_bar which will transform the data under the hood: ggplot(mpg, aes(class)) + geom_bar() Or do the transformation manually and map directly using geom_col: mpg %&gt;% group_by(class) %&gt;% count() %&gt;% ggplot(aes(class, n)) + geom_col() Problem 3 Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common? Some examples from the ggplot2 documentation include: geom_bar –&gt; stat_count geom_bin2d –&gt; stat_bin_2d geom_boxplot –&gt; stat_boxplot geom_contour –&gt; stat_contour geom_count –&gt; stat_sum geom_density –&gt; stat_density geom_density_2d –&gt; stat_density_2d geom_histogram –&gt; stat_bin geom_hex –&gt; stat_bin_hex Problem 4 What variables does stat_smooth() compute? What parameters control its behavior? stat_smooth computes the following: y - the predicted value ymin - lower pointwise confidence interval around the mean ymax - upper pointwise confidence interval around the mean se - standard error The behaviour of stat_smooth can be controled using: method to adjust the smoothing method used formula to adjust the smoothing formula used span to adjust the amount of smoothing level to set the confidence level used Problem 5 In our proportion bar chart, we need to set group = 1. Why? In other words what is the problem with these two graphs? The first chart displays a proportion = 1 for all groups. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop..)) While the second plot does something similar, multiplied by the number of categories in color. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..)) geom_bar() will compute prop - the groupwise proportion. So pass in an argument to group for prop to be calculated properly. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1)) ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., fill = color, group = color)) 3.8 - Position Adjustments Problem 1 What is the problem with this plot? How could you improve it? ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() Use geom_jitter() to correct the overplotting in the original. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter() Problem 2 What parameters to geom_jitter() control the amount of jittering? The width and height arguments control the amount of jittering and defaults to 40% of the resolution of the data. So values less than 0.4 will make a graph more compact than the default geom_jitter() and values greater than 0.4 will make the graph more spread out. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.20, height = 0.20) While values greater than 0.4 will make a smoother graph. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.60, height = 0.60) Problem 3 Compare and contrast geom_jitter() with geom_count(). geom_jitter() and geom_count() are both useful when dealing with overplotting. While geom_jitter will add a small amount of noise to each point to spread them out, geom_count will count the number of observations at each (x,y) point, and then map the count. geom_jitter() is equivalent to geom_point(position = 'jitter') geom_count() is equivalent to geom_point(stat = 'sum') ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_count() Problem 4 What’s the default position adjustment for geom_boxplot()? Create a visualisation of the mpg dataset that demonstrates it. The default position adjustment for geom_boxplot() is dodge. ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot() ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot(position = &#39;identity&#39;) 3.9 - Coordinate Systems Problem 1 Turn a stacked bar chart into a pie chart using coord_polar(). From the documentation for coord_polar() - first make a stacked bar chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar() And then turn it into a pie chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar(width = 1) + coord_polar(theta = &#39;y&#39;) Problem 2 What does labs() do? Read the documentation. labs() controls the labels of a plot, axis, or legend. ggplot(mpg, aes(cty, hwy)) + geom_point() + labs(title = &#39;Title&#39;, subtitle = &#39;Subtitle&#39;, caption = &#39;Caption&#39;) Problem 3 What’s the difference between coord_quickmap() and coord_map()? coord_quickmap() preserves straight lines when projecting onto a two dimensional surface and requires less computation. ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_map() ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_quickmap() Problem 4 What does the plot below tell you about the relationship between city and highway mpg? Why is coord_fixed() important? What does geom_abline() do? coord_fixed() (with no arguments) ensures that a unit on the x-axis is the same length as a unit on the y-axis. geom_abline() (with no arguments) adds a reference line with an intercept of 0 and a slope of 1. One can quickly see that every observation in the mpg dataset has better highway than city fuel efficiency. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + geom_abline() + coord_fixed() "],
["chapter-5-data-transformation.html", "Chapter 5 - Data Transformation 5.2 - Filter Rows with filter() 5.3 - Arrange Rows with arrange() 5.4 - Select Columns with select() 5.5 - Add New Variables with mutate() 5.6 - Grouped summaries with summarise() 5.7 - Grouped Mutates (and Filters)", " Chapter 5 - Data Transformation Load the libraries needed for these exercises. library(tidyverse) library(nycflights13) 5.2 - Filter Rows with filter() Problem 1 Find all flights that: Had an arrival delay of two or more hours flights %&gt;% filter(arr_delay &gt;= 120) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 10200 Flew to Houston (IAH or HOU) flights %&gt;% filter(dest %in% c(&#39;IAH&#39;, &#39;HOU&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9313 Were operated by United, American, or Delta flights %&gt;% filter(carrier %in% c(&#39;UA&#39;, &#39;AA&#39;, &#39;DL&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 139504 Departed in summer (July, August, and September) flights %&gt;% filter(month %in% c(7, 8, 9)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 86326 Arrived more than two hours late, but didn’t leave late flights %&gt;% filter(arr_delay &gt;= 120, dep_delay &lt;= 0) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 29 Were delayed by at least an hour, but made up over 30 minutes in flight flights %&gt;% filter(dep_delay &gt;= 60, arr_delay &lt;= dep_delay - 30) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 2074 Departed between midnight and 6am (inclusive) flights %&gt;% filter(dep_time &gt;= 0, dep_time &lt;= 600) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 2 Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges? between() is a shortcut for x &gt;= left &amp; x &lt;= right. We can simplify the last answer to Problem 1 as: flights %&gt;% filter(between(dep_time, 0, 600)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 3 How many flights have a missing dep_time? What other variables are missing? What might these rows represent? We use is.na() to filter the flights with a missing departure time. flights %&gt;% filter(is.na(dep_time)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 8255 Using summary() to see the breakout of the other variables, there appear to be flights that were cancelled. flights %&gt;% filter(is.na(dep_time)) %&gt;% summary() ## year month day dep_time ## Min. :2013 Min. : 1.000 Min. : 1.0 Min. : NA ## 1st Qu.:2013 1st Qu.: 3.000 1st Qu.: 8.0 1st Qu.: NA ## Median :2013 Median : 6.000 Median :12.0 Median : NA ## Mean :2013 Mean : 5.927 Mean :14.6 Mean :NaN ## 3rd Qu.:2013 3rd Qu.: 8.000 3rd Qu.:23.0 3rd Qu.: NA ## Max. :2013 Max. :12.000 Max. :31.0 Max. : NA ## NA&#39;s :8255 ## sched_dep_time dep_delay arr_time sched_arr_time ## Min. : 106 Min. : NA Min. : NA Min. : 1 ## 1st Qu.:1159 1st Qu.: NA 1st Qu.: NA 1st Qu.:1330 ## Median :1559 Median : NA Median : NA Median :1749 ## Mean :1492 Mean :NaN Mean :NaN Mean :1669 ## 3rd Qu.:1855 3rd Qu.: NA 3rd Qu.: NA 3rd Qu.:2049 ## Max. :2359 Max. : NA Max. : NA Max. :2359 ## NA&#39;s :8255 NA&#39;s :8255 ## arr_delay carrier flight tailnum ## Min. : NA Length:8255 Min. : 1 Length:8255 ## 1st Qu.: NA Class :character 1st Qu.:1577 Class :character ## Median : NA Mode :character Median :3535 Mode :character ## Mean :NaN Mean :3063 ## 3rd Qu.: NA 3rd Qu.:4373 ## Max. : NA Max. :6177 ## NA&#39;s :8255 ## origin dest air_time distance ## Length:8255 Length:8255 Min. : NA Min. : 17.0 ## Class :character Class :character 1st Qu.: NA 1st Qu.: 292.0 ## Mode :character Mode :character Median : NA Median : 583.0 ## Mean :NaN Mean : 695.4 ## 3rd Qu.: NA 3rd Qu.: 872.0 ## Max. : NA Max. :4963.0 ## NA&#39;s :8255 ## hour minute time_hour ## Min. : 1.00 Min. : 0.00 Min. :2013-01-01 06:00:00 ## 1st Qu.:11.00 1st Qu.: 5.00 1st Qu.:2013-03-07 07:00:00 ## Median :15.00 Median :27.00 Median :2013-06-12 18:00:00 ## Mean :14.67 Mean :25.61 Mean :2013-06-13 06:42:11 ## 3rd Qu.:18.00 3rd Qu.:42.00 3rd Qu.:2013-08-22 15:30:00 ## Max. :23.00 Max. :59.00 Max. :2013-12-31 20:00:00 ## Problem 4 Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE &amp; NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!) Working through these examples: * Anything to the zero power is 1 * Anything OR TRUE is TRUE * Anything AND FALSE is FALSE These results apply no matter what the LHS side, and so will apply to NA as well. NA ^ 0 ## [1] 1 NA | TRUE ## [1] TRUE NA &amp; FALSE ## [1] FALSE However operations on NA will return NA. NA * 0 is counter intuitive since you would think that anything multiplied by 0 would be 0. NA * 0 ## [1] NA NA ^ 2 ## [1] NA NA + 1 ## [1] NA 5.3 - Arrange Rows with arrange() Problem 1 How could you use arrange() to sort all missing values to the start? (Hint: use is.na()). We can sort missing values using the format: flights %&gt;% arrange(desc(is.na(dep_time))) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 NA 1630 NA NA ## 2 2013 1 1 NA 1935 NA NA ## 3 2013 1 1 NA 1500 NA NA ## 4 2013 1 1 NA 600 NA NA ## 5 2013 1 2 NA 1540 NA NA ## 6 2013 1 2 NA 1620 NA NA ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 2 Sort flights to find the most delayed flights. Find the flights that left earliest. The most delayed flights (by arr_delay) are: flights %&gt;% arrange(desc(arr_delay)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 ## 2 2013 6 15 1432 1935 1137 1607 ## 3 2013 1 10 1121 1635 1126 1239 ## 4 2013 9 20 1139 1845 1014 1457 ## 5 2013 7 22 845 1600 1005 1044 ## 6 2013 4 10 1100 1900 960 1342 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The flights that left earliest (by dep_delay) are: flights %&gt;% arrange(dep_delay) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 12 7 2040 2123 -43 40 ## 2 2013 2 3 2022 2055 -33 2240 ## 3 2013 11 10 1408 1440 -32 1549 ## 4 2013 1 11 1900 1930 -30 2233 ## 5 2013 1 29 1703 1730 -27 1947 ## 6 2013 8 9 729 755 -26 1002 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 3 Sort flights to find the fastest flights. We first calculate average speed in MPH as distance / hours in the air, and sort on the calculated variable. flights %&gt;% mutate(speed = distance / (air_time / 60)) %&gt;% arrange(desc(speed)) %&gt;% select(speed) %&gt;% head() ## # A tibble: 6 x 1 ## speed ## &lt;dbl&gt; ## 1 703.3846 ## 2 650.3226 ## 3 648.0000 ## 4 641.1429 ## 5 591.4286 ## 6 564.0000 Problem 4 Which flights traveled the longest? Which traveled the shortest? The longest flights are: flights %&gt;% arrange(desc(distance)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 857 900 -3 1516 ## 2 2013 1 2 909 900 9 1525 ## 3 2013 1 3 914 900 14 1504 ## 4 2013 1 4 900 900 0 1516 ## 5 2013 1 5 858 900 -2 1519 ## 6 2013 1 6 1019 900 79 1558 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The shortest flights are: flights %&gt;% arrange(distance) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 7 27 NA 106 NA NA ## 2 2013 1 3 2127 2129 -2 2222 ## 3 2013 1 4 1240 1200 40 1333 ## 4 2013 1 4 1829 1615 134 1937 ## 5 2013 1 4 2128 2129 -1 2218 ## 6 2013 1 5 1155 1200 -5 1241 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 5.4 - Select Columns with select() Problem 1 Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights. We can put all the variables directly into our select() statement: flights %&gt;% select(dep_time, dep_delay, arr_time, arr_delay) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 Or this would be a good place to try the starts_with() function: flights %&gt;% select(starts_with(&quot;dep&quot;), starts_with(&quot;arr&quot;)) ## # A tibble: 336,776 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 ## 7 555 -5 913 19 ## 8 557 -3 709 -14 ## 9 557 -3 838 -8 ## 10 558 -2 753 8 ## # ... with 336,766 more rows Or we can try a regex using matches() flights %&gt;% select(matches(&quot;^dep&quot;), matches(&quot;^arr&quot;)) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 Problem 2 What happens if you include the name of a variable multiple times in a select() call? Duplicating a variable within select() will still just return that variable one time: flights %&gt;% select(dep_time, dep_time) %&gt;% head() ## # A tibble: 6 x 1 ## dep_time ## &lt;int&gt; ## 1 517 ## 2 533 ## 3 542 ## 4 544 ## 5 554 ## 6 554 Problem 3 What does the one_of() function do? Why might it be helpful in conjunction with this vector? one_of() allows you select variables from within a character vector. We can pass vars to select everything from the vector: vars &lt;- c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;dep_delay&quot;, &quot;arr_delay&quot;) flights %&gt;% select(one_of(vars)) ## # A tibble: 336,776 x 5 ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 ## 2 2013 1 1 4 20 ## 3 2013 1 1 2 33 ## 4 2013 1 1 -1 -18 ## 5 2013 1 1 -6 -25 ## 6 2013 1 1 -4 12 ## 7 2013 1 1 -5 19 ## 8 2013 1 1 -3 -14 ## 9 2013 1 1 -3 -8 ## 10 2013 1 1 -2 8 ## # ... with 336,766 more rows Problem 4 Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default? select(flights, contains(&quot;TIME&quot;)) %&gt;% head() ## # A tibble: 6 x 6 ## dep_time sched_dep_time arr_time sched_arr_time air_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 830 819 227 ## 2 533 529 850 830 227 ## 3 542 540 923 850 160 ## 4 544 545 1004 1022 183 ## 5 554 600 812 837 116 ## 6 554 558 740 728 150 ## # ... with 1 more variables: time_hour &lt;dttm&gt; contains() contains an argument ignore.case which defaults to TRUE, we can set this to FALSE if needed: select(flights, contains(&quot;TIME&quot;, ignore.case = FALSE)) %&gt;% head() ## # A tibble: 6 x 0 5.5 - Add New Variables with mutate() Problem 1 Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. Use the modular arithmetic operators to break the time into its hours and minute components: flights %&gt;% select(dep_time, sched_dep_time) %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100))) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time sched_dep_time dep_time_cont sched_dep_time_cont ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 517 515 317 315 ## 2 533 529 333 329 ## 3 542 540 342 340 ## 4 544 545 344 345 ## 5 554 600 354 360 ## 6 554 558 354 358 Problem 2 Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it? The issue is that air_time is in minutes, while arr_time and dep_time are not: flights %&gt;% mutate(air_time_derived = arr_time - dep_time) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;int&gt; ## 1 227 313 ## 2 227 317 ## 3 160 381 ## 4 183 460 ## 5 116 258 ## 6 150 186 Instead use the mutate() statement from Problem 1, however the two differ: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), arr_time_cont = ((arr_time %/% 100) * 60 + (arr_time %% 100)), air_time_derived = arr_time_cont - dep_time_cont) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 227 193 ## 2 227 197 ## 3 160 221 ## 4 183 260 ## 5 116 138 ## 6 150 106 Problem 3 Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related? We would expect dep_delay to be the difference between the dep_time and the sched_dep_time. But be sure to convert from time to continuous first: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100)), dep_delay_derived = dep_time_cont - sched_dep_time_cont) %&gt;% select(dep_delay, dep_delay_derived) %&gt;% head() ## # A tibble: 6 x 2 ## dep_delay dep_delay_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 2 ## 2 4 4 ## 3 2 2 ## 4 -1 -1 ## 5 -6 -6 ## 6 -4 -4 Problem 4 Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank(). We’ll use min_rank() to rank the flights by arr_delay: flights %&gt;% select(arr_delay) %&gt;% mutate(most_delayed = min_rank(-arr_delay)) %&gt;% filter(most_delayed &lt;= 10) %&gt;% arrange(most_delayed) ## # A tibble: 10 x 2 ## arr_delay most_delayed ## &lt;dbl&gt; &lt;int&gt; ## 1 1272 1 ## 2 1127 2 ## 3 1109 3 ## 4 1007 4 ## 5 989 5 ## 6 931 6 ## 7 915 7 ## 8 895 8 ## 9 878 9 ## 10 875 10 Problem 5 What does 1:3 + 1:10 return? Why? We get an error because 1:3 + 1:10 are not multiples of each other: 1:3 + 1:10 ## Warning in 1:3 + 1:10: longer object length is not a multiple of shorter ## object length ## [1] 2 4 6 5 7 9 8 10 12 11 Think through what is happening under the hood. This operation is recycling the shorter vector: 1 + 1 2 + 2 3 + 3 4 + 1 5 + 2 6 + 3 7 + 1 8 + 2 9 + 3 10 + 1 - error because 1:3 has not been fully cycled through So the following will not return an error: 1:3 + 1:12 ## [1] 2 4 6 5 7 9 8 10 12 11 13 15 Problem 6 What trigonometric functions does R provide? R has the following trig functions within base: cos(x) sin(x) tan(x) acos(x) asin(x) atan(x) atan2(y, x) cospi(x) sinpi(x) tanpi(x) Note that angles are given in radians: cos(pi * 0.25) ## [1] 0.7071068 # cospi(x) is equivalent to cos(pi * x) cospi(0.25) ## [1] 0.7071068 5.6 - Grouped summaries with summarise() Problem 1 Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios: A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(fifteen_early = mean(arr_delay &lt;= -15, na.rm = TRUE), fifteen_late = mean(arr_delay &gt;= 15, na.rm = TRUE)) %&gt;% filter(fifteen_early == 0.50, fifteen_late == 0.50) ## # A tibble: 21 x 3 ## flight fifteen_early fifteen_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 107 0.5 0.5 ## 2 2072 0.5 0.5 ## 3 2366 0.5 0.5 ## 4 2500 0.5 0.5 ## 5 2552 0.5 0.5 ## 6 3495 0.5 0.5 ## 7 3505 0.5 0.5 ## 8 3518 0.5 0.5 ## 9 3544 0.5 0.5 ## 10 3651 0.5 0.5 ## # ... with 11 more rows A flight is always 10 minutes late. flights %&gt;% group_by(flight) %&gt;% summarise(ten_late = mean(arr_delay == 10, na.rm = TRUE)) %&gt;% filter(ten_late == 1.00) ## # A tibble: 5 x 2 ## flight ten_late ## &lt;int&gt; &lt;dbl&gt; ## 1 2254 1 ## 2 3656 1 ## 3 3785 1 ## 4 3880 1 ## 5 5854 1 A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(thirty_early = mean(arr_delay &lt;= -30, na.rm = TRUE), thirty_late = mean(arr_delay &gt;= 30, na.rm = TRUE)) %&gt;% filter(thirty_early == 0.50, thirty_late == 0.50) ## # A tibble: 3 x 3 ## flight thirty_early thirty_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3651 0.5 0.5 ## 2 3916 0.5 0.5 ## 3 3951 0.5 0.5 99% of the time a flight is on time. 1% of the time it’s 2 hours late. flights %&gt;% group_by(flight) %&gt;% summarise(on_time = mean(arr_delay &lt;= 0, na.rm = TRUE), late = mean(arr_delay &gt;= 120, na.rm = TRUE)) %&gt;% filter(on_time == 0.99, late == 0.01) ## # A tibble: 0 x 3 ## # ... with 3 variables: flight &lt;int&gt;, on_time &lt;dbl&gt;, late &lt;dbl&gt; Problem 2 Come up with another approach that will give you the same output as not_cancelled %&gt;% count(dest) and not_cancelled %&gt;% count(tailnum, wt = distance) (without using count()). First setup the not_cancelled data set. not_cancelled &lt;- flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) The first chunk of code gives us the following output: not_cancelled %&gt;% count(dest) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows We can replicate this without using count() by doing a group_by() on dest: not_cancelled %&gt;% group_by(dest) %&gt;% summarise(n = n()) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows The second chunk of code gives us: not_cancelled %&gt;% count(tailnum, wt = distance) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Again we can avoid using count by doing a group_by() on tailnum. Since wt = distance gives the total number of miles flown, we use sum() instead: not_cancelled %&gt;% group_by(tailnum) %&gt;% summarise(n = sum(distance)) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Problem 3 Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column? arr_delay is the more important of the two columns - filtering on arr_delay alone will give the same subset: flights %&gt;% summarise(suboptimal = sum(is.na(dep_delay) | is.na(arr_delay)), optimal = sum(is.na(arr_delay))) ## # A tibble: 1 x 2 ## suboptimal optimal ## &lt;int&gt; &lt;int&gt; ## 1 9430 9430 Problem 4 Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay? There is a generally positive trend between average delay and the proportion of cancelled flights, with a couple of outliers. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(avg_delay, cancelled)) + geom_point() A lot of flights were cancelled on February 8th and 9th, although the average delays those days were not that large - a snowstorm hit the region that weekend, with a lot of flights preemptively cancelled. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(cancelled)) %&gt;% head() ## # A tibble: 6 x 3 ## date cancelled avg_delay ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013-02-09 0.5745614 6.639175 ## 2 2013-02-08 0.5107527 24.228571 ## 3 2013-05-23 0.2348178 61.970899 ## 4 2013-09-12 0.2288306 58.912418 ## 5 2013-12-10 0.2163309 44.508796 ## 6 2013-12-14 0.1893064 46.397504 Problem 5 Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %&gt;% group_by(carrier, dest) %&gt;% summarise(n()) At first glance, Frontier and AirTran seem to have the worst delays. flights %&gt;% group_by(carrier) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(median_delay)) ## # A tibble: 16 x 2 ## carrier median_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 F9 6 ## 2 FL 5 ## 3 EV -1 ## 4 MQ -1 ## 5 YV -2 ## 6 B6 -3 ## 7 WN -3 ## 8 UA -6 ## 9 US -6 ## 10 9E -7 ## 11 OO -7 ## 12 DL -8 ## 13 AA -9 ## 14 VX -9 ## 15 HA -13 ## 16 AS -17 We can try to get a better sense of bad airlines vs bad airports by grouping by both, but this will be thrown off by carrier-dest combinations that occur infrequently. flights %&gt;% group_by(carrier, dest) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(carrier, median_delay)) + geom_boxplot() ## Warning: Removed 2 rows containing non-finite values (stat_boxplot). Problem 6 What does the sort argument to count() do. When might you use it? The sort argument will arrange count() in descending order. If we quickly wanted to find the most popular destinations, we could do: flights %&gt;% group_by(dest) %&gt;% count(sort = TRUE) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: dest [6] ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ORD 17283 ## 2 ATL 17215 ## 3 LAX 16174 ## 4 BOS 15508 ## 5 MCO 14082 ## 6 CLT 14064 5.7 - Grouped Mutates (and Filters) Problem 1 Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping. Problem 2 Which plane (tailnum) has the worst on-time record? We do a familiar group_by()-summarise() to calculate the proportion of flights with an arr_delay less than or equal to 0, and then apply a filter to see the on-time performance of planes with more than twenty flights. flights %&gt;% group_by(tailnum) %&gt;% summarise(flights = n(), on_time = mean(arr_delay &lt;= 0, na.rm = TRUE)) %&gt;% select(tailnum, flights, on_time) %&gt;% filter(flights &gt; 20) %&gt;% arrange(on_time) %&gt;% head() ## # A tibble: 6 x 3 ## tailnum flights on_time ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 N988AT 37 0.2000000 ## 2 N983AT 32 0.2500000 ## 3 N980AT 47 0.2553191 ## 4 N969AT 34 0.2647059 ## 5 N932AT 30 0.2666667 ## 6 N149AT 22 0.2727273 Problem 3 What time of day should you fly if you want to avoid delays as much as possible? It appears that flights later in day have a greater chance of being delayed than those early in the morning. flights %&gt;% group_by(hour) %&gt;% filter(!is.na(dep_delay)) %&gt;% summarise(delayed = mean(dep_delay &gt; 0, na.rm = TRUE)) %&gt;% ggplot(aes(x = hour, y = delayed)) + geom_col() Problem 4 For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination. A grouped mutate comes in handy here, as we can first calculate the total minutes of delay for each destination and then use that value to compute the proportion of the total delay attributable to each flight. flights %&gt;% group_by(dest) %&gt;% filter(arr_delay &gt; 0) %&gt;% mutate(total_delay = sum(arr_delay), prop_delay = arr_delay / sum(arr_delay)) %&gt;% select(dest, flight, total_delay, prop_delay) %&gt;% arrange(desc(total_delay)) %&gt;% head() ## # A tibble: 6 x 4 ## # Groups: dest [1] ## dest flight total_delay prop_delay ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ATL 4650 300299 3.996017e-05 ## 2 ATL 1547 300299 1.665007e-05 ## 3 ATL 346 300299 5.661025e-05 ## 4 ATL 4654 300299 1.998009e-05 ## 5 ATL 347 300299 6.660029e-06 ## 6 ATL 4876 300299 3.663016e-05 Problem 5 Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag() explore how the delay of a flight is related to the delay of the immediately preceding flight. First group by origin and the perform a mutate() with lag() to get the delay of the immediately preceding flight. We then use summarise to get the correlation between the delay and lagged delay for each airport. flights %&gt;% group_by(origin) %&gt;% filter(!is.na(dep_delay)) %&gt;% arrange(year, month, day, hour, minute) %&gt;% mutate(lag_delay = lag(dep_delay)) %&gt;% summarise(delay_correlation = cor(dep_delay, lag_delay, use = &#39;complete.obs&#39;)) ## # A tibble: 3 x 2 ## origin delay_correlation ## &lt;chr&gt; &lt;dbl&gt; ## 1 EWR 0.2648892 ## 2 JFK 0.2422018 ## 3 LGA 0.3021787 Problem 6 Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air? A grouped mutate is helpful here, as we can calculate the mean air time by destination and then immediately use that value to calculate a flight’s deviation from it. Note that we filtered out flights less than an hour long. deviation &lt;- flights %&gt;% group_by(dest) %&gt;% filter(!is.na(air_time)) %&gt;% mutate(mean_air_time = mean(air_time), deviation = (air_time - mean_air_time) / mean_air_time) %&gt;% filter(mean_air_time &gt; 60) %&gt;% arrange(deviation) %&gt;% select(air_time, mean_air_time, deviation, origin, dest) deviation %&gt;% head() ## # A tibble: 6 x 5 ## # Groups: dest [6] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 65 112.93045 -0.4244245 LGA ATL ## 2 55 93.39494 -0.4111030 EWR GSP ## 3 70 114.38215 -0.3880164 EWR BNA ## 4 93 150.57368 -0.3823622 EWR MSP ## 5 62 95.96510 -0.3539318 EWR CVG ## 6 40 61.45885 -0.3491580 LGA PIT deviation %&gt;% tail() ## # A tibble: 6 x 5 ## # Groups: dest [5] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 147 86.15072 0.7063118 EWR CLT ## 2 198 115.58813 0.7129786 EWR ORD ## 3 185 106.26630 0.7409093 EWR SDF ## 4 138 70.88533 0.9468063 JFK RDU ## 5 170 84.83202 1.0039602 LGA DTW ## 6 170 84.83202 1.0039602 JFK DTW Problem 7 Find all destinations that are flown by at least two carriers. Use that information to rank the carriers. We first use a group_by with mutate() and filter() to subset the destinations serviced by at least 2 carriers, followed by a second group_by to rank the carriers by total destinations served. We also merge data from the airlines data set to get the full carrier names. ExpressJet and Endeavor Air are regional airlines which operate as American Eagle, United Express, and Delta Connection. flights %&gt;% group_by(dest) %&gt;% mutate(carriers = n_distinct(carrier)) %&gt;% filter(carriers &gt;= 2) %&gt;% group_by(carrier) %&gt;% summarise(destinations = n_distinct(dest)) %&gt;% arrange(desc(destinations)) %&gt;% left_join(airlines) %&gt;% select(carrier, name, destinations) %&gt;% head() ## Joining, by = &quot;carrier&quot; ## # A tibble: 6 x 3 ## carrier name destinations ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 EV ExpressJet Airlines Inc. 51 ## 2 9E Endeavor Air Inc. 48 ## 3 UA United Air Lines Inc. 42 ## 4 DL Delta Air Lines Inc. 39 ## 5 B6 JetBlue Airways 35 ## 6 AA American Airlines Inc. 19 Problem 8 For each plane, count the number of flights before the first delay of greater than 1 hour. First group_by() tailnum and then apply a filter() using the cumall window function to subset everything before the first delay of more than 1 hour. flights %&gt;% arrange(year, month, day, hour, minute) %&gt;% group_by(tailnum) %&gt;% filter(cumall(dep_delay &lt;= 60)) %&gt;% count() %&gt;% arrange(desc(n)) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: tailnum [6] ## tailnum n ## &lt;chr&gt; &lt;int&gt; ## 1 N954UW 206 ## 2 N952UW 163 ## 3 N957UW 142 ## 4 N5FAAA 117 ## 5 N38727 99 ## 6 N3742C 98 "],
["chapter-7-exploratory-data-analysis.html", "Chapter 7 - Exploratory Data Analysis 7.3 - Variation 7.4 - Missing Values", " Chapter 7 - Exploratory Data Analysis Load the libraries needed for these exercises. library(tidyverse) 7.3 - Variation Problem 1 Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth. The distribution of x, y, and z generally seems to fall between 0 and 10mm, although the distributions of y and z both have much longer tails. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = x), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = z), binwidth = 0.5) Problem 2 Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.) The price of diamonds appears to peak around $2000, followed by a long tail for the much more expensive diamonds. Narrowing the value of binwidth shows that some values are not very populated. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 1000) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 500) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 100) Problem 3 How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference? People may prefer to buy a diamond that is a full carat rather than almost a carat large. There appears to be significant rounding in the data set: diamonds %&gt;% filter(between(carat, 0.99, 1.00)) %&gt;% group_by(carat) %&gt;% count() ## # A tibble: 2 x 2 ## # Groups: carat [2] ## carat n ## &lt;dbl&gt; &lt;int&gt; ## 1 0.99 23 ## 2 1.00 1558 Problem 4 Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows? Compare and contrast the following three graphs: while coord_cartesian() will preserve data, ylim() will drop rows that fall outside of the limits. ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0,60)) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + ylim(0,60) ## Warning: Removed 11 rows containing missing values (geom_bar). 7.4 - Missing Values Problem 1 What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference? Missing values are plotted in a bar chart but not a histogram. Remember that histograms are generally used to display numeric data, while bar charts are used for categorical data. Missing values can be considered another category to plot in a bar chart, but there is not necessarily an intuitive way to place missing values in a histogram. diamonds %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1610 rows containing non-finite values (stat_bin). diamonds %&gt;% mutate(cut = as.character(cut)) %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_bar() Problem 2 What does na.rm = TRUE do in mean() and sum()? Setting na.rm = TRUE will remove missing values before executing the function. x &lt;- c(1, 2, 3, NA) mean(x) ## [1] NA mean(x, na.rm = TRUE) ## [1] 2 "],
["chapter-10-tibbles.html", "Chapter 10 - Tibbles 10.5 - Exercises", " Chapter 10 - Tibbles Load the libraries needed for these exercises. library(tidyverse) 10.5 - Exercises Problem 1 How can you tell if an object is a tibble? (Hint: try printing mtcars, which is a regular data frame). Use the is.tibble() function to determine if an object is a tibble. A tibble will also have a heading if printed to the console. is.tibble(mtcars) ## [1] FALSE is.tibble(diamonds) ## [1] TRUE diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.20 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4.00 4.05 2.39 ## # ... with 53,930 more rows Problem 2 Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration? A data frame will attempt to auto-complete, while a tibble will not: df &lt;- data.frame(abc = 1, xyz = &quot;a&quot;) tib &lt;- tibble(abc = 1, xyz = &quot;a&quot;) df$x ## [1] a ## Levels: a tib$x ## Warning: Unknown or uninitialised column: &#39;x&#39;. ## NULL Data frames will sometimes simplify: is.data.frame(df[, &quot;xyz&quot;]) ## [1] FALSE is.tibble(tib[, &quot;xyz&quot;]) ## [1] TRUE Tibble will display useful information on the data: df[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## abc xyz ## 1 1 a tib[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## # A tibble: 1 x 2 ## abc xyz ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a Problem 3 If you have the name of a variable stored in an object, e.g. var &lt;- &quot;mpg&quot;, how can you extract the reference variable from a tibble? Use [] to extract the variable and [[]] to extract the vector: var &lt;- &#39;mpg&#39; as.tibble(mtcars)[var] ## # A tibble: 32 x 1 ## mpg ## &lt;dbl&gt; ## 1 21.0 ## 2 21.0 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ... with 22 more rows as.tibble(mtcars)[[var]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 ## [15] 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 ## [29] 15.8 19.7 15.0 21.4 Problem 4 Practice referring to non-syntactic names in the following data frame by: Extracting the variable called 1. annoying &lt;- tibble( `1` = 1:10, `2` = `1` * 2 + rnorm(length(`1`)) ) annoying %&gt;% select(`1`) ## # A tibble: 10 x 1 ## `1` ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 7 ## 8 8 ## 9 9 ## 10 10 Plotting a scatterplot of 1 vs 2. ggplot(annoying, aes(`1`, `2`)) + geom_point() Creating a new column called 3 which is 2 divided by 1. annoying &lt;- annoying %&gt;% mutate(`3` = `2` / `1`) Renaming the columns to one, two and three. annoying %&gt;% select(one = `1`, two = `2`, three = `3`) ## # A tibble: 10 x 3 ## one two three ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3.005085 3.005085 ## 2 2 3.253603 1.626801 ## 3 3 6.455019 2.151673 ## 4 4 8.217199 2.054300 ## 5 5 11.002126 2.200425 ## 6 6 13.575450 2.262575 ## 7 7 13.464341 1.923477 ## 8 8 17.507758 2.188470 ## 9 9 17.517832 1.946426 ## 10 10 20.747170 2.074717 Problem 5 What does tibble::enframe() do? When might you use it? enframe() can be used to convert a vector or list to a tibble: enframe(c(a = 5, b = 10)) ## # A tibble: 2 x 2 ## name value ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 5 ## 2 b 10 Problem 6 What option controls how many additional column names are printed at the footer of a tibble? The tibble.max_extra_cols option controls this behavior, with a default of 100. "],
["chapter-11-data-import.html", "Chapter 11 - Data Import 11.2 - Getting Started 11.3 - Parsing a Vector", " Chapter 11 - Data Import Load the libraries needed for these exercises. library(tidyverse) 11.2 - Getting Started Problem 1 What function would you use to read a file where fields were separated with “|”? Use read_delim(), using | as the delimiter: data &lt;- &#39;a|b|c\\n1|2|3&#39; read_delim(data, delim = &#39;|&#39;) ## # A tibble: 1 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 Problem 2 Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common? read_csv() and read_tsv() are essentially just read_delim with the delimiter preset to either a comma or a tab. All of their other arguments are the same. Problem 3 What are the most important arguments to read_fwf()? The most important argument to read_fwf() is col_positions, as this determines how data is read: fwf_sample &lt;- readr_example(&quot;fwf-sample.txt&quot;) cat(read_lines(fwf_sample)) ## John Smith WA 418-Y11-4111 Mary Hartford CA 319-Z19-4341 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA 418-Y11-4111 ## 2 Mary Hartford CA 319-Z19-4341 ## 3 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(5, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA ## 2 Mary Hartford CA ## 3 Evan Nolan IL Problem 4 Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like &quot; or '. By convention, read_csv() assumes that the quoting character will be &quot;, and if you want to change it you’ll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame? &quot;x,y\\n1,'a,b'&quot; Since read_delim() must be used instead of read_csv(), the delimiter must be set. The quote argument can be set to a single quote instead of a double quote: data &lt;- &quot;x,y\\n1,&#39;a,b&#39;&quot; read_delim(data, delim = &#39;,&#39;, quote = &#39;\\&#39;&#39;) ## # A tibble: 1 x 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a,b Problem 5 Identify what is wrong with each of the following inline CSV files. What happens when you run the code? There are more data than columns, which results in a parsing failure. The extra data are dropped from the data frame: read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 2 columns 3 columns literal data file 2 2 &lt;NA&gt; 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 4 5 There is too little data in row 2 and too much data in row 3 - row 2 is filled in with a missing value while row 3 drops data: read_csv(&quot;a,b,c\\n1,2\\n1,2,3,4&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 3 columns 2 columns literal data file 2 2 &lt;NA&gt; 3 columns 4 columns literal data ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 NA ## 2 1 2 3 There are two variables but only one data point - b is filled in with a missing value: read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 a closing quote at end of file literal data file 2 1 &lt;NA&gt; 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; Appears that the header was entered twice, so the data are parsed as character instead of a string. Or if the goal here was to enter a missing value NA, note that the n was processed as a new line \\n. read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b read_csv(&quot;a,b\\n1,2\\nna,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 na b read_csv() has a delimiter set to ,, use read_csv2() instead: read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv2(&quot;a;b\\n1;3&quot;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 3 11.3 - Parsing a Vector Problem 1 What are the most important arguments to locale()? The date_names argument provides useful defaults for a locale() object: dutch &lt;- locale(&#39;nl&#39;) japanese &lt;- locale(&#39;ja&#39;) str(dutch) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;januari&quot; &quot;februari&quot; &quot;maart&quot; &quot;april&quot; ... ## ..$ mon_ab: chr [1:12] &quot;jan.&quot; &quot;feb.&quot; &quot;mrt.&quot; &quot;apr.&quot; ... ## ..$ day : chr [1:7] &quot;zondag&quot; &quot;maandag&quot; &quot;dinsdag&quot; &quot;woensdag&quot; ... ## ..$ day_ab: chr [1:7] &quot;zo&quot; &quot;ma&quot; &quot;di&quot; &quot;wo&quot; ... ## ..$ am_pm : chr [1:2] &quot;a.m.&quot; &quot;p.m.&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; str(japanese) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ mon_ab: chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ day : chr [1:7] &quot;日曜日&quot; &quot;月曜日&quot; &quot;火曜日&quot; &quot;水曜日&quot; ... ## ..$ day_ab: chr [1:7] &quot;日&quot; &quot;月&quot; &quot;火&quot; &quot;水&quot; ... ## ..$ am_pm : chr [1:2] &quot;午前&quot; &quot;午後&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Be sure to read the full documentation for locale(). Common data import issues can probably be solved with decimal_mark, grouping_mark, and/or encoding. Problem 2 What happens if you try and set decimal_mark and grouping_mark to the same character? What happens to the default value of grouping_mark when you set decimal_mark to “,”? What happens to the default value of decimal_mark when you set the grouping_mark to “.”? locale() requires that decimal_mark and grouping_mark be different: x &lt;- locale(decimal_mark = &#39;.&#39;, grouping_mark = &#39;.&#39;) ## Error: `decimal_mark` and `grouping_mark` must be different Setting decimal_mark to , will automatically update grouping_mark to .. Similarly setting grouping_mark to . will automatically update decimal_mark to ,: x &lt;- locale(decimal_mark = &#39;,&#39;) x$grouping_mark ## [1] &quot;.&quot; y &lt;- locale(grouping_mark = &#39;.&#39;) y$decimal_mark ## [1] &quot;,&quot; Problem 3 I didn’t discuss the date_format and time_format options to locale(). What do they do? Construct an example that shows when they might be useful. A specific date_format and time_format structure can be specified in a locale(). This can be useful for formatting data with non-standard formatting: parse_date(&#39;June/7/90&#39;, locale = locale(date_format = &#39;%B/%d/%y&#39;)) ## [1] &quot;1990-06-07&quot; parse_time(&#39;1:15PM&#39;, locale = locale(time_format = &#39;%I:%M%p&#39;)) ## 13:15:00 Problem 4 If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly. Create a locale with the time zone updated: str(locale(tz = &#39;US/Eastern&#39;)) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;January&quot; &quot;February&quot; &quot;March&quot; &quot;April&quot; ... ## ..$ mon_ab: chr [1:12] &quot;Jan&quot; &quot;Feb&quot; &quot;Mar&quot; &quot;Apr&quot; ... ## ..$ day : chr [1:7] &quot;Sunday&quot; &quot;Monday&quot; &quot;Tuesday&quot; &quot;Wednesday&quot; ... ## ..$ day_ab: chr [1:7] &quot;Sun&quot; &quot;Mon&quot; &quot;Tue&quot; &quot;Wed&quot; ... ## ..$ am_pm : chr [1:2] &quot;AM&quot; &quot;PM&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;US/Eastern&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Problem 5 What’s the difference between read_csv() and read_csv2()? read_csv() has a delimiter set to , while read_csv2 is set to ;, as some countries use , as the decimal_mark: read_csv(&#39;a,b\\n1,2&#39;) ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 read_csv2(&#39;a;b\\n1;2&#39;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 Problem 6 What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out. See this list of common encodings (via Wikipedia). Problem 7 Generate the correct format string to parse each of the following dates and times: d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 t1 &lt;- &quot;1705&quot; t2 &lt;- &quot;11:15:10.12 PM&quot; Build up a datetime format using the pieces described in the chapter: parse_date(d1, format = &#39;%B %d, %Y&#39;) ## [1] &quot;2010-01-01&quot; parse_date(d2, format = &#39;%Y-%b-%d&#39;) ## [1] &quot;2015-03-07&quot; parse_date(d3, format = &#39;%d-%b-%Y&#39;) ## [1] &quot;2017-06-06&quot; parse_date(d4, format = &#39;%B %d (%Y)&#39;) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; parse_date(d5, format = &#39;%m/%d/%y&#39;) ## [1] &quot;2014-12-30&quot; parse_time(t1, format = &#39;%H%M&#39;) ## 17:05:00 parse_time(t2, format = &#39;%I:%M:%OS %p&#39;) ## 23:15:10.12 "]
]
