[
["index.html", "R for Data Science Solution Set Preface Acknowledgements", " R for Data Science Solution Set Preface This is a solution guide to the exercises in R for Data Science by Hadley Wickham and Garret Grolemund. This guide is a work in progress, and all are welcome to contribute. The complete source for this book is available on github; full instructions on how to contribute are available in the README. Acknowledgements A couple different resources were consulted at various points in drafting this solution set (usually to double-check an answer when the question was somewhat ambiguous). Full credit and thanks go to the following guides, which are great resources if you would like a different take on a question: https://jrnold.github.io/r4ds-exercise-solutions/ http://cfss.uchicago.edu/r4ds_solutions.html "],
["chapter-3-data-visualisation.html", "Chapter 3 - Data Visualisation 3.2 - First Steps 3.3 - Aesthetic Mappings 3.5 - Facets 3.6 - Geometric Objects 3.7 - Statistical Transformations 3.8 - Position Adjustments 3.9 - Coordinate Systems", " Chapter 3 - Data Visualisation Load the libraries needed for these exercises. library(tidyverse) library(maps) 3.2 - First Steps Problem 1 Run ggplot(data = mpg). What do you see? The initial ggplot() call creates a a blank plot without any aesthetics. ggplot(data = mpg) Problem 2 How many rows are in mpg? How many columns? Use the nrow() and ncol() functions from base to determine that there are 234 rows and 11 columns in the mpg data set. nrow(mpg) ## [1] 234 ncol(mpg) ## [1] 11 Problem 3 What does the drv variable describe? Read the help for ?mpg to find out. The variable drv describes the drive of the vehicle: f = front-wheel drive, r = rear wheel drive, 4 = 4wd. Problem 4 Make a scatter plot of hwy vs cyl. Set hwy and cyl as the x and y variables within aes(), and use geom_point() to create a scatterplot. ggplot(data = mpg, mapping = aes(x = cyl, y = hwy)) + geom_point() Problem 5 What happens if you make a scatter plot of class vs drv? Why is the plot not useful? Since class and drv are categorical variables, there isn’t much of a meaningful relationship in the scatter plot. ggplot(data = mpg, mapping = aes(x = class, y = drv)) + geom_point() 3.3 - Aesthetic Mappings Problem 1 What’s gone wrong with this code? Why are the points not blue? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;)) To set an aesthetic manually, it must go outside of aes(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) Problem 2 Which variables in mpg are categorical? Which variables are continuous? (Hint: type ?mpg to read the documentation for the data set). How can you see this information when you run mpg? Use str() to see the structure of a dataset. str(mpg) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 234 obs. of 11 variables: ## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... Problem 3 Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables? Continuous variables will use a gradient to scale color and size, but will throw an error when applied to shape. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ)) + geom_point() ggplot(data = mpg, mapping = aes(x = cty, y = hwy, size = displ)) + geom_point() p &lt;- ggplot(data = mpg, mapping = aes(x = cty, y = hwy, shape = displ)) + geom_point() Problem 4 What happens if you map the same variable to multiple aesthetics? Mapping displ to color and size results in the following graph. Not necessarily helpful, but two ways of displaying the some variation. ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = displ, size = displ)) + geom_point() Problem 5 What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point) The stroke aesthetic will modify the width of the border of a shape. Taking the example from the ggplot2 documentation: ggplot(data = mtcars, mapping = aes(x = wt, y = mpg)) + geom_point(shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 5, stroke = 5) Problem 6 What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ &lt; 5)? In this case the condition passed to color returns a boolean that will map to color. ggplot(data = mtcars, mapping = aes(wt, mpg, color = disp &lt; 100)) + geom_point() 3.5 - Facets Problem 1 What happens if you facet on a continuous variable? The facet_wrap feature will still produce plots for each unique value, but the result is not necessarily helpful. ggplot(data = mtcars, mapping = aes(disp, mpg)) + geom_point() + facet_wrap(~ wt) Problem 2 What do the empty cells in plot with facet_grid(drv ~ cyl) mean? How do they relate to this plot? Empty cells occur when there are no observations within a specific combination of facet variables. For instance, in the given plot there are no vehicles with 4wd and 5 cylinders, which matches the empty cell with facet_grid(drv ~ cyl). ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = cyl)) Problem 3 What plots does the following code make? What does . do? In the first example, using . creates a facet_grid() plot without a column variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ .) This can be easier than trying to hack together a similar plot using facet_wrap(). ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ drv, nrow = n_distinct(mpg$drv)) The . can also be used to make a facet_grid() while omitting a row variable. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl) Problem 4 Take the first faceted plot in this section. What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset? Faceting can make it easier to see the variation by class than using the color aesthetic, but can be unwieldy when the number of distinct values in class is large. For a larger dataset, faceting may be necessary, as the increased number of points may make it difficult to see a variation by color. Compare the following plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) Problem 5 Read ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments? The nrow and ncol arguments allow you to control the number of rows or columns in the panel. There are a number of other arguments in facet_wrap(): * scales: can fix scales or allow them to vary * shrink: shrink scales to fit output of statistics, not raw data * labeller: takes one data frame of labels and returns a list or data frame of character vectors * as.table: display facets as a table or a plot * switch: flip the labels * drop: drop unused factor lebels * dir: control direction of the panel * strip.position: control where to place the labels The facet_grid() function has nrow and ncol predefined by the faceting variables. Problem 6 When using facet_grid() you should usually put the variable with more unique levels in the columns. Why? This will expand the panel vertically, making it easier to scroll through the grid. Compare the following two plots: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(trans ~ drv) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ trans) 3.6 - Geometric Objects Problem 1 What geom would you use to draw a line chart? A boxplot? A histogram? An area chart? Use geom_line() to draw a line chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line() Use geom_boxplot() to create a boxplot. ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() Use geom_histogram() to create a histogram. ggplot(data = mpg, mapping = aes(x = hwy)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. And use geom_area() to create an area chart. ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_area() Problem 2 Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions. Be sure to think through the initial ggplot call and consider what will be passed to geom_point() and geom_smooth(). ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 3 What does show.legend = FALSE do? What happens if you remove it? Why do you think I used it earlier in the chapter? The show.legend argument can be used to map a layer to a legend. Setting to FALSE will remove that layer from the plot. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE, show.legend = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; But note that this only works by geom: ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Problem 4 What does the se argument to geom_smooth() do? The se argument controls whether a confidence band is displayed around the smoothed line. Note that the argument is set to TRUE by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; The level argument is used to control the confidence interval, and is set to 0.95 by default. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(show.legend = FALSE) + geom_smooth(level = 0.9999) ## `geom_smooth()` using method = &#39;loess&#39; Problem 5 Will these two graphs look different? Why/why not? The graphs should look the same, as data and aes are inherited by geom_point() and geom_smooth() in the first example. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; ggplot() + geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; Problem 6 Recreate the R code necessary to generate the following graphs. Be sure to think through how each aes is set and inherited. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, grp = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() 3.7 - Statistical Transformations Problem 1 What is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function? The default geom associated with stat_summary() is pointrange. Recreate the last plot using: ggplot(data = diamonds) + geom_pointrange( mapping = aes(x = cut, y = depth), stat = &#39;summary&#39;, fun.ymin = min, fun.ymax = max, fun.y = median ) Problem 2 What does geom_col() do? How is it different to geom_bar()? From the ggplot2 documentation: geom_bar() makes the height of the bar proportional to the number of cases in each group, while geom_col() will map directly to the data. Make a simple bar chart using geom_bar which will transform the data under the hood: ggplot(mpg, aes(class)) + geom_bar() Or do the transformation manually and map directly using geom_col: mpg %&gt;% group_by(class) %&gt;% count() %&gt;% ggplot(aes(class, n)) + geom_col() Problem 3 Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common? Some examples from the ggplot2 documentation include: geom_bar –&gt; stat_count geom_bin2d –&gt; stat_bin_2d geom_boxplot –&gt; stat_boxplot geom_contour –&gt; stat_contour geom_count –&gt; stat_sum geom_density –&gt; stat_density geom_density_2d –&gt; stat_density_2d geom_histogram –&gt; stat_bin geom_hex –&gt; stat_bin_hex Problem 4 What variables does stat_smooth() compute? What parameters control its behavior? stat_smooth computes the following: y - the predicted value ymin - lower pointwise confidence interval around the mean ymax - upper pointwise confidence interval around the mean se - standard error The behaviour of stat_smooth can be controled using: method to adjust the smoothing method used formula to adjust the smoothing formula used span to adjust the amount of smoothing level to set the confidence level used Problem 5 In our proportion bar chart, we need to set group = 1. Why? In other words what is the problem with these two graphs? The first chart displays a proportion = 1 for all groups. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop..)) While the second plot does something similar, multiplied by the number of categories in color. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..)) geom_bar() will compute prop - the groupwise proportion. So pass in an argument to group for prop to be calculated properly. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1)) ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., fill = color, group = color)) 3.8 - Position Adjustments Problem 1 What is the problem with this plot? How could you improve it? ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() Use geom_jitter() to correct the overplotting in the original. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter() Problem 2 What parameters to geom_jitter() control the amount of jittering? The width and height arguments control the amount of jittering and defaults to 40% of the resolution of the data. So values less than 0.4 will make a graph more compact than the default geom_jitter() and values greater than 0.4 will make the graph more spread out. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.20, height = 0.20) While values greater than 0.4 will make a smoother graph. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter(width = 0.60, height = 0.60) Problem 3 Compare and contrast geom_jitter() with geom_count(). geom_jitter() and geom_count() are both useful when dealing with overplotting. While geom_jitter will add a small amount of noise to each point to spread them out, geom_count will count the number of observations at each (x,y) point, and then map the count. geom_jitter() is equivalent to geom_point(position = 'jitter') geom_count() is equivalent to geom_point(stat = 'sum') ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_count() Problem 4 What’s the default position adjustment for geom_boxplot()? Create a visualisation of the mpg dataset that demonstrates it. The default position adjustment for geom_boxplot() is dodge. ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot() ggplot(data = mpg, aes(x = class, y = cty, color = drv)) + geom_boxplot(position = &#39;identity&#39;) 3.9 - Coordinate Systems Problem 1 Turn a stacked bar chart into a pie chart using coord_polar(). From the documentation for coord_polar() - first make a stacked bar chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar() And then turn it into a pie chart: ggplot(data = mtcars, aes(x = factor(1), fill = factor(cyl))) + geom_bar(width = 1) + coord_polar(theta = &#39;y&#39;) Problem 2 What does labs() do? Read the documentation. labs() controls the labels of a plot, axis, or legend. ggplot(mpg, aes(cty, hwy)) + geom_point() + labs(title = &#39;Title&#39;, subtitle = &#39;Subtitle&#39;, caption = &#39;Caption&#39;) Problem 3 What’s the difference between coord_quickmap() and coord_map()? coord_quickmap() preserves straight lines when projecting onto a two dimensional surface and requires less computation. ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_map() ggplot(map_data(&#39;state&#39;), aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_quickmap() Problem 4 What does the plot below tell you about the relationship between city and highway mpg? Why is coord_fixed() important? What does geom_abline() do? coord_fixed() (with no arguments) ensures that a unit on the x-axis is the same length as a unit on the y-axis. geom_abline() (with no arguments) adds a reference line with an intercept of 0 and a slope of 1. One can quickly see that every observation in the mpg dataset has better highway than city fuel efficiency. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + geom_abline() + coord_fixed() "],
["chapter-5-data-transformation.html", "Chapter 5 - Data Transformation 5.2 - Filter Rows with filter() 5.3 - Arrange Rows with arrange() 5.4 - Select Columns with select() 5.5 - Add New Variables with mutate() 5.6 - Grouped summaries with summarise() 5.7 - Grouped Mutates (and Filters)", " Chapter 5 - Data Transformation Load the libraries needed for these exercises. library(tidyverse) library(nycflights13) 5.2 - Filter Rows with filter() Problem 1 Find all flights that: Had an arrival delay of two or more hours flights %&gt;% filter(arr_delay &gt;= 120) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 10200 Flew to Houston (IAH or HOU) flights %&gt;% filter(dest %in% c(&#39;IAH&#39;, &#39;HOU&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9313 Were operated by United, American, or Delta flights %&gt;% filter(carrier %in% c(&#39;UA&#39;, &#39;AA&#39;, &#39;DL&#39;)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 139504 Departed in summer (July, August, and September) flights %&gt;% filter(month %in% c(7, 8, 9)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 86326 Arrived more than two hours late, but didn’t leave late flights %&gt;% filter(arr_delay &gt;= 120, dep_delay &lt;= 0) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 29 Were delayed by at least an hour, but made up over 30 minutes in flight flights %&gt;% filter(dep_delay &gt;= 60, arr_delay &lt;= dep_delay - 30) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 2074 Departed between midnight and 6am (inclusive) flights %&gt;% filter(dep_time &gt;= 0, dep_time &lt;= 600) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 2 Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges? between() is a shortcut for x &gt;= left &amp; x &lt;= right. We can simplify the last answer to Problem 1 as: flights %&gt;% filter(between(dep_time, 0, 600)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 9344 Problem 3 How many flights have a missing dep_time? What other variables are missing? What might these rows represent? We use is.na() to filter the flights with a missing departure time. flights %&gt;% filter(is.na(dep_time)) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 8255 Using summary() to see the breakout of the other variables, there appear to be flights that were cancelled. flights %&gt;% filter(is.na(dep_time)) %&gt;% summary() ## year month day dep_time ## Min. :2013 Min. : 1.000 Min. : 1.0 Min. : NA ## 1st Qu.:2013 1st Qu.: 3.000 1st Qu.: 8.0 1st Qu.: NA ## Median :2013 Median : 6.000 Median :12.0 Median : NA ## Mean :2013 Mean : 5.927 Mean :14.6 Mean :NaN ## 3rd Qu.:2013 3rd Qu.: 8.000 3rd Qu.:23.0 3rd Qu.: NA ## Max. :2013 Max. :12.000 Max. :31.0 Max. : NA ## NA&#39;s :8255 ## sched_dep_time dep_delay arr_time sched_arr_time ## Min. : 106 Min. : NA Min. : NA Min. : 1 ## 1st Qu.:1159 1st Qu.: NA 1st Qu.: NA 1st Qu.:1330 ## Median :1559 Median : NA Median : NA Median :1749 ## Mean :1492 Mean :NaN Mean :NaN Mean :1669 ## 3rd Qu.:1855 3rd Qu.: NA 3rd Qu.: NA 3rd Qu.:2049 ## Max. :2359 Max. : NA Max. : NA Max. :2359 ## NA&#39;s :8255 NA&#39;s :8255 ## arr_delay carrier flight tailnum ## Min. : NA Length:8255 Min. : 1 Length:8255 ## 1st Qu.: NA Class :character 1st Qu.:1577 Class :character ## Median : NA Mode :character Median :3535 Mode :character ## Mean :NaN Mean :3063 ## 3rd Qu.: NA 3rd Qu.:4373 ## Max. : NA Max. :6177 ## NA&#39;s :8255 ## origin dest air_time distance ## Length:8255 Length:8255 Min. : NA Min. : 17.0 ## Class :character Class :character 1st Qu.: NA 1st Qu.: 292.0 ## Mode :character Mode :character Median : NA Median : 583.0 ## Mean :NaN Mean : 695.4 ## 3rd Qu.: NA 3rd Qu.: 872.0 ## Max. : NA Max. :4963.0 ## NA&#39;s :8255 ## hour minute time_hour ## Min. : 1.00 Min. : 0.00 Min. :2013-01-01 06:00:00 ## 1st Qu.:11.00 1st Qu.: 5.00 1st Qu.:2013-03-07 07:00:00 ## Median :15.00 Median :27.00 Median :2013-06-12 18:00:00 ## Mean :14.67 Mean :25.61 Mean :2013-06-13 06:42:11 ## 3rd Qu.:18.00 3rd Qu.:42.00 3rd Qu.:2013-08-22 15:30:00 ## Max. :23.00 Max. :59.00 Max. :2013-12-31 20:00:00 ## Problem 4 Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE &amp; NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!) Working through these examples: * Anything to the zero power is 1 * Anything OR TRUE is TRUE * Anything AND FALSE is FALSE These results apply no matter what the LHS side, and so will apply to NA as well. NA ^ 0 ## [1] 1 NA | TRUE ## [1] TRUE NA &amp; FALSE ## [1] FALSE However operations on NA will return NA. NA * 0 is counter intuitive since you would think that anything multiplied by 0 would be 0. NA * 0 ## [1] NA NA ^ 2 ## [1] NA NA + 1 ## [1] NA 5.3 - Arrange Rows with arrange() Problem 1 How could you use arrange() to sort all missing values to the start? (Hint: use is.na()). We can sort missing values using the format: flights %&gt;% arrange(desc(is.na(dep_time))) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 NA 1630 NA NA ## 2 2013 1 1 NA 1935 NA NA ## 3 2013 1 1 NA 1500 NA NA ## 4 2013 1 1 NA 600 NA NA ## 5 2013 1 2 NA 1540 NA NA ## 6 2013 1 2 NA 1620 NA NA ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 2 Sort flights to find the most delayed flights. Find the flights that left earliest. The most delayed flights (by arr_delay) are: flights %&gt;% arrange(desc(arr_delay)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 ## 2 2013 6 15 1432 1935 1137 1607 ## 3 2013 1 10 1121 1635 1126 1239 ## 4 2013 9 20 1139 1845 1014 1457 ## 5 2013 7 22 845 1600 1005 1044 ## 6 2013 4 10 1100 1900 960 1342 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The flights that left earliest (by dep_delay) are: flights %&gt;% arrange(dep_delay) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 12 7 2040 2123 -43 40 ## 2 2013 2 3 2022 2055 -33 2240 ## 3 2013 11 10 1408 1440 -32 1549 ## 4 2013 1 11 1900 1930 -30 2233 ## 5 2013 1 29 1703 1730 -27 1947 ## 6 2013 8 9 729 755 -26 1002 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Problem 3 Sort flights to find the fastest flights. We first calculate average speed in MPH as distance / hours in the air, and sort on the calculated variable. flights %&gt;% mutate(speed = distance / (air_time / 60)) %&gt;% arrange(desc(speed)) %&gt;% select(speed) %&gt;% head() ## # A tibble: 6 x 1 ## speed ## &lt;dbl&gt; ## 1 703. ## 2 650. ## 3 648 ## 4 641. ## 5 591. ## 6 564 Problem 4 Which flights traveled the longest? Which traveled the shortest? The longest flights are: flights %&gt;% arrange(desc(distance)) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 857 900 -3 1516 ## 2 2013 1 2 909 900 9 1525 ## 3 2013 1 3 914 900 14 1504 ## 4 2013 1 4 900 900 0 1516 ## 5 2013 1 5 858 900 -2 1519 ## 6 2013 1 6 1019 900 79 1558 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The shortest flights are: flights %&gt;% arrange(distance) %&gt;% head() ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 7 27 NA 106 NA NA ## 2 2013 1 3 2127 2129 -2 2222 ## 3 2013 1 4 1240 1200 40 1333 ## 4 2013 1 4 1829 1615 134 1937 ## 5 2013 1 4 2128 2129 -1 2218 ## 6 2013 1 5 1155 1200 -5 1241 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 5.4 - Select Columns with select() Problem 1 Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights. We can put all the variables directly into our select() statement: flights %&gt;% select(dep_time, dep_delay, arr_time, arr_delay) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 Or this would be a good place to try the starts_with() function: flights %&gt;% select(starts_with(&quot;dep&quot;), starts_with(&quot;arr&quot;)) ## # A tibble: 336,776 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 ## 7 555 -5 913 19 ## 8 557 -3 709 -14 ## 9 557 -3 838 -8 ## 10 558 -2 753 8 ## # ... with 336,766 more rows Or we can try a regex using matches() flights %&gt;% select(matches(&quot;^dep&quot;), matches(&quot;^arr&quot;)) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2 830 11 ## 2 533 4 850 20 ## 3 542 2 923 33 ## 4 544 -1 1004 -18 ## 5 554 -6 812 -25 ## 6 554 -4 740 12 Problem 2 What happens if you include the name of a variable multiple times in a select() call? Duplicating a variable within select() will still just return that variable one time: flights %&gt;% select(dep_time, dep_time) %&gt;% head() ## # A tibble: 6 x 1 ## dep_time ## &lt;int&gt; ## 1 517 ## 2 533 ## 3 542 ## 4 544 ## 5 554 ## 6 554 Problem 3 What does the one_of() function do? Why might it be helpful in conjunction with this vector? one_of() allows you select variables from within a character vector. We can pass vars to select everything from the vector: vars &lt;- c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;dep_delay&quot;, &quot;arr_delay&quot;) flights %&gt;% select(one_of(vars)) ## # A tibble: 336,776 x 5 ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 ## 2 2013 1 1 4 20 ## 3 2013 1 1 2 33 ## 4 2013 1 1 -1 -18 ## 5 2013 1 1 -6 -25 ## 6 2013 1 1 -4 12 ## 7 2013 1 1 -5 19 ## 8 2013 1 1 -3 -14 ## 9 2013 1 1 -3 -8 ## 10 2013 1 1 -2 8 ## # ... with 336,766 more rows Problem 4 Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default? select(flights, contains(&quot;TIME&quot;)) %&gt;% head() ## # A tibble: 6 x 6 ## dep_time sched_dep_time arr_time sched_arr_time air_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 830 819 227 ## 2 533 529 850 830 227 ## 3 542 540 923 850 160 ## 4 544 545 1004 1022 183 ## 5 554 600 812 837 116 ## 6 554 558 740 728 150 ## # ... with 1 more variable: time_hour &lt;dttm&gt; contains() contains an argument ignore.case which defaults to TRUE, we can set this to FALSE if needed: select(flights, contains(&quot;TIME&quot;, ignore.case = FALSE)) %&gt;% head() ## # A tibble: 6 x 0 5.5 - Add New Variables with mutate() Problem 1 Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. Use the modular arithmetic operators to break the time into its hours and minute components: flights %&gt;% select(dep_time, sched_dep_time) %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100))) %&gt;% head() ## # A tibble: 6 x 4 ## dep_time sched_dep_time dep_time_cont sched_dep_time_cont ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 517 515 317 315 ## 2 533 529 333 329 ## 3 542 540 342 340 ## 4 544 545 344 345 ## 5 554 600 354 360 ## 6 554 558 354 358 Problem 2 Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it? The issue is that air_time is in minutes, while arr_time and dep_time are not: flights %&gt;% mutate(air_time_derived = arr_time - dep_time) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;int&gt; ## 1 227 313 ## 2 227 317 ## 3 160 381 ## 4 183 460 ## 5 116 258 ## 6 150 186 Instead use the mutate() statement from Problem 1, however the two differ: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), arr_time_cont = ((arr_time %/% 100) * 60 + (arr_time %% 100)), air_time_derived = arr_time_cont - dep_time_cont) %&gt;% select(air_time, air_time_derived) %&gt;% head() ## # A tibble: 6 x 2 ## air_time air_time_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 227 193 ## 2 227 197 ## 3 160 221 ## 4 183 260 ## 5 116 138 ## 6 150 106 Problem 3 Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related? We would expect dep_delay to be the difference between the dep_time and the sched_dep_time. But be sure to convert from time to continuous first: flights %&gt;% mutate(dep_time_cont = ((dep_time %/% 100) * 60 + (dep_time %% 100)), sched_dep_time_cont = ((sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100)), dep_delay_derived = dep_time_cont - sched_dep_time_cont) %&gt;% select(dep_delay, dep_delay_derived) %&gt;% head() ## # A tibble: 6 x 2 ## dep_delay dep_delay_derived ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 2 ## 2 4 4 ## 3 2 2 ## 4 -1 -1 ## 5 -6 -6 ## 6 -4 -4 Problem 4 Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank(). We’ll use min_rank() to rank the flights by arr_delay: flights %&gt;% select(arr_delay) %&gt;% mutate(most_delayed = min_rank(-arr_delay)) %&gt;% filter(most_delayed &lt;= 10) %&gt;% arrange(most_delayed) ## # A tibble: 10 x 2 ## arr_delay most_delayed ## &lt;dbl&gt; &lt;int&gt; ## 1 1272 1 ## 2 1127 2 ## 3 1109 3 ## 4 1007 4 ## 5 989 5 ## 6 931 6 ## 7 915 7 ## 8 895 8 ## 9 878 9 ## 10 875 10 Problem 5 What does 1:3 + 1:10 return? Why? We get an error because 1:3 + 1:10 are not multiples of each other: 1:3 + 1:10 ## Warning in 1:3 + 1:10: longer object length is not a multiple of shorter ## object length ## [1] 2 4 6 5 7 9 8 10 12 11 Think through what is happening under the hood. This operation is recycling the shorter vector: 1 + 1 2 + 2 3 + 3 4 + 1 5 + 2 6 + 3 7 + 1 8 + 2 9 + 3 10 + 1 - error because 1:3 has not been fully cycled through So the following will not return an error: 1:3 + 1:12 ## [1] 2 4 6 5 7 9 8 10 12 11 13 15 Problem 6 What trigonometric functions does R provide? R has the following trig functions within base: cos(x) sin(x) tan(x) acos(x) asin(x) atan(x) atan2(y, x) cospi(x) sinpi(x) tanpi(x) Note that angles are given in radians: cos(pi * 0.25) ## [1] 0.7071068 # cospi(x) is equivalent to cos(pi * x) cospi(0.25) ## [1] 0.7071068 5.6 - Grouped summaries with summarise() Problem 1 Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios: A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(fifteen_early = mean(arr_delay &lt;= -15, na.rm = TRUE), fifteen_late = mean(arr_delay &gt;= 15, na.rm = TRUE)) %&gt;% filter(fifteen_early == 0.50, fifteen_late == 0.50) ## # A tibble: 21 x 3 ## flight fifteen_early fifteen_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 107 0.5 0.5 ## 2 2072 0.5 0.5 ## 3 2366 0.5 0.5 ## 4 2500 0.5 0.5 ## 5 2552 0.5 0.5 ## 6 3495 0.5 0.5 ## 7 3505 0.5 0.5 ## 8 3518 0.5 0.5 ## 9 3544 0.5 0.5 ## 10 3651 0.5 0.5 ## # ... with 11 more rows A flight is always 10 minutes late. flights %&gt;% group_by(flight) %&gt;% summarise(ten_late = mean(arr_delay == 10, na.rm = TRUE)) %&gt;% filter(ten_late == 1.00) ## # A tibble: 5 x 2 ## flight ten_late ## &lt;int&gt; &lt;dbl&gt; ## 1 2254 1 ## 2 3656 1 ## 3 3785 1 ## 4 3880 1 ## 5 5854 1 A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time. flights %&gt;% group_by(flight) %&gt;% summarise(thirty_early = mean(arr_delay &lt;= -30, na.rm = TRUE), thirty_late = mean(arr_delay &gt;= 30, na.rm = TRUE)) %&gt;% filter(thirty_early == 0.50, thirty_late == 0.50) ## # A tibble: 3 x 3 ## flight thirty_early thirty_late ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3651 0.5 0.5 ## 2 3916 0.5 0.5 ## 3 3951 0.5 0.5 99% of the time a flight is on time. 1% of the time it’s 2 hours late. flights %&gt;% group_by(flight) %&gt;% summarise(on_time = mean(arr_delay &lt;= 0, na.rm = TRUE), late = mean(arr_delay &gt;= 120, na.rm = TRUE)) %&gt;% filter(on_time == 0.99, late == 0.01) ## # A tibble: 0 x 3 ## # ... with 3 variables: flight &lt;int&gt;, on_time &lt;dbl&gt;, late &lt;dbl&gt; Problem 2 Come up with another approach that will give you the same output as not_cancelled %&gt;% count(dest) and not_cancelled %&gt;% count(tailnum, wt = distance) (without using count()). First setup the not_cancelled data set. not_cancelled &lt;- flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) The first chunk of code gives us the following output: not_cancelled %&gt;% count(dest) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows We can replicate this without using count() by doing a group_by() on dest: not_cancelled %&gt;% group_by(dest) %&gt;% summarise(n = n()) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows The second chunk of code gives us: not_cancelled %&gt;% count(tailnum, wt = distance) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Again we can avoid using count by doing a group_by() on tailnum. Since wt = distance gives the total number of miles flown, we use sum() instead: not_cancelled %&gt;% group_by(tailnum) %&gt;% summarise(n = sum(distance)) ## # A tibble: 4,037 x 2 ## tailnum n ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows Problem 3 Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column? arr_delay is the more important of the two columns - filtering on arr_delay alone will give the same subset: flights %&gt;% summarise(suboptimal = sum(is.na(dep_delay) | is.na(arr_delay)), optimal = sum(is.na(arr_delay))) ## # A tibble: 1 x 2 ## suboptimal optimal ## &lt;int&gt; &lt;int&gt; ## 1 9430 9430 Problem 4 Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay? There is a generally positive trend between average delay and the proportion of cancelled flights, with a couple of outliers. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(avg_delay, cancelled)) + geom_point() A lot of flights were cancelled on February 8th and 9th, although the average delays those days were not that large - a snowstorm hit the region that weekend, with a lot of flights preemptively cancelled. flights %&gt;% mutate(date = lubridate::make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(cancelled = mean(is.na(arr_delay)), avg_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(cancelled)) %&gt;% head() ## # A tibble: 6 x 3 ## date cancelled avg_delay ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013-02-09 0.575 6.64 ## 2 2013-02-08 0.511 24.2 ## 3 2013-05-23 0.235 62.0 ## 4 2013-09-12 0.229 58.9 ## 5 2013-12-10 0.216 44.5 ## 6 2013-12-14 0.189 46.4 Problem 5 Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %&gt;% group_by(carrier, dest) %&gt;% summarise(n()) At first glance, Frontier and AirTran seem to have the worst delays. flights %&gt;% group_by(carrier) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% arrange(desc(median_delay)) ## # A tibble: 16 x 2 ## carrier median_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 F9 6 ## 2 FL 5 ## 3 EV -1 ## 4 MQ -1 ## 5 YV -2 ## 6 B6 -3 ## 7 WN -3 ## 8 UA -6 ## 9 US -6 ## 10 9E -7 ## 11 OO -7 ## 12 DL -8 ## 13 AA -9 ## 14 VX -9 ## 15 HA -13 ## 16 AS -17 We can try to get a better sense of bad airlines vs bad airports by grouping by both, but this will be thrown off by carrier-dest combinations that occur infrequently. flights %&gt;% group_by(carrier, dest) %&gt;% summarise(median_delay = median(arr_delay, na.rm = TRUE)) %&gt;% ggplot(aes(carrier, median_delay)) + geom_boxplot() ## Warning: Removed 2 rows containing non-finite values (stat_boxplot). Problem 6 What does the sort argument to count() do. When might you use it? The sort argument will arrange count() in descending order. If we quickly wanted to find the most popular destinations, we could do: flights %&gt;% group_by(dest) %&gt;% count(sort = TRUE) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: dest [6] ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ORD 17283 ## 2 ATL 17215 ## 3 LAX 16174 ## 4 BOS 15508 ## 5 MCO 14082 ## 6 CLT 14064 5.7 - Grouped Mutates (and Filters) Problem 1 Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping. Problem 2 Which plane (tailnum) has the worst on-time record? We do a familiar group_by()-summarise() to calculate the proportion of flights with an arr_delay less than or equal to 0, and then apply a filter to see the on-time performance of planes with more than twenty flights. flights %&gt;% group_by(tailnum) %&gt;% summarise(flights = n(), on_time = mean(arr_delay &lt;= 0, na.rm = TRUE)) %&gt;% select(tailnum, flights, on_time) %&gt;% filter(flights &gt; 20) %&gt;% arrange(on_time) %&gt;% head() ## # A tibble: 6 x 3 ## tailnum flights on_time ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 N988AT 37 0.2 ## 2 N983AT 32 0.25 ## 3 N980AT 47 0.255 ## 4 N969AT 34 0.265 ## 5 N932AT 30 0.267 ## 6 N149AT 22 0.273 Problem 3 What time of day should you fly if you want to avoid delays as much as possible? It appears that flights later in day have a greater chance of being delayed than those early in the morning. flights %&gt;% group_by(hour) %&gt;% filter(!is.na(dep_delay)) %&gt;% summarise(delayed = mean(dep_delay &gt; 0, na.rm = TRUE)) %&gt;% ggplot(aes(x = hour, y = delayed)) + geom_col() Problem 4 For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination. A grouped mutate comes in handy here, as we can first calculate the total minutes of delay for each destination and then use that value to compute the proportion of the total delay attributable to each flight. flights %&gt;% group_by(dest) %&gt;% filter(arr_delay &gt; 0) %&gt;% mutate(total_delay = sum(arr_delay), prop_delay = arr_delay / sum(arr_delay)) %&gt;% select(dest, flight, total_delay, prop_delay) %&gt;% arrange(desc(total_delay)) %&gt;% head() ## # A tibble: 6 x 4 ## # Groups: dest [1] ## dest flight total_delay prop_delay ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ATL 4650 300299 0.0000400 ## 2 ATL 1547 300299 0.0000167 ## 3 ATL 346 300299 0.0000566 ## 4 ATL 4654 300299 0.0000200 ## 5 ATL 347 300299 0.00000666 ## 6 ATL 4876 300299 0.0000366 Problem 5 Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag() explore how the delay of a flight is related to the delay of the immediately preceding flight. First group by origin and the perform a mutate() with lag() to get the delay of the immediately preceding flight. We then use summarise to get the correlation between the delay and lagged delay for each airport. flights %&gt;% group_by(origin) %&gt;% filter(!is.na(dep_delay)) %&gt;% arrange(year, month, day, hour, minute) %&gt;% mutate(lag_delay = lag(dep_delay)) %&gt;% summarise(delay_correlation = cor(dep_delay, lag_delay, use = &#39;complete.obs&#39;)) ## # A tibble: 3 x 2 ## origin delay_correlation ## &lt;chr&gt; &lt;dbl&gt; ## 1 EWR 0.265 ## 2 JFK 0.242 ## 3 LGA 0.302 Problem 6 Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air? A grouped mutate is helpful here, as we can calculate the mean air time by destination and then immediately use that value to calculate a flight’s deviation from it. Note that we filtered out flights less than an hour long. deviation &lt;- flights %&gt;% group_by(dest) %&gt;% filter(!is.na(air_time)) %&gt;% mutate(mean_air_time = mean(air_time), deviation = (air_time - mean_air_time) / mean_air_time) %&gt;% filter(mean_air_time &gt; 60) %&gt;% arrange(deviation) %&gt;% select(air_time, mean_air_time, deviation, origin, dest) deviation %&gt;% head() ## # A tibble: 6 x 5 ## # Groups: dest [6] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 65 113. -0.424 LGA ATL ## 2 55 93.4 -0.411 EWR GSP ## 3 70 114. -0.388 EWR BNA ## 4 93 151. -0.382 EWR MSP ## 5 62 96.0 -0.354 EWR CVG ## 6 40 61.5 -0.349 LGA PIT deviation %&gt;% tail() ## # A tibble: 6 x 5 ## # Groups: dest [5] ## air_time mean_air_time deviation origin dest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 147 86.2 0.706 EWR CLT ## 2 198 116. 0.713 EWR ORD ## 3 185 106. 0.741 EWR SDF ## 4 138 70.9 0.947 JFK RDU ## 5 170 84.8 1.00 LGA DTW ## 6 170 84.8 1.00 JFK DTW Problem 7 Find all destinations that are flown by at least two carriers. Use that information to rank the carriers. We first use a group_by with mutate() and filter() to subset the destinations serviced by at least 2 carriers, followed by a second group_by to rank the carriers by total destinations served. We also merge data from the airlines data set to get the full carrier names. ExpressJet and Endeavor Air are regional airlines which operate as American Eagle, United Express, and Delta Connection. flights %&gt;% group_by(dest) %&gt;% mutate(carriers = n_distinct(carrier)) %&gt;% filter(carriers &gt;= 2) %&gt;% group_by(carrier) %&gt;% summarise(destinations = n_distinct(dest)) %&gt;% arrange(desc(destinations)) %&gt;% left_join(airlines) %&gt;% select(carrier, name, destinations) %&gt;% head() ## Joining, by = &quot;carrier&quot; ## # A tibble: 6 x 3 ## carrier name destinations ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 EV ExpressJet Airlines Inc. 51 ## 2 9E Endeavor Air Inc. 48 ## 3 UA United Air Lines Inc. 42 ## 4 DL Delta Air Lines Inc. 39 ## 5 B6 JetBlue Airways 35 ## 6 AA American Airlines Inc. 19 Problem 8 For each plane, count the number of flights before the first delay of greater than 1 hour. First group_by() tailnum and then apply a filter() using the cumall window function to subset everything before the first delay of more than 1 hour. flights %&gt;% arrange(year, month, day, hour, minute) %&gt;% group_by(tailnum) %&gt;% filter(cumall(dep_delay &lt;= 60)) %&gt;% count() %&gt;% arrange(desc(n)) %&gt;% head() ## # A tibble: 6 x 2 ## # Groups: tailnum [6] ## tailnum n ## &lt;chr&gt; &lt;int&gt; ## 1 N954UW 206 ## 2 N952UW 163 ## 3 N957UW 142 ## 4 N5FAAA 117 ## 5 N38727 99 ## 6 N3742C 98 "],
["chapter-7-exploratory-data-analysis.html", "Chapter 7 - Exploratory Data Analysis 7.3 - Variation 7.4 - Missing Values", " Chapter 7 - Exploratory Data Analysis Load the libraries needed for these exercises. library(tidyverse) 7.3 - Variation Problem 1 Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth. The distribution of x, y, and z generally seems to fall between 0 and 10mm, although the distributions of y and z both have much longer tails. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = x), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = z), binwidth = 0.5) Problem 2 Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.) The price of diamonds appears to peak around $2000, followed by a long tail for the much more expensive diamonds. Narrowing the value of binwidth shows that some values are not very populated. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 1000) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 500) ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 100) Problem 3 How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference? People may prefer to buy a diamond that is a full carat rather than almost a carat large. There appears to be significant rounding in the data set: diamonds %&gt;% filter(between(carat, 0.99, 1.00)) %&gt;% group_by(carat) %&gt;% count() ## # A tibble: 2 x 2 ## # Groups: carat [2] ## carat n ## &lt;dbl&gt; &lt;int&gt; ## 1 0.99 23 ## 2 1 1558 Problem 4 Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows? Compare and contrast the following three graphs: while coord_cartesian() will preserve data, ylim() will drop rows that fall outside of the limits. ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0,60)) ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + ylim(0,60) ## Warning: Removed 11 rows containing missing values (geom_bar). 7.4 - Missing Values Problem 1 What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference? Missing values are plotted in a bar chart but not a histogram. Remember that histograms are generally used to display numeric data, while bar charts are used for categorical data. Missing values can be considered another category to plot in a bar chart, but there is not necessarily an intuitive way to place missing values in a histogram. diamonds %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1610 rows containing non-finite values (stat_bin). diamonds %&gt;% mutate(cut = as.character(cut)) %&gt;% mutate(cut = ifelse(cut == &#39;Fair&#39;, NA, cut)) %&gt;% ggplot(aes(x=cut)) + geom_bar() Problem 2 What does na.rm = TRUE do in mean() and sum()? Setting na.rm = TRUE will remove missing values before executing the function. x &lt;- c(1, 2, 3, NA) mean(x) ## [1] NA mean(x, na.rm = TRUE) ## [1] 2 "],
["chapter-10-tibbles.html", "Chapter 10 - Tibbles 10.5 - Exercises", " Chapter 10 - Tibbles Load the libraries needed for these exercises. library(tidyverse) 10.5 - Exercises Problem 1 How can you tell if an object is a tibble? (Hint: try printing mtcars, which is a regular data frame). Use the is.tibble() function to determine if an object is a tibble. A tibble will also have a heading if printed to the console. is.tibble(mtcars) ## [1] FALSE is.tibble(diamonds) ## [1] TRUE diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows Problem 2 Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration? A data frame will attempt to auto-complete, while a tibble will not: df &lt;- data.frame(abc = 1, xyz = &quot;a&quot;) tib &lt;- tibble(abc = 1, xyz = &quot;a&quot;) df$x ## [1] a ## Levels: a tib$x ## Warning: Unknown or uninitialised column: &#39;x&#39;. ## NULL Data frames will sometimes simplify: is.data.frame(df[, &quot;xyz&quot;]) ## [1] FALSE is.tibble(tib[, &quot;xyz&quot;]) ## [1] TRUE Tibble will display useful information on the data: df[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## abc xyz ## 1 1 a tib[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## # A tibble: 1 x 2 ## abc xyz ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a Problem 3 If you have the name of a variable stored in an object, e.g. var &lt;- &quot;mpg&quot;, how can you extract the reference variable from a tibble? Use [] to extract the variable and [[]] to extract the vector: var &lt;- &#39;mpg&#39; as.tibble(mtcars)[var] ## # A tibble: 32 x 1 ## mpg ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ... with 22 more rows as.tibble(mtcars)[[var]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 ## [15] 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 ## [29] 15.8 19.7 15.0 21.4 Problem 4 Practice referring to non-syntactic names in the following data frame by: Extracting the variable called 1. annoying &lt;- tibble( `1` = 1:10, `2` = `1` * 2 + rnorm(length(`1`)) ) annoying %&gt;% select(`1`) ## # A tibble: 10 x 1 ## `1` ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 7 ## 8 8 ## 9 9 ## 10 10 Plotting a scatterplot of 1 vs 2. ggplot(annoying, aes(`1`, `2`)) + geom_point() Creating a new column called 3 which is 2 divided by 1. annoying &lt;- annoying %&gt;% mutate(`3` = `2` / `1`) Renaming the columns to one, two and three. annoying %&gt;% select(one = `1`, two = `2`, three = `3`) ## # A tibble: 10 x 3 ## one two three ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2.58 2.58 ## 2 2 2.96 1.48 ## 3 3 7.82 2.61 ## 4 4 8.52 2.13 ## 5 5 11.6 2.32 ## 6 6 12.2 2.03 ## 7 7 15.4 2.20 ## 8 8 16.3 2.04 ## 9 9 18.4 2.04 ## 10 10 21.5 2.15 Problem 5 What does tibble::enframe() do? When might you use it? enframe() can be used to convert a vector or list to a tibble: enframe(c(a = 5, b = 10)) ## # A tibble: 2 x 2 ## name value ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 5 ## 2 b 10 Problem 6 What option controls how many additional column names are printed at the footer of a tibble? The tibble.max_extra_cols option controls this behavior, with a default of 100. "],
["chapter-11-data-import.html", "Chapter 11 - Data Import 11.2 - Getting Started 11.3 - Parsing a Vector", " Chapter 11 - Data Import Load the libraries needed for these exercises. library(tidyverse) 11.2 - Getting Started Problem 1 What function would you use to read a file where fields were separated with “|”? Use read_delim(), using | as the delimiter: data &lt;- &#39;a|b|c\\n1|2|3&#39; read_delim(data, delim = &#39;|&#39;) ## # A tibble: 1 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 Problem 2 Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common? read_csv() and read_tsv() are essentially just read_delim with the delimiter preset to either a comma or a tab. All of their other arguments are the same. Problem 3 What are the most important arguments to read_fwf()? The most important argument to read_fwf() is col_positions, as this determines how data is read: fwf_sample &lt;- readr_example(&quot;fwf-sample.txt&quot;) cat(read_lines(fwf_sample)) ## John Smith WA 418-Y11-4111 Mary Hartford CA 319-Z19-4341 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA 418-Y11-4111 ## 2 Mary Hartford CA 319-Z19-4341 ## 3 Evan Nolan IL 219-532-c301 read_fwf(fwf_sample, fwf_widths(c(5, 10, 12), c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) ## Parsed with column specification: ## cols( ## name = col_character(), ## state = col_character(), ## ssn = col_character() ## ) ## # A tibble: 3 x 3 ## name state ssn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Smith WA ## 2 Mary Hartford CA ## 3 Evan Nolan IL Problem 4 Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like &quot; or '. By convention, read_csv() assumes that the quoting character will be &quot;, and if you want to change it you’ll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame? &quot;x,y\\n1,'a,b'&quot; Since read_delim() must be used instead of read_csv(), the delimiter must be set. The quote argument can be set to a single quote instead of a double quote: data &lt;- &quot;x,y\\n1,&#39;a,b&#39;&quot; read_delim(data, delim = &#39;,&#39;, quote = &#39;\\&#39;&#39;) ## # A tibble: 1 x 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a,b Problem 5 Identify what is wrong with each of the following inline CSV files. What happens when you run the code? There are more data than columns, which results in a parsing failure. The extra data are dropped from the data frame: read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 2 columns 3 columns literal data file 2 2 &lt;NA&gt; 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 4 5 There is too little data in row 2 and too much data in row 3 - row 2 is filled in with a missing value while row 3 drops data: read_csv(&quot;a,b,c\\n1,2\\n1,2,3,4&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 3 columns 2 columns literal data file 2 2 &lt;NA&gt; 3 columns 4 columns literal data ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 NA ## 2 1 2 3 There are two variables but only one data point - b is filled in with a missing value: read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 a closing quote at end of file &quot;&quot; literal data file 2 1 &lt;NA&gt; 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; Appears that the header was entered twice, so the data are parsed as character instead of a string. Or if the goal here was to enter a missing value NA, note that the n was processed as a new line \\n. read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b read_csv(&quot;a,b\\n1,2\\nna,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 na b read_csv() has a delimiter set to ,, use read_csv2() instead: read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv2(&quot;a;b\\n1;3&quot;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 3 11.3 - Parsing a Vector Problem 1 What are the most important arguments to locale()? The date_names argument provides useful defaults for a locale() object: dutch &lt;- locale(&#39;nl&#39;) japanese &lt;- locale(&#39;ja&#39;) str(dutch) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;januari&quot; &quot;februari&quot; &quot;maart&quot; &quot;april&quot; ... ## ..$ mon_ab: chr [1:12] &quot;jan.&quot; &quot;feb.&quot; &quot;mrt.&quot; &quot;apr.&quot; ... ## ..$ day : chr [1:7] &quot;zondag&quot; &quot;maandag&quot; &quot;dinsdag&quot; &quot;woensdag&quot; ... ## ..$ day_ab: chr [1:7] &quot;zo&quot; &quot;ma&quot; &quot;di&quot; &quot;wo&quot; ... ## ..$ am_pm : chr [1:2] &quot;a.m.&quot; &quot;p.m.&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; str(japanese) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ mon_ab: chr [1:12] &quot;1月&quot; &quot;2月&quot; &quot;3月&quot; &quot;4月&quot; ... ## ..$ day : chr [1:7] &quot;日曜日&quot; &quot;月曜日&quot; &quot;火曜日&quot; &quot;水曜日&quot; ... ## ..$ day_ab: chr [1:7] &quot;日&quot; &quot;月&quot; &quot;火&quot; &quot;水&quot; ... ## ..$ am_pm : chr [1:2] &quot;午前&quot; &quot;午後&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;UTC&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Be sure to read the full documentation for locale(). Common data import issues can probably be solved with decimal_mark, grouping_mark, and/or encoding. Problem 2 What happens if you try and set decimal_mark and grouping_mark to the same character? What happens to the default value of grouping_mark when you set decimal_mark to “,”? What happens to the default value of decimal_mark when you set the grouping_mark to “.”? locale() requires that decimal_mark and grouping_mark be different: x &lt;- locale(decimal_mark = &#39;.&#39;, grouping_mark = &#39;.&#39;) ## Error: `decimal_mark` and `grouping_mark` must be different Setting decimal_mark to , will automatically update grouping_mark to .. Similarly setting grouping_mark to . will automatically update decimal_mark to ,: x &lt;- locale(decimal_mark = &#39;,&#39;) x$grouping_mark ## [1] &quot;.&quot; y &lt;- locale(grouping_mark = &#39;.&#39;) y$decimal_mark ## [1] &quot;,&quot; Problem 3 I didn’t discuss the date_format and time_format options to locale(). What do they do? Construct an example that shows when they might be useful. A specific date_format and time_format structure can be specified in a locale(). This can be useful for formatting data with non-standard formatting: parse_date(&#39;June/7/90&#39;, locale = locale(date_format = &#39;%B/%d/%y&#39;)) ## [1] &quot;1990-06-07&quot; parse_time(&#39;1:15PM&#39;, locale = locale(time_format = &#39;%I:%M%p&#39;)) ## 13:15:00 Problem 4 If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly. Create a locale with the time zone updated: str(locale(tz = &#39;US/Eastern&#39;)) ## List of 7 ## $ date_names :List of 5 ## ..$ mon : chr [1:12] &quot;January&quot; &quot;February&quot; &quot;March&quot; &quot;April&quot; ... ## ..$ mon_ab: chr [1:12] &quot;Jan&quot; &quot;Feb&quot; &quot;Mar&quot; &quot;Apr&quot; ... ## ..$ day : chr [1:7] &quot;Sunday&quot; &quot;Monday&quot; &quot;Tuesday&quot; &quot;Wednesday&quot; ... ## ..$ day_ab: chr [1:7] &quot;Sun&quot; &quot;Mon&quot; &quot;Tue&quot; &quot;Wed&quot; ... ## ..$ am_pm : chr [1:2] &quot;AM&quot; &quot;PM&quot; ## ..- attr(*, &quot;class&quot;)= chr &quot;date_names&quot; ## $ date_format : chr &quot;%AD&quot; ## $ time_format : chr &quot;%AT&quot; ## $ decimal_mark : chr &quot;.&quot; ## $ grouping_mark: chr &quot;,&quot; ## $ tz : chr &quot;US/Eastern&quot; ## $ encoding : chr &quot;UTF-8&quot; ## - attr(*, &quot;class&quot;)= chr &quot;locale&quot; Problem 5 What’s the difference between read_csv() and read_csv2()? read_csv() has a delimiter set to , while read_csv2 is set to ;, as some countries use , as the decimal_mark: read_csv(&#39;a,b\\n1,2&#39;) ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 read_csv2(&#39;a;b\\n1;2&#39;) ## Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use read_delim() for more control. ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 Problem 6 What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out. See this list of common encodings (via Wikipedia). Problem 7 Generate the correct format string to parse each of the following dates and times: d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 t1 &lt;- &quot;1705&quot; t2 &lt;- &quot;11:15:10.12 PM&quot; Build up a datetime format using the pieces described in the chapter: parse_date(d1, format = &#39;%B %d, %Y&#39;) ## [1] &quot;2010-01-01&quot; parse_date(d2, format = &#39;%Y-%b-%d&#39;) ## [1] &quot;2015-03-07&quot; parse_date(d3, format = &#39;%d-%b-%Y&#39;) ## [1] &quot;2017-06-06&quot; parse_date(d4, format = &#39;%B %d (%Y)&#39;) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; parse_date(d5, format = &#39;%m/%d/%y&#39;) ## [1] &quot;2014-12-30&quot; parse_time(t1, format = &#39;%H%M&#39;) ## 17:05:00 parse_time(t2, format = &#39;%I:%M:%OS %p&#39;) ## 23:15:10.12 "],
["chapter-12-tidy-data.html", "Chapter 12 - Tidy Data 12.2 - Tidy Data 12.3 - Spreading and Gathering 12.4 - Spreading and Uniting", " Chapter 12 - Tidy Data Load the libraries needed for these exercises. library(tidyverse) 12.2 - Tidy Data Problem 1 Using prose, describe how the variables and observations are organised in each of the sample tables. table1 is the ‘tidy’ dataset: each variable has its own column, each observation has its own row, and each value has its own cell: table1 ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table2 combines cases and population into one column called type, this means that each variable does not have its own column, and that each observation spans multiple rows: table2 ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 In table3 the variable rate violates a tidy principle, with multiple values contained in a cell, which also means that each variable does not have its own column: table3 ## # A tibble: 6 x 3 ## country year rate ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 table4a and table4b separate cases and population into their own tables across years, with multiple observations in each row: table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 table4b ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 19987071 20595360 ## 2 Brazil 172006362 174504898 ## 3 China 1272915272 1280428583 Problem 2 Compute the rate for table2, and table4a + table4b. You will need to perform four operations: Extract the number of TB cases per country per year. Extract the matching population per country per year. Divide cases by population, and multiply by 10000. Store back in the appropriate place. Which representation is easiest to work with? Which is hardest? Why? NOTE these exercises demonstrate the difficulties of working with non-tidy data, the methods to come later in this chapter will greatly simplify the below code. Create a tidy version of table2 by filtering type into two tables and using the dplyr full_join() function to recreate table1 table2a &lt;- table2 %&gt;% filter(type == &#39;cases&#39;) %&gt;% select(country, year, cases = count) table2b &lt;- table2 %&gt;% filter(type == &#39;population&#39;) %&gt;% select(country, year, population = count) full_join(table2a, table2b) %&gt;% mutate(rate = cases / population * 10000) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 5 ## country year cases population rate ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.373 ## 2 Afghanistan 2000 2666 20595360 1.29 ## 3 Brazil 1999 37737 172006362 2.19 ## 4 Brazil 2000 80488 174504898 4.61 ## 5 China 1999 212258 1272915272 1.67 ## 6 China 2000 213766 1280428583 1.67 Use similar logic on table4a and table4b - this ends up being a bit more work as the data are already stored across two tables: table4a_1 &lt;- table4a %&gt;% mutate(year = 1999) %&gt;% select(country, year, cases = `1999`) table4a_2 &lt;- table4a %&gt;% mutate(year = 2000) %&gt;% select(country, year, cases = `2000`) table4b_1 &lt;- table4b %&gt;% mutate(year = 1999) %&gt;% select(country, year, population = `1999`) table4b_2 &lt;- table4b %&gt;% mutate(year = 2000) %&gt;% select(country, year, population = `2000`) bind_rows(table4a_1, table4a_2) %&gt;% full_join(bind_rows(table4b_1, table4b_2)) %&gt;% mutate(rate = cases / population * 10000) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 5 ## country year cases population rate ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.373 ## 2 Brazil 1999 37737 172006362 2.19 ## 3 China 1999 212258 1272915272 1.67 ## 4 Afghanistan 2000 2666 20595360 1.29 ## 5 Brazil 2000 80488 174504898 4.61 ## 6 China 2000 213766 1280428583 1.67 Problem 3 Recreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first? Filter type so that only cases is plotted: table2 %&gt;% filter(type == &#39;cases&#39;) %&gt;% ggplot(aes(year, count)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) 12.3 - Spreading and Gathering Problem 1 Why are gather() and spread() not perfectly symmetrical? Carefully consider the following example: stocks &lt;- tibble( year = c(2015, 2015, 2016, 2016), half = c( 1, 2, 1, 2), return = c(1.88, 0.59, 0.92, 0.17) ) stocks ## # A tibble: 4 x 3 ## year half return ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 1 1.88 ## 2 2015 2 0.59 ## 3 2016 1 0.92 ## 4 2016 2 0.17 stocks %&gt;% spread(year, return) %&gt;% gather(&quot;year&quot;, &quot;return&quot;, `2015`:`2016`) ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2015 1.88 ## 2 2 2015 0.59 ## 3 1 2016 0.92 ## 4 2 2016 0.17 (Hint: look at the variable types and think about column names.) Both spread() and gather() have a convert argument. What does it do? In the above example gather() and spread() are not perfectly symmetrical as year is converted from a numeric to a character variable. Use the convert argument to automatically run type.convert() on the key column: stocks %&gt;% spread(year, return, convert = TRUE) %&gt;% gather(&quot;year&quot;, &quot;return&quot;, `2015`:`2016`, convert = TRUE) ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2015 1.88 ## 2 2 2015 0.59 ## 3 1 2016 0.92 ## 4 2 2016 0.17 Problem 2 Why does this code fail? table4a %&gt;% gather(1999, 2000, key = &quot;year&quot;, value = &quot;cases&quot;) ## Error in inds_combine(.vars, ind_list): Position must be between 0 and n Be sure to use backticks to include a nonstandard variable name within a tibble: table4a %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 Problem 3 Why does spreading this tibble fail? How could you add a new column to fix the problem? people &lt;- tribble( ~name, ~key, ~value, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Phillip Woods&quot;, &quot;age&quot;, 50, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156 ) Spreading the given tibble will fail because rows 1 and 3 are identical observations. Add a count variable to fix the problem: people$count &lt;- c(1,1,2,1,1) people %&gt;% spread(key, value) ## # A tibble: 3 x 4 ## name count age height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Jessica Cordero 1 37 156 ## 2 Phillip Woods 1 45 186 ## 3 Phillip Woods 2 50 NA Problem 4 Tidy the simple tibble below. Do you need to spread or gather it? What are the variables? preg &lt;- tribble( ~pregnant, ~male, ~female, &quot;yes&quot;, NA, 10, &quot;no&quot;, 20, 12 ) The given tibble is not tidy as one variable (sex) is spread across multiple columns. Use gather(): preg %&gt;% gather(male:female, key = sex, value = count) ## # A tibble: 4 x 3 ## pregnant sex count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 yes male NA ## 2 no male 20 ## 3 yes female 10 ## 4 no female 12 12.4 - Spreading and Uniting Problem 1 What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) ## Warning: Expected 3 pieces. Additional pieces discarded in 1 rows [2]. ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f ## 3 h i j tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) ## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 1 rows [2]. ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e &lt;NA&gt; ## 3 f g i extra controls what happens when separate() results in too many pieces. In the first example, the second row appears to have an extra observation, which is dropped by default. Using extra = 'merge' will preserve the value: tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), extra = &#39;merge&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f,g ## 3 h i j fill controls what happens when separate() results in not enough pieces. In the second example, the second row appears to be missing an observation, which will be filled from the right be default. Using fill = 'left' will fill from left instead. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), fill = &#39;left&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 &lt;NA&gt; d e ## 3 f g i Problem 2 Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE? remove will drop the original input column from the data frame. Set it to FALSE in order to keep it in the data: tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f&quot;, &quot;g,h,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), remove = FALSE) ## # A tibble: 3 x 4 ## x one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a,b,c a b c ## 2 d,e,f d e f ## 3 g,h,i g h i Problem 3 Compare and contrast separate() and extract(). Why are there three variations of separation (by position, by separator, and with groups), but only one unite? separate() will create columns using either a position or a separator, while extract() will create columns using a regular expression groups. Consider the differences in the following: df &lt;- data.frame(x = c(NA, &quot;a-b&quot;, &quot;a-d&quot;, &quot;b-c&quot;, &quot;d-e&quot;)) df %&gt;% separate(x, c(&quot;A&quot;, &quot;B&quot;)) ## A B ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 a b ## 3 a d ## 4 b c ## 5 d e df %&gt;% extract(x, c(&quot;A&quot;, &quot;B&quot;), &quot;([a-d]+)-([a-d]+)&quot;) ## A B ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 a b ## 3 a d ## 4 b c ## 5 &lt;NA&gt; &lt;NA&gt; There is only one variation of unite() since it is a many to one mapping. The arguments passed to unite() will always be concatenated to single result. "],
["chapter-13-relational-data.html", "Chapter 13 - Relational data 13.2 - nycflights13 13.3 - Keys 13.4 - Mutating joins 13.5 - Filtering joins", " Chapter 13 - Relational data Load the libraries needed for these exercises. library(nycflights13) library(tidyverse) 13.2 - nycflights13 Problem 1 Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine? Latitude and longitude from the airports table and origin and destination from the flights table would be needed. Problem 2 I forgot to draw the relationship between weather and airports. What is the relationship and how should it appear in the diagram? The relationship is between origin from weather and faa from airports. It should be drawn as an arrow around the the flights table. Problem 3 weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with flights? Destination. Problem 4 We know that some days of the year are “special”, and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables? It would create a table of observations for days that are special that could relate to the flights table through day, month, and year. 13.3 - Keys Problem 1 Add a surrogate key to flights. flights %&gt;% mutate(surrogate_key = row_number()) ## # A tibble: 336,776 x 20 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 13 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, surrogate_key &lt;int&gt; Problem 2 Identify the keys in the following datasets Lahman::Batting babynames::babynames nasaweather::atmos fueleconomy::vehicles ggplot2::diamonds (You might need to install some packages and read some documentation.) Lahman::Batting - playerID, yearID, and stint library(Lahman) Batting &lt;- as_tibble(Batting) Batting %&gt;% count(playerID, yearID, stint) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 4 ## # ... with 4 variables: playerID &lt;chr&gt;, yearID &lt;int&gt;, stint &lt;int&gt;, n &lt;int&gt; babynames::babynames library(babynames) babynames &lt;- as_tibble(babynames) babynames %&gt;% count(year, sex, name) %&gt;% filter(nn &gt; 1) ## # A tibble: 0 x 4 ## # ... with 4 variables: year &lt;dbl&gt;, sex &lt;chr&gt;, name &lt;chr&gt;, nn &lt;int&gt; nasaweather::atmos - lat, long, year, month library(nasaweather) ## ## Attaching package: &#39;nasaweather&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## storms atmos &lt;- as_tibble(atmos) atmos %&gt;% count(lat, long, year, month) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 5 ## # ... with 5 variables: lat &lt;dbl&gt;, long &lt;dbl&gt;, year &lt;int&gt;, month &lt;int&gt;, ## # n &lt;int&gt; fueleconomy::vehicles - library(fueleconomy) vehicles &lt;- as_tibble(vehicles) vehicles %&gt;% count(id) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 2 ## # ... with 2 variables: id &lt;int&gt;, n &lt;int&gt; ggplot2::diamonds - none! diamonds &lt;- as_tibble(diamonds) diamonds %&gt;% count(carat, cut, color, clarity, depth, table, price, x, y, z) %&gt;% filter(n &gt; 1) ## # A tibble: 143 x 11 ## carat cut color clarity depth table price x y z n ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.3 Good J VS1 63.4 57 394 4.23 4.26 2.69 2 ## 2 0.3 Very Good G VS2 63 55 526 4.29 4.31 2.71 2 ## 3 0.3 Very Good J VS1 63.4 57 506 4.26 4.23 2.69 2 ## 4 0.3 Premium D SI1 62.2 58 709 4.31 4.28 2.67 2 ## 5 0.3 Ideal G VS2 63 55 675 4.31 4.29 2.71 2 ## 6 0.3 Ideal G IF 62.1 55 863 4.32 4.35 2.69 2 ## 7 0.3 Ideal H SI1 62.2 57 450 4.26 4.29 2.66 2 ## 8 0.3 Ideal H SI1 62.2 57 450 4.27 4.28 2.66 2 ## 9 0.31 Good D SI1 63.5 56 571 4.29 4.31 2.73 2 ## 10 0.31 Very Good D SI1 63.5 56 732 4.31 4.29 2.73 2 ## # ... with 133 more rows Problem 3 Draw a diagram illustrating the connections between the Batting, Master, and Salaries tables in the Lahman package. Draw another diagram that shows the relationship between Master, Managers, AwardsManagers. Problem 4 How would you characterise the relationship between the Batting, Pitching, and Fielding tables? 13.4 - Mutating joins Problem 1 Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States: airports %&gt;% semi_join(flights, c(&quot;faa&quot; = &quot;dest&quot;)) %&gt;% ggplot(aes(lon, lat)) + borders(&quot;state&quot;) + geom_point() + coord_quickmap() (Don’t worry if you don’t understand what semi_join() does — you’ll learn about it next.) You might want to use the size or colour of the points to display the average delay for each airport. flights %&gt;% group_by(dest) %&gt;% summarize(arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% ggplot(aes(lon, lat, size = arr_delay), alpha = 0.5) + borders(&quot;state&quot;) + geom_point(alpha = 0.3, color = &quot;blue&quot;) + coord_quickmap() ## ## Attaching package: &#39;maps&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## map ## Warning: Removed 5 rows containing missing values (geom_point). Problem 2 Add the location of the origin and destination (i.e. the lat and lon) to flights. airports2 &lt;- airports %&gt;% select(faa, lat, lon) flights %&gt;% left_join(airports2, c(&quot;origin&quot; = &quot;faa&quot;)) %&gt;% rename(origin_lat = lat, origin_lon = lon) %&gt;% left_join(airports2, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% rename(dest_lat = lat, dest_lon = lon) ## # A tibble: 336,776 x 23 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 16 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, origin_lat &lt;dbl&gt;, origin_lon &lt;dbl&gt;, ## # dest_lat &lt;dbl&gt;, dest_lon &lt;dbl&gt; Problem 3 Is there a relationship between the age of a plane and its delays? flights %&gt;% left_join(planes, &quot;tailnum&quot;) %&gt;% ggplot(aes(year.y, dep_delay)) + geom_point(alpha = 0.2) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 61980 rows containing non-finite values (stat_smooth). ## Warning: Removed 61980 rows containing missing values (geom_point). flights %&gt;% left_join(planes, &quot;tailnum&quot;) %&gt;% ggplot(aes(year.y, arr_delay)) + geom_point(alpha = 0.2) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 62923 rows containing non-finite values (stat_smooth). ## Warning: Removed 62923 rows containing missing values (geom_point). Problem 4 What weather conditions make it more likely to see a delay? flight_weather &lt;- flights %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% select(year, month, day, arr_delay, dep_delay, temp:visib, -wind_dir) %&gt;% filter(complete.cases(.)) %&gt;% mutate(arr_delay_categorical = cut_number(arr_delay, 5)) flight_weather %&gt;% summarize_all(funs(sum(is.na(.)))) ## # A tibble: 1 x 14 ## year month day arr_delay dep_delay temp dewp humid wind_speed ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 0 0 0 ## # ... with 5 more variables: wind_gust &lt;int&gt;, precip &lt;int&gt;, ## # pressure &lt;int&gt;, visib &lt;int&gt;, arr_delay_categorical &lt;int&gt; flight_means &lt;- flight_weather %&gt;% select(arr_delay_categorical, temp:visib) %&gt;% group_by(arr_delay_categorical) %&gt;% summarize_all(funs(mean(.))) flight_means %&gt;% gather(key = weather_type, value = value, -arr_delay_categorical) %&gt;% ggplot(aes(arr_delay_categorical, value)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~weather_type, scales = &quot;free&quot;) lm(arr_delay ~ dewp + humid + precip + pressure + temp + visib + wind_gust + wind_speed, data = flight_weather) ## ## Call: ## lm(formula = arr_delay ~ dewp + humid + precip + pressure + temp + ## visib + wind_gust + wind_speed, data = flight_weather) ## ## Coefficients: ## (Intercept) dewp humid precip pressure ## 538.52374 0.85046 -0.44252 98.37679 -0.47439 ## temp visib wind_gust wind_speed ## -0.66531 -2.40736 0.08383 NA Problem 5 What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather. flight_weather &lt;- flights %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% select(year, month, day, arr_delay, dep_delay, temp:visib, -wind_dir) %&gt;% filter(complete.cases(.)) %&gt;% mutate(dep_delay_categorical = cut_number(dep_delay, 5)) airports2 &lt;- airports %&gt;% select(faa, lat, lon) flight_airports &lt;- flights %&gt;% left_join(airports2, c(&quot;origin&quot; = &quot;faa&quot;)) %&gt;% rename(origin_lat = lat, origin_lon = lon) %&gt;% left_join(airports2, c(&quot;dest&quot; = &quot;faa&quot;)) %&gt;% rename(dest_lat = lat, dest_lon = lon) %&gt;% left_join(weather, c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) %&gt;% filter(complete.cases(.)) %&gt;% filter(month == 6 &amp; day == 13) flight_airports %&gt;% ggplot(aes(dep_delay)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. flight_airports %&gt;% ggplot(aes(arr_delay)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. flight_airports %&gt;% ggplot(aes(dest_lon, dest_lat, size = dep_delay)) + borders(&quot;state&quot;) + geom_point(alpha = 0.2) + coord_quickmap() Two derechos hit the United States East Coast on June 13, 2013. This caused significant departure delays at several airports. 13.5 - Filtering joins Problem 1 What does it mean for a flight to have a missing tailnum? What do the tail numbers that don’t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.) planes &lt;- as_tibble(planes) flights &lt;- as_tibble(flights) no_tailnum &lt;- flights %&gt;% anti_join(planes, &quot;tailnum&quot;) count(no_tailnum, carrier) ## # A tibble: 10 x 2 ## carrier n ## &lt;chr&gt; &lt;int&gt; ## 1 9E 1044 ## 2 AA 22558 ## 3 B6 830 ## 4 DL 110 ## 5 F9 50 ## 6 FL 187 ## 7 MQ 25397 ## 8 UA 1693 ## 9 US 699 ## 10 WN 38 count(no_tailnum, origin) ## # A tibble: 3 x 2 ## origin n ## &lt;chr&gt; &lt;int&gt; ## 1 EWR 5908 ## 2 JFK 17137 ## 3 LGA 29561 Departures from LaGuardia (LGA), JFK, and Newark (EWR) account for 100 percent of the planes without tail numbers. American Airlines (AA) and Envoy Airline (MQ) account for 90 percent of the planes without tail numbers. Problem 2 Filter flights to only show flights with planes that have flown at least 100 flights. flights100 &lt;- flights %&gt;% group_by(tailnum) %&gt;% count(tailnum) %&gt;% filter(n &gt;= 100) semi_join(flights, flights100, &quot;tailnum&quot;) ## # A tibble: 230,902 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 544 545 -1 1004 ## 4 2013 1 1 554 558 -4 740 ## 5 2013 1 1 555 600 -5 913 ## 6 2013 1 1 557 600 -3 709 ## 7 2013 1 1 557 600 -3 838 ## 8 2013 1 1 558 600 -2 849 ## 9 2013 1 1 558 600 -2 853 ## 10 2013 1 1 558 600 -2 923 ## # ... with 230,892 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Problem 3 Combine fueleconomy::vehicles and fueleconomy::common to find only the records for the most common models. library(fueleconomy) semi_join(vehicles, common) ## Joining, by = c(&quot;make&quot;, &quot;model&quot;) ## # A tibble: 14,531 x 12 ## id make model year class trans drive cyl displ fuel hwy cty ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1833 Acura Inte… 1986 Subc… Auto… Fron… 4 1.6 Regu… 28 22 ## 2 1834 Acura Inte… 1986 Subc… Manu… Fron… 4 1.6 Regu… 28 23 ## 3 3037 Acura Inte… 1987 Subc… Auto… Fron… 4 1.6 Regu… 28 22 ## 4 3038 Acura Inte… 1987 Subc… Manu… Fron… 4 1.6 Regu… 28 23 ## 5 4183 Acura Inte… 1988 Subc… Auto… Fron… 4 1.6 Regu… 27 22 ## 6 4184 Acura Inte… 1988 Subc… Manu… Fron… 4 1.6 Regu… 28 23 ## 7 5303 Acura Inte… 1989 Subc… Auto… Fron… 4 1.6 Regu… 27 22 ## 8 5304 Acura Inte… 1989 Subc… Manu… Fron… 4 1.6 Regu… 28 23 ## 9 6442 Acura Inte… 1990 Subc… Auto… Fron… 4 1.8 Regu… 24 20 ## 10 6443 Acura Inte… 1990 Subc… Manu… Fron… 4 1.8 Regu… 26 21 ## # ... with 14,521 more rows Problem 4 Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns? daily_delay &lt;- flights %&gt;% filter(arr_delay &gt; 0) %&gt;% group_by(year, month, day) %&gt;% summarize(arr_delay = sum(arr_delay, na.rm = TRUE)) %&gt;% mutate(yesterday = arr_delay + lag(arr_delay), tomorrow = arr_delay + lead(arr_delay)) %&gt;% ungroup() %&gt;% filter(min_rank(-tomorrow) == 1 | min_rank(-yesterday) == 1) Problem 5 What does anti_join(flights, airports, by = c(“dest” = “faa”)) tell you? What does anti_join(airports, flights, by = c(“faa” = “dest”)) tell you? Problem 6 You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned above. "],
["chapter-14-strings.html", "Chapter 14 - Strings 14.2 - String basics 14.3.2 - Anchors 14.3.2 - Character classes and alternatives 14.3.4 - Repetition 14.3.5 - Grouping and backreferences 14.4 - Tools 14.4.3 - Extract Matches 14.4.4 - Grouped matches 14.4.5 - Replacing matches 14.4.6 - Splitting 14.5 - Other types of pattern 14.6 - Other uses of regular expressions", " Chapter 14 - Strings Load the libraries needed for these exercises. library(tidyverse) 14.2 - String basics Problem 1 In code that doesn’t use stringr, you’ll often see paste() and paste0(). What’s the difference between the two functions? What stringr function are they equivalent to? How do the functions differ in their handling of NA? paste() automatically includes a space between each character string it combines. paste0() does not include a space. They are ~equivalent to str_c() from library(stringr). paste() and paste0() include NA as text. str_c() returns an NA for the entire string if the string contains an NA. Problem 2 In your own words, describe the difference between the sep and collapse arguments to str_c(). sep is a character string to insert between input vectors. Its input vector and output vector always have the same length. length(str_c(&quot;Letter&quot;, letters, sep = &quot;: &quot;)) ## [1] 26 collapse is a character string to insert between input vectors and to turn the vector into a single string. collapse always returns a vector with length one. length(str_c(&quot;Letter&quot;, letters, collapse = &quot;: &quot;)) ## [1] 1 Problem 3 Use str_length() and str_sub() to extract the middle character from a string. What will you do if the string has an even number of characters. string_middle &lt;- function(string) { string_length &lt;- str_length(string) if (string_length %% 2 == 1) { str_sub(string, floor((string_length + 1) / 2), ceiling((string_length) / 2)) } else if (string_length %% 2 == 0) { NULL } else {&quot;Error!&quot;} } string_middle(&quot;abc&quot;) ## [1] &quot;b&quot; string_middle(&quot;abcd&quot;) ## NULL It returned a NULL if string_length() is even. Problem 4 What does str_wrap() do? When might you want to use it? It implements the Knuth-Plass paragraph wrapping algorithm. It “breaks text paragraphs into lines, of total width - if it is possible - of at most given width. graph &lt;- &quot;It implements the Knuth-Plass paragraph wrapping algorithm. It breaks text paragraphs into lines, of total width - if it is possible - of at most given width.&quot; str_wrap(graph, width = 20) ## [1] &quot;It implements\\nthe Knuth-Plass\\nparagraph wrapping\\nalgorithm. It breaks\\ntext paragraphs\\ninto lines, of total\\nwidth - if it is\\npossible - of at\\nmost given width.&quot; This could be useful for formatting in html and rmarkdown. Especially for graphics and sidebars. Custom width is useful - especially in reproducible documents. Problem 5 What does str_trim() do? What’s the opposite of str_trim()? It trims whitespace from the left, right, or both sides of a character string. It is the string version of trimws(). str_pad() is the opposite of str_trim(). It adds whitespace to the left, right, or both sides of a character string. Problem 6 Write a function that turns (e.g.) a vector c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) into a string a, b, and c. Think carefully about what it should do if given a vector of length 0, 1, or 2. list_maker &lt;- function(string) { if (length(string) &gt; 1) { stringa &lt;- string[1:length(string)-1] stringb &lt;- string[length(string)] stringa &lt;- str_c(stringa, collapse = &quot;, &quot;) str_c(stringa, &quot;, and &quot;, stringb, collapse = &quot;&quot;) } else { string } } string &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) list_maker(string) ## [1] &quot;a, b, c, d, and e&quot; 14.3 - Matching patterns with regular expressions {-} Problem 1 Explain why each of these strings don’t match a : “&quot;,”\\“,”\\&quot;. “&quot; escapes the quotation mark and isn’t a valid character string in R. “\\” returns a character string with two backslashes which doesn’t match one backslash. “\\&quot; escapes the quotation mark and isn’t a valid character string. Problem 2 How would you match the sequence “’? Problem 3 What patterns will the regular expression ...... match? How would you represent it as a string? It will match a string of three periods separated by characters. \\\\..\\\\..\\\\... str_view(&quot;.a.b.c&quot;, &quot;\\\\..\\\\..\\\\..&quot;) 14.3.2 - Anchors Problem 1 How would you match the literal string “\\(^\\)”? x &lt;- &quot;$^$&quot; str_view(x, &quot;\\\\$\\\\^\\\\$&quot;) Problem 2 Given the corpus of common words in stringr::words, create regular expressions that will find all words that: Start with “y” str_view(words, &quot;^y&quot;, match = TRUE) End with “x” table(str_detect(words, &quot;x$&quot;)) ## ## FALSE TRUE ## 976 4 Are exactly three letters long. (Don’t cheat by using str_length()!) table(str_detect(words, &quot;^...$&quot;)) ## ## FALSE TRUE ## 870 110 Have seven letters or more. table(str_detect(words, &quot;^.......&quot;)) ## ## FALSE TRUE ## 761 219 14.3.2 - Character classes and alternatives Problem 1 Create regular expressions to find all words that: Start with a vowel str_view(words[1:10], &quot;^[aeiou]&quot;, match = TRUE) Only contain consonants. (Hint: think about match “not”-vowels.) str_view(words, &quot;^[^aeiou]+$&quot;, match = TRUE) I’m not sure if this can be done with + which is introduced on page 204 after the exercises. End with ed, but not with eed. str_view(words, &quot;[^e]ed$&quot;, match = TRUE) End with ing or ize. str_view(words, &quot;ing$|ize$&quot;, match = TRUE) Problem 2 Empirically verify the rule “i before e except after c.” Let’s try this with proof by contradiction. We need to look for two conditions: ie after c ei str_view(words, &quot;ei|[c]ie&quot;, match = TRUE) Six words violate the rules. “i before e except after c” is and always will be rubbish. Problem 3 Is “q” always followed by a “u”? Proof by contradiction: look for a “q” not followed by a “u”. str_view(words, &quot;q^[u]&quot;, match = TRUE) Yes, “q” is always followed by a “u” in this data set. Problem 4 Write a regular expression that matches a word if it’s probably written in British English, not American English. str_view(words, &quot;our|ise|ogue&quot;, match = TRUE) Problem 5 Create a regular expression that will match telephone numbers as commonly written in your country. phone &lt;- c(&quot;212-555-7891&quot;, &quot;(212)-555-7891&quot;) str_view(phone, &quot;\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d\\\\d|\\\\(\\\\d\\\\d\\\\d\\\\)-\\\\d\\\\d\\\\d-\\\\d\\\\d\\\\d\\\\d&quot;, match = TRUE) 14.3.4 - Repetition Problem 1 Describe the equivalents of ?, +, and * in {n, m} form. ? == {1} + == {1,} * == {0,} Problem 2 Describe in words what these regular expressions match (read carefully to if I’m using a regular expression or a string that defines a regular expressions): ^.*$ matches an entire string. ^ matches the start of a string. . is any character which is repeated 0 or more times with *. $ matches the end of a string. &quot;\\\\{.+\\\\}&quot; 3.\\d{4}-\\d{2}-\\d{2} matches exactly 4 digits followed by a dash followed by exactly two digits followed by a dash followed by exactly two digits. This is the same as the ISO8601 date international standard. \\\\\\\\{4} matches exactly four backslashes. Problem 3 Create regular expressions to find all words that: Start with three consonants. string &lt;- c(&quot;scratch&quot;, &quot;apple&quot;) str_view(string, &quot;^[^aeiou]{3}&quot;) Have three or more vowels in a row. string &lt;- c(&quot;scratch&quot;, &quot;aaapple&quot;) str_view(string, &quot;^[aeiou]{3,}&quot;) Have two or more vowel consonant pairs in a row. string &lt;- c(&quot;banana&quot;, &quot;coconut&quot;) str_view(string, &quot;([aeiou][^aeiou]){2,}&quot;) Problem 4 Solve the beginner regexp crosswords at http://regexcrossword.com/challenges/beginner 14.3.5 - Grouping and backreferences Problem 1 Describe in words what these expressions will match: (.)\\1\\1 will match any string of three repeated letters or symbols. &quot;(.)(.)\\\\2\\\\1&quot; will match a four letter palindrome (spelled the same forwards and backwards). (..)\\1 will match a four letter string where the second half is a reptition of the first half. &quot;(.).\\\\1.\\\\1&quot; will match and repetition of the same character three times where each character is spearated by a character (ex. “ababa” and “&amp;&amp;&amp;&amp;&amp;”). &quot;(.)(.)(.)*\\\\3\\\\2\\\\1&quot; will match a string of characters where the first three characters are repeted in reverse and the middle character can be repeated multiple times (ex. “abccba” and “abcccccba”). Problem 2 0.0.0.0.1 2. Construct regular expressions to match words that: Start and end with the same character. &quot;^(.).*\\\\1$&quot; Contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice) &quot;.*(..).*\\\\1.*&quot; Contain one letter repeated in at least three places (e.g., “eleven” contains three “e”s). &quot;.*(.).*\\\\1.*\\\\1.*&quot; 14.4 - Tools Problem 1 For each of the following challenges, try solving it by using both a singular regular expression, and a combination of multiple str_detect() calls: 1. Find all words that start of end with x. str_detect(words, &quot;^x.*x$&quot;) &amp; str_detect(str_detect(words, &quot;^x&quot;), &quot;x$&quot;) 2. Find all words that start with a vowel and end with a consonant. str_detect(words, &quot;^[aeiou].*[^aeiou]$&quot;) &amp; str_detect(str_detect(words, &quot;^[aeiou]&quot;), &quot;[^aeiou]$&quot;) 3. Are there any words that contain at least one of each different vowel? TODO(aaron): hmm? 4. What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator) as_tibble(words) %&gt;% mutate(vowels = str_count(value, &quot;[aeiou]&quot;)) %&gt;% filter(vowels == max(vowels)) ## # A tibble: 8 x 2 ## value vowels ## &lt;chr&gt; &lt;int&gt; ## 1 appropriate 5 ## 2 associate 5 ## 3 available 5 ## 4 colleague 5 ## 5 encourage 5 ## 6 experience 5 ## 7 individual 5 ## 8 television 5 as_tibble(words) %&gt;% mutate(letters = str_count(value), vowels = str_count(value, &quot;[aeiou]&quot;), proportion = vowels / letters) %&gt;% filter(proportion == max(proportion)) ## # A tibble: 1 x 4 ## value letters vowels proportion ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 1 1 14.4.3 - Extract Matches Problem 1 In the previous example, you might have noticed that the regular expression matched “flickered”, which is not a color. Modify the regex to fix the problem. colors &lt;- &quot;\\\\b(red|orange|yellow|green|blue|purple)\\\\b&quot; more &lt;- sentences[str_count(sentences, colors) &gt; 1] str_view_all(more, colors) Problem 2 From the Harvard sentences data, extract: 1. The first word from each sentence. str_extract(sentences, &quot;[^\\\\s]*&quot;) 2. All words ending in ing. str_extract_all(sentences, &quot;\\\\b[^\\\\s]*ing\\\\b&quot;) 3. All plurals. TODO(aaron): hmm? 14.4.4 - Grouped matches Problem 1 Find all words that come after a “number” like “one”, “two”, “three”, etc. Pull out the number and the word. numbers &lt;- &quot;([Oo]ne|[Tt]wo|[Tt]hree|[Ff]our|[Ff]ive|[Ss]ix|[Ss]even|[Ee]ight|[Nn]ine|[Tt]en) ([^ ]+)&quot; tibble(sentence = sentences) %&gt;% extract( sentence, c(&quot;number&quot;, &quot;word&quot;), numbers, remove = FALSE ) %&gt;% filter(!is.na(number)) ## # A tibble: 46 x 3 ## sentence number word ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Rice is often served in round bowls. ten served ## 2 Four hours of steady work faced us. Four hours ## 3 Two blue fish swam in the tank. Two blue ## 4 Lift the square stone over the fence. one over ## 5 The rope will bind the seven books at once. seven books ## 6 The two met while playing on the sand. two met ## 7 There are more than two factors here. two factors ## 8 He lay prone and hardly moved a limb. one and ## 9 Ten pins were set in order. Ten pins ## 10 Type out three lists of orders. three lists ## # ... with 36 more rows Problem 2 Find all contractions. Separate out the pieces before and after the apostrophe. &quot;[^ ]*'[^ ]*&quot; could be used, but it returns possessive nouns. The following string of regular expressions gets around this problem. contractions &lt;- &quot;[^ ]*&#39;m|[^ ]*n&#39;t|[^ ]*&#39;ve|[^ ]*&#39;d|[^ ]*&#39;re|[^ ]*&#39;ll|[Ll]et&#39;s|[Ss]he&#39;s|[Hh]e&#39;s&quot; tibble(sentence = sentences) %&gt;% mutate(contraction = str_extract(sentences, contractions)) %&gt;% filter(!is.na(contraction)) %&gt;% extract(contraction, c(&quot;before&quot;, &quot;apostrophe&quot;, &quot;after&quot;), &quot;(.*)(&#39;)(.*)&quot;) ## # A tibble: 4 x 4 ## sentence before apostrophe after ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Open the crate but don&#39;t break the glass. don &#39; t ## 2 Let&#39;s all join as we sing the last chorus. Let &#39; s ## 3 We don&#39;t get much money but we have fun. don &#39; t ## 4 We don&#39;t like to admit our small faults. don &#39; t 14.4.5 - Replacing matches Problem 1 Replace all forward slashes in a string with backslashes. str_replace_all(&quot;a/b/c&quot;, &quot;/&quot;, &quot;\\\\\\\\&quot;) Problem 2 Implement a simple version of str_to_lower() using str_replace_all(). str_replace_all(&quot;AbC&quot;, &quot;[A-Z]&quot;, tolower) Problem 3 Switch the first and last letters in words. Which of those strings are still words? new.words &lt;- str_replace(words, &quot;(^.)(.*)(.$)&quot;, &quot;\\\\3\\\\2\\\\1&quot;) words[new.words %in% words] ## [1] &quot;a&quot; &quot;america&quot; &quot;area&quot; &quot;dad&quot; &quot;dead&quot; ## [6] &quot;deal&quot; &quot;dear&quot; &quot;depend&quot; &quot;dog&quot; &quot;educate&quot; ## [11] &quot;else&quot; &quot;encourage&quot; &quot;engine&quot; &quot;europe&quot; &quot;evidence&quot; ## [16] &quot;example&quot; &quot;excuse&quot; &quot;exercise&quot; &quot;expense&quot; &quot;experience&quot; ## [21] &quot;eye&quot; &quot;god&quot; &quot;health&quot; &quot;high&quot; &quot;knock&quot; ## [26] &quot;lead&quot; &quot;level&quot; &quot;local&quot; &quot;nation&quot; &quot;no&quot; ## [31] &quot;non&quot; &quot;on&quot; &quot;rather&quot; &quot;read&quot; &quot;refer&quot; ## [36] &quot;remember&quot; &quot;serious&quot; &quot;stairs&quot; &quot;test&quot; &quot;tonight&quot; ## [41] &quot;transport&quot; &quot;treat&quot; &quot;trust&quot; &quot;window&quot; &quot;yesterday&quot; 14.4.6 - Splitting Problem 1 Split up a string like “apples, pears, and bananas” into individual components. str_split(&quot;apples, pears, and bananas&quot;, boundary(&quot;word&quot;)) Problem 2 Why is it better to split up by boundary(“word”) than &quot; “? &quot; &quot; captures non-words like the space after the period while boundary(&quot;word&quot;) only captures words. Problem 3 What does splitting with an empty string (“”) do? Experiment and read the documentation. “An empty pattern,”“, is equivalent to boundary(”character“).” 14.5 - Other types of pattern Problem 1 How would you find all strings containing “&quot; with regex() versus fixed. regex(&quot;\\\\\\\\&quot;) &amp; fixed(&quot;\\&quot;) Problem 2 What are the five most common words in setences? The five most common words are “the”, “a”, “of”, “to”, and “and”. str_split(sentences, boundary(&quot;word&quot;)) %&gt;% flatten_chr() %&gt;% str_to_lower() %&gt;% as_tibble() %&gt;% group_by(value) %&gt;% count() %&gt;% arrange(-n) %&gt;% ungroup() %&gt;% top_n(5) ## Selecting by n ## # A tibble: 5 x 2 ## value n ## &lt;chr&gt; &lt;int&gt; ## 1 the 751 ## 2 a 202 ## 3 of 132 ## 4 to 123 ## 5 and 118 14.6 - Other uses of regular expressions Problem 1 Find the stringi function that: 1. Count the number of words stri_count_words 2. Find duplicated strings. stri_duplicated() 3. Generate random text. stri_rand_strings() Problem 2 How do you control the language that str_sort() uses for sorting? With the locale = argument in the opts_collator argument. "],
["chapter-15-factors.html", "Chapter 15 - Factors 15.3 - General Social Survey 15.4 - Modifying factor order 15.5 - Modifying factor levels", " Chapter 15 - Factors Load the libraries needed for these exercises. library(tidyverse) library(forcats) 15.3 - General Social Survey Problem 1 Explore the distribution of rincome (reported income). What makes the default bar chart hard to understand? How could you improve the plot? There are so many bars that the x-axis labels overlap. ggplot(gss_cat, aes(rincome)) + geom_bar() Let’s rotate the labels. ggplot(gss_cat, aes(rincome)) + geom_bar() + theme(axis.text.x = element_text(angle=90)) Problem 2 What is the most common relig in this survey? What’s the most common partyid? gss_cat %&gt;% count(relig) %&gt;% top_n(1) ## # A tibble: 1 x 2 ## relig n ## &lt;fct&gt; &lt;int&gt; ## 1 Protestant 10846 gss_cat %&gt;% count(partyid) %&gt;% top_n(1) ## # A tibble: 1 x 2 ## partyid n ## &lt;fct&gt; &lt;int&gt; ## 1 Independent 4119 Problem 3 Which relig does denom apply to? How can you find out without a table? How can you find out with a vizualization? denom applies to Protestant. gss_cat %&gt;% group_by(denom) %&gt;% count(relig) ## # A tibble: 47 x 3 ## # Groups: denom [30] ## denom relig n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 No answer No answer 93 ## 2 No answer Christian 2 ## 3 No answer Protestant 22 ## 4 Don&#39;t know Christian 11 ## 5 Don&#39;t know Protestant 41 ## 6 No denomination Christian 452 ## 7 No denomination Other 7 ## 8 No denomination Protestant 1224 ## 9 Other Protestant 2534 ## 10 Episcopal Protestant 397 ## # ... with 37 more rows gss_cat %&gt;% group_by(relig, denom) %&gt;% summarize(n = n()) %&gt;% ggplot(aes(relig, denom, size = n)) + geom_point() + theme(axis.text.x=element_text(angle = 90)) 15.4 - Modifying factor order Problem 1 There are some conspicuously high numbers in tvhours. Is the mean a good summary? Exteme values bias the mean. tvhours is skewed to the right and median may be a better summary statistic. gss_cat %&gt;% ggplot(aes(tvhours)) + geom_histogram() mean(gss_cat$tvhours, na.rm = TRUE) ## [1] 2.980771 median(gss_cat$tvhours, na.rm = TRUE) ## [1] 2 Problem 2 For each factor in gss_cat identify whether the order of the levels is arbitrary or principled. marital: arbitrary age: principled race: arbitrary rincome: principled partyid: arbitrary relig: arbitrary denom: arbitrary Problem 3 Why did moving “Not Applicable” to the front of the levels move it to the bottom of the plot? Factors are shown in reverse order from top to bottom when coord_flip is used. gss_cat %&gt;% mutate(race = fct_relevel(race, &quot;Not applicable&quot;)) %&gt;% ggplot(aes(race)) + geom_bar() + coord_flip() + scale_x_discrete(drop = FALSE) 15.5 - Modifying factor levels Problem 1 How have the proportions of people identifying as Democrat, Republican, and Independent changed over time? gss_cat %&gt;% mutate(partyid = fct_collapse(partyid, other = c(&quot;No answer&quot;, &quot;Don&#39;t know&quot;, &quot;Other party&quot;), rep = c(&quot;Strong republican&quot;, &quot;Not str republican&quot;), ind = c(&quot;Ind,near rep&quot;, &quot;Independent&quot;, &quot;Ind,near dem&quot;), dem = c(&quot;Not str democrat&quot;, &quot;Strong democrat&quot;))) %&gt;% filter(partyid != &quot;other&quot;) %&gt;% ggplot(aes(x = year, ..prop.., fill = partyid)) + geom_bar(position = &quot;dodge&quot;) + scale_x_continuous(breaks = c(2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014)) Problem 2 How could you collapse rincome into a small set of categories? gss_cat %&gt;% mutate(rincome = fct_collapse(rincome, `More than $10,000` = c(&quot;$10000 - 14999&quot;, &quot;$15000 - 19999&quot;, &quot;$20000 - 24999&quot;, &quot;$25000 or more&quot;), `Less than $10,000` = c(&quot;Lt $1000&quot;, &quot;$1000 to 2999&quot;, &quot;$3000 to 3999&quot;, &quot;$4000 to 4999&quot;, &quot;$5000 to 5999&quot;, &quot;$6000 to 6999&quot;, &quot;$7000 to 7999&quot;, &quot;$8000 to 9999&quot;))) %&gt;% mutate(rincome = fct_lump(rincome, n = 3)) %&gt;% count(rincome, sort = TRUE) ## # A tibble: 4 x 2 ## rincome n ## &lt;fct&gt; &lt;int&gt; ## 1 More than $10,000 10862 ## 2 Not applicable 7043 ## 3 Less than $10,000 2153 ## 4 Other 1425 "],
["chapter-16-dates-and-times.html", "Chapter 16 - Dates and times 16.2 - Creating date/times 16.3 - Date-time components 16.4 - Time spans", " Chapter 16 - Dates and times Load the libraries needed for these exercises. library(tidyverse) library(lubridate) library(nycflights13) 16.2 - Creating date/times Problem 1 What happens if you parse a string that contains invalid dates? ymd(c(&quot;2010-10-10&quot;, &quot;bananas&quot;)) ## Warning: 1 failed to parse. ## [1] &quot;2010-10-10&quot; NA Warning message: 1 failed to parse. Problem 2 What does the tzone argument to today() do? Why is it important? tzone controls the time zone used when finding the current date. It defaults to the system time zone. It is important because every hour a different time zone moves from today to tomorrow and when analyzing data from another time zone dates can change. Problem 3 Use the appropriate lubridate function to parse the following dates: d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 mdy(d1) ## [1] &quot;2010-01-01&quot; ymd(d2) ## [1] &quot;2015-03-07&quot; dmy(d3) ## [1] &quot;2017-06-06&quot; mdy(d4) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; mdy(d5) ## [1] &quot;2014-12-30&quot; 16.3 - Date-time components make_datetime_100 &lt;- function(year, month, day, time) { make_datetime(year, month, day, time %/% 100, time %% 100) } flights_dt &lt;- flights %&gt;% filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% mutate( dep_time = make_datetime_100(year, month, day, dep_time), arr_time = make_datetime_100(year, month, day, arr_time), sched_dep_time = make_datetime_100(year, month, day, sched_dep_time), sched_arr_time = make_datetime_100(year, month, day, sched_arr_time) ) %&gt;% select(origin, dest, ends_with(&quot;delay&quot;), ends_with(&quot;time&quot;)) Problem 1 How does the distribution of flight times within a day change over the course of the year? flights_dt %&gt;% mutate(dep_hour = update(dep_time, yday = 1), month = month(dep_time, label = TRUE)) %&gt;% ggplot(aes(dep_hour, color = month)) + geom_freqpoly(binwidth = 900) + labs(title = &quot;Distribution of Flight Times by Month&quot;) Problem 2 Compare dep_time, sched_dep_time, and dep_delay. Are they consistent? Explain your findings. dep_time, sched_dep_time, and dep_delay are mostly consistent. The only issue is when delays extend past midnight. The value for day doesn’t increase for dep_time when a a flight is delayed beyond its scheduled day. flights_dt %&gt;% mutate(dep_time2 = sched_dep_time + dep_delay * 60) %&gt;% filter(dep_time != dep_time2) %&gt;% select(sched_dep_time, dep_time, dep_time2) ## # A tibble: 1,205 x 3 ## sched_dep_time dep_time dep_time2 ## &lt;dttm&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 2013-01-01 18:35:00 2013-01-01 08:48:00 2013-01-02 08:48:00 ## 2 2013-01-02 23:59:00 2013-01-02 00:42:00 2013-01-03 00:42:00 ## 3 2013-01-02 22:50:00 2013-01-02 01:26:00 2013-01-03 01:26:00 ## 4 2013-01-03 23:59:00 2013-01-03 00:32:00 2013-01-04 00:32:00 ## 5 2013-01-03 21:45:00 2013-01-03 00:50:00 2013-01-04 00:50:00 ## 6 2013-01-03 23:59:00 2013-01-03 02:35:00 2013-01-04 02:35:00 ## 7 2013-01-04 23:59:00 2013-01-04 00:25:00 2013-01-05 00:25:00 ## 8 2013-01-04 22:45:00 2013-01-04 01:06:00 2013-01-05 01:06:00 ## 9 2013-01-05 23:59:00 2013-01-05 00:14:00 2013-01-06 00:14:00 ## 10 2013-01-05 22:30:00 2013-01-05 00:37:00 2013-01-06 00:37:00 ## # ... with 1,195 more rows Problem 3 Compare air_time with the duration between the departure and arrival. Explain your findings. (Hint: consider the location of the airport.) TODO(aaron): There is no way to explain my findings. flights_dt %&gt;% mutate(air_time_calc = as.numeric(arr_time - dep_time), air_time_diff = air_time - air_time_calc) %&gt;% select(origin, dest, air_time, air_time_calc, air_time_diff) ## # A tibble: 328,063 x 5 ## origin dest air_time air_time_calc air_time_diff ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EWR IAH 227 193 34 ## 2 LGA IAH 227 197 30 ## 3 JFK MIA 160 221 -61 ## 4 JFK BQN 183 260 -77 ## 5 LGA ATL 116 138 -22 ## 6 EWR ORD 150 106 44 ## 7 EWR FLL 158 198 -40 ## 8 LGA IAD 53 72 -19 ## 9 JFK MCO 140 161 -21 ## 10 LGA ORD 138 115 23 ## # ... with 328,053 more rows Problem 4 How does the average delay time change over the course of a day? Should you use dep_time or sched_dep_time? Why? The average delay time increases slightly over the course of a day. This makes sense. Events that delay flights, like weather, mechanical issues, and pilot flight limits, accumulate over the course of the day and increase the probability of a flight being delayed. sched_dep_time or dep_time could make sense. sched_dep_time is more useful if you’re planning on scheduling a flight and want to avoid delays! flights_dt %&gt;% mutate(sched_dep_time = update(sched_dep_time, yday = 1)) %&gt;% ggplot(aes(sched_dep_time, dep_delay)) + geom_point(alpha = 0.05) + geom_smooth() Problem 5 On what day of the week should you leave if you want to minimize the chance of a delay? Saturday boasts the lowest percentage of flights that have delayed departures and delayed arrivals. flights_dt %&gt;% mutate(day_of_week = wday(dep_time, label = TRUE), delayed = ifelse(dep_delay &gt; 0, 1, 0)) %&gt;% group_by(day_of_week) %&gt;% summarize(delay_prob = mean(delayed)) %&gt;% ggplot(aes(day_of_week, delay_prob)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label = scales::percent(delay_prob)), vjust = -0.25, size = 3) + scale_y_continuous(labels = scales::percent, limits = c(0, 0.6)) + labs(title = &quot;Percentage of Flight Departures Delayed By Day of the Week&quot;, subtitle = &quot;Flights are Delayed if They Depart &gt;= 1 Minute Behind Schedule&quot;, x = &quot;Day of the Week&quot;, y = &quot;Percentage of Flights Delayed&quot;) flights_dt %&gt;% mutate(day_of_week = wday(arr_time, label = TRUE), delayed = ifelse(arr_delay &gt; 0, 1, 0)) %&gt;% group_by(day_of_week) %&gt;% summarize(delay_prob = mean(delayed, na.rm = TRUE)) %&gt;% ggplot(aes(day_of_week, delay_prob)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label = scales::percent(delay_prob)), vjust = -0.25, size = 3) + scale_y_continuous(labels = scales::percent, limits = c(0, 0.6)) + labs(title = &quot;Percentage of Flight Arrivals Delayed By Day of the Week&quot;, subtitle = &quot;Flights are Delayed if They Arrive &gt;= 1 Minute Behind Schedule&quot;, x = &quot;Day of the Week&quot;, y = &quot;Percentage of Flights Delayed&quot;) Problem 6 What makes the distribution of diamonds$carat and flights_dep_time similar? Humans round. In the case of the diamonds, they always round up! ggplot(data = diamonds, mapping = aes(x = carat)) + geom_histogram(bins = 100) + scale_y_continuous(expand = c(0, 0), labels = scales::dollar) + labs(title = &quot;Diamond Prices Increase With Size&quot;, subtitle = &quot;Diamond Prices in Dollars and Sizes in Carats&quot;, caption = &quot;Urban Institute&quot;, x = &quot;Carat&quot;, y = &quot;Price&quot; ) flights_dt %&gt;% mutate(dep_time = update(dep_time, yday = 1)) %&gt;% ggplot(aes(dep_time)) + geom_histogram(bins = 100) Problem 7 Confirm my hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. Hint: create a binary variable that tells whether or not the flight was delayed. Early departures of scheduled flights in minutes 20-30 and minutes 50-60 is definitely a contributing factor to the disuniform distribution of average delay times on page 245. flights_dt %&gt;% mutate(Minute = minute(dep_time), dep_delay_dummy = ifelse(dep_delay &gt; 0, 1, 0), dep_delay_dummy = factor(dep_delay_dummy, labels = c(&quot;On Time&quot;, &quot;Delayed&quot;))) %&gt;% ggplot(aes(Minute, color = dep_delay_dummy)) + geom_freqpoly() + labs(title = &quot;Distribution of Minutes of Departure Times by Delay Status&quot;, y = &quot;Count&quot;) 16.4 - Time spans Problem 1 Why is there months() but no dmonths()? Unlike hours, days, and weeks, the number of months in a year never varies. Problem 2 Explaindays(overnight * 1) to someone who has just started learning R. How does it work? Overnight is a logical vector where TRUE == 1 and FALSE == 0. If it’s an overnight flight, days() add 23, 24, or 25 hours to the value depending on the day of the year. I am unsure why * 1 is necessary. Problem 3 Create a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year. ymd(&quot;2015-01-01&quot;) + months(0:11) ## [1] &quot;2015-01-01&quot; &quot;2015-02-01&quot; &quot;2015-03-01&quot; &quot;2015-04-01&quot; &quot;2015-05-01&quot; ## [6] &quot;2015-06-01&quot; &quot;2015-07-01&quot; &quot;2015-08-01&quot; &quot;2015-09-01&quot; &quot;2015-10-01&quot; ## [11] &quot;2015-11-01&quot; &quot;2015-12-01&quot; floor_date(today(), unit = &quot;year&quot;) + months(0:11) ## [1] &quot;2018-01-01&quot; &quot;2018-02-01&quot; &quot;2018-03-01&quot; &quot;2018-04-01&quot; &quot;2018-05-01&quot; ## [6] &quot;2018-06-01&quot; &quot;2018-07-01&quot; &quot;2018-08-01&quot; &quot;2018-09-01&quot; &quot;2018-10-01&quot; ## [11] &quot;2018-11-01&quot; &quot;2018-12-01&quot; Problem 4 Write a function that, given your birthday (as a date), returns how old you are in years. age &lt;- function(birthday) { (birthday %--% today()) / dyears(1) } age(ymd(&quot;1992-03-14&quot;)) ## [1] 26.2274 Problem 5 Why can’t (today() %--% (today() + years(1)) / months(1) work? There is an uneven number of parentheses. "],
["chapter-19-functions.html", "Chapter 19 - Functions 19.2 - When should you write a function? 19.3 - Functions are for humans and computers 19.4 - Conditional execution 19.5 - Function arguments", " Chapter 19 - Functions Load the libraries needed for these exercises. library(tidyverse) 19.2 - When should you write a function? Problem 1 Why is TRUE not a parameter to rescale01()? What would happen if x contained a single missing value, and na.rm was FALSE. TRUE is not a paramater to rescale01() because it does not vary from function call to function call. If x contained a single missing value, and na.rm was FALSE then rescale01() would return a vector of NAs with the length of X. Problem 2 In the second variant of rescale01(), infinite values are left unchanged. Rewrite rescale01() so that -Inf is mapped to zero and Inf is mapped to 1. rescale01 &lt;- function(x) { ifelse(x == Inf, max(x), x) rng &lt;- range(x, na.rm = TRUE, finite = TRUE) x &lt;- (x - rng[1]) / (rng[2] - rng[1]) x &lt;- ifelse(x == Inf, 1, x) ifelse(x == -Inf, 0, x) } rescale01(c(Inf, 2, 3, 1)) ## [1] 1.0 0.5 1.0 0.0 Problem 3 Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need? Can you rewrite it to be more expressive or less duplicative? missing_share &lt;- function(x) { mean(is.na(x)) } percent &lt;- function(x) { x / sum(x, na.rm = TRUE) } coef_of_variation &lt;- function(x) { sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE) } Problem 4 Follow *http://nicercode.github.io/intro/writing-functions.html* to write your own functions to compute the variance and skew of a numeric vector. \\(var(x) = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_{i}-\\bar{x})^2}\\) variance &lt;- function(x) { # remove missing values x &lt;- x[!is.na(x)] # calculate the mean xbar &lt;- mean(x) # calculate n n &lt;- length(x) # calculate square errors square_errors &lt;- (x - xbar) ^ 2 # calculate variance sum(square_errors) / (n - 1) } Sample skewness is the ratio of the third moment about the mean to the second moment about the mean raised to the power of \\(\\frac{3} {2}\\). \\(skew(x) = \\frac{n\\sqrt{n-1}}{n-2} \\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^3} {(\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2)^{3/2}}\\) skew &lt;- function(x) { # remove missing values x &lt;- x[!is.na(x)] # calculate n n &lt;- length(x) # calculate variance v &lt;- var(x) # calculate xbar xbar &lt;- mean(x) # calculate the third moment about the mean third.moment &lt;- (1/(n - 2)) * sum((x - xbar)^3) # calculate the ratio of the third moment about the mean to the second moment about the mean raised to the power of 3/2 third.moment / (var(x) ^ (3 / 2)) } Problem 5 Write both_na(), a function that takes two vectors of the same length and returns the number of positions than have an NA in both vectors. both_na &lt;- function(x, y) { # test condition that both observation are missing values missing_pairs &lt;- is.na(x) &amp; is.na(y) # sum up missing pairs sum(missing_pairs) } Problem 6 What do the following functions do? Why are they useful even though they are short? is_directory &lt;- function(x) file.info(x)$isdir This function returns a boolean for if the specified file is a directory or not. file.info() returns a lot of information and this function is useful because it extracts a simple subset of that infromation. is_readable &lt;- function(x) file.access(x, 4) == 0 This function returns a boolean for if the specified file is readable or not. It’s useful because mode doesn’t need to be specified in the function call while it is needed for file.access(). Additionally, this function extracts and summarizes an interesting subset of the information from file.access(). Problem 7 Read the complete lyrics (http://bit.ly/littlebunnyfoofoo) to “Little Bunny Foo Foo.” There’s a lot of duplication in this song. Extend the piping example to recreate the complete song, and use functions to reduce the duplication. warning &lt;- function(chance) { if (chance == 3) { goon(foo_foo, from = good_fairy, to = foo_foo) } } mouse_bop &lt;- function() { foo_foo %&gt;% hop(through = forest) %&gt;% scoop(up = field_mouse) %&gt;% bop(on = head) } down_came(good_fairy) said(audience = foo_foo, statement = &quot;Little bunny Foo Foo I don&#39;t want to see you Scooping up the field mice And bopping them on the head. I&#39;ll give you three chances, And if you don&#39;t behave, I will turn you into a goon!&quot;) mouse_bop() warning(1) mouse_bop() warning(2) mouse_bop() warning(3) end() 19.3 - Functions are for humans and computers Problem 1 Read the source code for each of the following three functions, puzzle out what they do, and brainstorm better names: f1 &lt;- function(string, prefix) { substr(string, 1, nchar(prefix)) == prefix } is_prefix() f2 &lt;- function(x) { if (length(x) &lt;= 1) return(NULL) x[-length(x)] } drop_last() f3 &lt;- function(x, y) { rep(y, length.out = length(x)) } match_length() Problem 2 Take a function that you’ve written and spend five minutes brainstorming a better name for it and its arguments. Problem 3 Compare and contrast rnorm() and MASS::mvrnorm(). How can you make them more consistent? mvrnorm(n = 1, mu, Sigma, tol = 1e-6, empirical = FALSE, EISPACK = FALSE) rnorm(n, mean = 0, sd = 1) Match the argument names so both functions use greek names or English names. Set common default arguments for both functions. mvrnorm() has a default value for n but not for mu or Sigma, and rnorm() has default values for mean and sd but not n. Problem 4 Make a case for why norm_r(), norm_d(), etc., would be better than rnorm(), dnorm(). Make a case for the opposite. For: Families of functions should start with the same prefix. In this case, norm is the family of function. Against: Sometimes it is more useful to search based on the use of the distribution (i.e. “r”, “d”) than the type of distribution. The current function names allow for search of a constant use across different distributions. 19.4 - Conditional execution Problem 1 What’s the difference between if and ifelse()? Carefully read the help and construct three examples that illustrate the key differences. if() evaluates to a single value for the expression evaluated. ifelse() returns a value with the same shape as the argument test. ifelse() can return a vector with length greater than one that is a combination of TRUEs and FALSEs. x &lt;- c(1, 2, 3) if (x &gt; 0) {&quot;yes&quot;} ## [1] &quot;yes&quot; if (x &gt; 1) {&quot;yes&quot;} ifelse(x &gt; 1, &quot;yes&quot;, &quot;no&quot;) ## [1] &quot;no&quot; &quot;yes&quot; &quot;yes&quot; Problem 2 Write a greeting function that says “good morning”, “good afternoon”, or “good evening”, depending on the time of day. (Hint: use a time argument that defaults to lubridate::now(). That will make it easier to test your function.) library(lubridate) greeting &lt;- function() { if (now() &lt; today() + hms(&quot;12:00:00 EST&quot;)) { &quot;good morning&quot; } else if (now() &lt; today() + hms(&quot;18:00:00 EST&quot;)) { &quot;good afternoon&quot; } else { &quot;good evening&quot; } } Problem 3 Implement a fizzbuzz function. It takes a single number as input. If the number is divisible by three, it returns “fizz”. If it’s divisible by five it returns “buzz”. If it’s divisible by three and five, it returns “fizzbuzz”. Otherwise, it returns the number. Make sure you first write working code before you create the function. fizzbuzz &lt;- function(x) { if (near(x %% 3, 0) &amp;&amp; near(x %% 5, 0)) { &quot;fizzbuzz&quot; } else if (near(x %% 3, 0)) { &quot;fizz&quot; } else if (near(x %% 5, 0)) { &quot;buzz&quot; } else { x } } fizzbuzz(3) ## [1] &quot;fizz&quot; fizzbuzz(5) ## [1] &quot;buzz&quot; fizzbuzz(15) ## [1] &quot;fizzbuzz&quot; fizzbuzz(16) ## [1] 16 Problem 4 How could you use cut() to simplify this set of nested if-else statements? if (temp &lt;= 0) { &quot;freezing&quot; } else if (temp &lt;= 10) { &quot;cold&quot; } else if (temp &lt;= 20) { &quot;cool&quot; } else if (temp &lt;= 30) { &quot;warm&quot; } else { &quot;hot&quot; } temps &lt;- c(-10, 15, 40) cut(temps, c(-Inf, 0, 10, 20, 30, Inf), labels = c(&quot;freezing&quot;, &quot;cold&quot;, &quot;cool&quot;, &quot;warm&quot;, &quot;hot&quot;)) ## [1] freezing cool hot ## Levels: freezing cold cool warm hot How would you change the call to cut() if I’d used &lt; instead of &lt;=? What is the other chief advantage of cut() for this problem? (Hint: what happens if you have many values in temp?) Add right = FALSE as an argument to the function so the intervals are closed on the left instead of closed on the right. cut() is advantageous because it is vectorized. Problem 5 What happens if you use switch() with numeric values? It throws back an error. switch() evaluates EXPR and accordingly chooses one of the further arguments (in …). Arguments can’t be numbers. Problem 6 What does this switch() call do? What happens if x is “e”? a evaluates to the subsequent argument and returns “ab”. c evaluates to the subsequent argument and returns “cd”. e returns nothing because it isn’t present in switch(). 19.5 - Function arguments Problem 1 What does commas(letters, collapse = “-”) do? Why? It returns an error because the argument collapse has multiple values. Problem 2 It’d be nice if you could supply multiple characters to the pad argument, e.g. rule(“Title”, pad = “-+”). Why doesn’t this currently work? How could you fix it? This works now. I guess library(stringr) resolved this. rule &lt;- function(..., pad = &quot;-&quot;) { title &lt;- paste0(...) width &lt;- getOption(&quot;width&quot;) - nchar(title) - 5 cat(title, &quot; &quot;, stringr::str_dup(pad, width), &quot;\\n&quot;, sep = &quot;&quot;) } rule(&quot;Important output&quot;, pad = &quot;+-&quot;) ## Important output +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+- Problem 3 What does the trim argument to mean() do? When might you use it? trim is the proportion of observations (0 to 0.5) to be dropped from each end of x before the mean is computed. It is useful with the extreme values on each of the distribution are outliers or are noisy. Problem 4 The default value for the method argument to cor() is c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;). What does that mean? What value is used by default? It means the possible methods are &quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;. It defaults to &quot;pearson&quot; for the Pearson correlation coefficient. "],
["chapter-20-vectors.html", "Chapter 20 - Vectors 20.3 - Important types of atomic vector 20.4 - Using atomic vectors 20.5 - Recursive vectors (lists) 20.7 - Augmented vectors", " Chapter 20 - Vectors library(tidyverse) 20.3 - Important types of atomic vector Problem 1 Describe the difference between is.finite(x) and !is.infinite(x). is.finite(x) returns TRUE for NaN and NA. !is.infinite(x) returns FALSE for NaN and NA. That’s because both functions test for finite/infinite and not missing. ! thus turns a FALSE from a missing value into a TRUE. is.finite(NaN) ## [1] FALSE !is.infinite(NaN) ## [1] TRUE is.finite(NA) ## [1] FALSE !is.infinite(NA) ## [1] TRUE Problem 2 Read the source code for dplyr::near() (Hint: to see the source code, drop the ()). How does it work? It subtracts the first value from the second value and then sees if the difference is smaller than a tolerance of .Machine$double.eps^0.5. Problem 3 A logical vector can take 3 possible values. How many possible values can an integer vector take? How many possible values can a double take? Use google to do some research. R has 2147483647 positive integers, 2147483647 negative integers, NA, and 0L. That sums up to 4.294967310^{9} possible values for integers. This numbers is ironically not an integer in R. The maximum double on this computer is 1.797693110^{308} and the minimum double on this computer is 1.797693110^{308}. This machine floats to 53. Double can also take the values -Inf, Inf, NA, and NaN. Doubles can approximately take (.Machine$double.xmax * 2) * (10 ^ .Machine$double.digits) + 4 values. R can’t actually display this number. Problem 4 Brainstorm at least four functions that allow you to convert a double to an integer. How do they differ? Be precise. todo(aaron): I can think of ways to truncate decimals. I can’t think of ways to change the type of atomic vector. 2.2 ## [1] 2.2 as_integer &lt;- function(x) { (x %/% 1) } typeof(as_integer(2.2)) ## [1] &quot;double&quot; as_integer &lt;- function(x) { x - x %% 1 } as_integer(2.2) ## [1] 2 as_integer &lt;- function(x) { round(x) } as_integer(2.2) ## [1] 2 Problem 5 What functions from the readr package allow you to turn a string into logical, integer, and double vector? parse_logical, parse_integer, and parse_number 20.4 - Using atomic vectors Problem 1 What does mean(is.na(x)) tell you about a vector x? What about sum(!is.finite(x))? mean(is.na(x)) calculates the proportion of values in the vector that are missing. sum(!is.finite(x)) calculates the number of values in the vector that are infinite, missing, or not a number. Problem 2 Carefully read the documentation of is.vector(). What does it actually test for? Why does is.atomic() not agree with the definition of atomic vectors above? is.vector() tests if a vector is of the specified mode and has no attributes other than names. is.atomic() returns TRUE if the object is NULL. In “R for Data Science”, NULL isn’t considered a vector. Problem 3 Compare and contrast setNames() with purrr::set_names(). purrr::set_names() is a snake case wrapper for setNames() with tweaked defaults and stricter argument checking. In particular, the argument x is unnamed and and comes first and names are named and come second in purrr::set_names(). Additionally, it tests to see if x is a vector. purrr::set_names() is now the same as rlang::set_names() so: If you do nothing, x will be named with itself. If x already has names, you can provide a function or formula to transform the existing names. In that case, … is passed to the function. If nm is NULL, the names are removed (if present). In all other cases, nm and … are coerced to character. Problem 4 Create functions that take a vector as input and returns: The last value. Should you use [ or [[? Use [[ because it will always return only one value. numbers &lt;- c(1, 10, 93, 25, 43, NA, NA, 104, 10, NA, 25) get_last &lt;- function(x) { x[[length(x)]] } get_last(numbers) ## [1] 25 The elements at even numbered positions. get_evens &lt;- function(x) { index &lt;- seq(from = 2, to = length(x), by = 2) x[index] } get_evens(numbers) ## [1] 10 25 NA 104 NA Every element except the last value. get_all_but_last &lt;- function(x) { index &lt;- 1:(length(numbers) - 1) x[index] } get_all_but_last(numbers) ## [1] 1 10 93 25 43 NA NA 104 10 NA Only even numbers (and no missing values). get_evens &lt;- function(x) { index &lt;- seq(from = 2, to = length(x), by = 2) evens &lt;- x[index] evens[!is.na(evens)] } get_evens(numbers) ## [1] 10 25 104 Problem 5 Why is x[-which(x &gt; 0)] not the same as x[x &lt;= 0]? x[-which(x &gt; 0)] returns NaN and x[x &lt;= 0] does not return NaN. which() returns integers of the positions that meet the criteria and aren’t NaN. Adding - to the index, drops the values meet the criteria and aren’t NaN, but leaves the values that don’t meet the criteria or are NaN. Conditionals return NA when tested against NaN, so NaN is dropped. This holds even if the opposite vector is used as an index. ! changes TRUE to FALSE and FALSE to TRUE but it leaves NA as NA. x &lt;- c(NA, -5, 10, 20, 0, NA, 10000, 10.1, NaN, Inf) # 1 which(x &gt; 0) ## [1] 3 4 7 8 10 #2 -which(x &gt; 0) ## [1] -3 -4 -7 -8 -10 #3 x[-which(x &gt; 0)] ## [1] NA -5 0 NA NaN # 1 x &lt;= 0 ## [1] NA TRUE FALSE FALSE TRUE NA FALSE FALSE NA FALSE # 2 x[x &lt;= 0] ## [1] NA -5 0 NA NA Problem 6 What happens when you subset with a positive integer that’s bigger than the length of the vector? What happens when you subset with a name that doesn’t exist? The subset returns an NA. x &lt;- c(1, 2, 3) x[5] ## [1] NA The subset returns an NA with a name attribute of NA. x &lt;- c(a = 1, b = 2, c = 3) x[&quot;d&quot;] ## &lt;NA&gt; ## NA 20.5 - Recursive vectors (lists) Problem 1 Draw the following lists as nested sets: list(a, b, list(c, d), list(e, f)) list(list(list(list(list(list(a)))))) Problem 2 What happens if you subset a tibble as if you’re subsetting a list? What are the key differences between a list and a tibble? [ returns a tibble with the referenced columns. [[ returns a single vector with no attributes. mtcars &lt;- tbl_df(mtcars) # tibble with just the first vector mtcars[1] ## # A tibble: 32 x 1 ## mpg ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ... with 22 more rows # vector with no attributes mtcars[[1]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 ## [15] 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 ## [29] 15.8 19.7 15.0 21.4 A tibble is a list of columns. The difference between a tibble and a list is that all of the elemtns of a data frame must be vectors of the same length while lists can have elements of different lengths. 20.7 - Augmented vectors Problem 1 What does hms::hms(3600) return? How does it print? What primitive type is the augmented vector built on top of? What attributes does it use? It returns a vector with classes “hms” and “difftime”. The primitive type is double. It has attributes $units and $class. Problem 2 Try and make a tibble that has columns with different lengths. What happens? It returns an error: “Error: Column a must be length 1 or 5, not 3” tibble(a = 1:3, b = 1:5) Problem 3 Based on the definition above, is it ok to have a list as a column of a tibble? Yes. columns are an important feature of tibbles. tibble(a = list(c(1, 2, 3), c(1, 3), 1), b = 1:3) ## # A tibble: 3 x 2 ## a b ## &lt;list&gt; &lt;int&gt; ## 1 &lt;dbl [3]&gt; 1 ## 2 &lt;dbl [2]&gt; 2 ## 3 &lt;dbl [1]&gt; 3 "],
["chapter-21-iteration.html", "Chapter 21 - Iteration 21.2 For loops 21.3 - For loop variations 21.4 For loops vs. functionals 21.5 The map functions 21.9 Other patterns of for loops", " Chapter 21 - Iteration library(tidyverse) library(stringr) library(purrr) 21.2 For loops Problem 1 Write a for loop to compute the mean of every column in mtcars. means &lt;- vector(mode = &quot;double&quot;, length = ncol(mtcars)) for (i in seq_along(mtcars)) { means[[i]] &lt;- mean(mtcars[[i]]) } Write a for loop to determine the type of each column in nycflights13::flights. types &lt;- vector(mode = &quot;character&quot;, length = ncol(nycflights13::flights)) for (i in seq_along(nycflights13::flights)) { types[[i]] &lt;- typeof(nycflights13::flights[[i]]) } Write a for loop to compute the number of unique values in each column of iris. uniques &lt;- vector(mode = &quot;integer&quot;, length = ncol(iris)) for (i in seq_along(iris)) { uniques[[i]] &lt;- length(unique(iris[[i]])) } Write a for loop to generate 10 random normals for each of μ=−10, 0, 10, and 100. mu &lt;- c(-10, 0, 10, 100) means &lt;- vector(mode = &quot;list&quot;, length = length(mu)) for (i in seq_along(mu)) { means[[i]] &lt;- rnorm(10, mu[[i]]) } Problem 2 Eliminate the for loop in each of the following examples by taking advantage of an existing function that works with vectors: out &lt;- &quot;&quot; for (x in letters) { out &lt;- stringr::str_c(out, x) } str_c(letters, collapse = &quot;&quot;) ## [1] &quot;abcdefghijklmnopqrstuvwxyz&quot; x &lt;- sample(100) sd &lt;- 0 for (i in seq_along(x)) { sd &lt;- sd + (x[i] - mean(x)) ^ 2 } sd &lt;- sqrt(sd / (length(x) - 1)) x &lt;- sample(100) sd(x) ## [1] 29.01149 x &lt;- runif(100) out &lt;- vector(&quot;numeric&quot;, length(x)) out[1] &lt;- x[1] for (i in 2:length(x)) { out[i] &lt;- out[i - 1] + x[i] } x &lt;- runif(100) cumsum(x) ## [1] 0.7992565 1.7608118 2.0568895 2.7632569 3.1874423 3.4156319 ## [7] 3.7932377 4.5010074 4.7897675 5.2268024 5.7017297 5.8936281 ## [13] 6.5535643 6.9500150 7.2025988 8.1761619 8.2140256 8.3230613 ## [19] 8.6160396 9.0065614 9.8620361 10.7127212 11.1803565 11.8688522 ## [25] 12.1589534 12.8618798 13.6073635 13.8465202 14.6820606 15.5347900 ## [31] 15.6181820 16.2615141 16.3094982 16.9174266 17.4108490 18.0282809 ## [37] 18.6796008 19.3726228 19.9166126 20.8239177 21.7560005 22.6184446 ## [43] 22.7806640 23.5676463 23.6948960 24.2016778 25.0481692 25.7883647 ## [49] 26.4821228 26.8559495 27.3206825 27.7898423 27.7932023 28.3234821 ## [55] 29.1914478 29.5327613 30.3893470 30.3923624 31.1120492 31.3565176 ## [61] 31.8913102 32.3702339 32.4786353 32.5455526 33.0663031 33.8657784 ## [67] 34.4458223 34.5220059 34.8413884 35.6982702 36.2742193 36.4214467 ## [73] 36.6967912 37.2807661 37.5067842 38.1225982 38.9413877 39.5963806 ## [79] 40.0266886 40.5622833 41.0330933 41.7829160 42.0595204 42.9576707 ## [85] 43.5532956 44.3516510 45.2313919 46.0113575 46.1073148 46.2408325 ## [91] 46.8870112 47.7124623 48.0929501 48.2655434 48.2890810 48.8839214 ## [97] 49.8599138 50.0684173 50.8891799 51.6686330 Problem 3 Write a for loop that prints() the lyrics to the children’s song “Alice the camel”. humps &lt;- c(&quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;one&quot;, &quot;no&quot;) for (i in seq_along(humps)) { for (j in 1:3) { print(str_glue(&quot;Alice the camel has {humps[i]} humps.&quot;)) } if (i &lt; 6) { # str_glue is unecessary. it drops [1] print(str_glue(&quot;So go, Alice, go.&quot;)) } else { print(str_glue(&quot;Now Alice is a horse&quot;)) } } ## Alice the camel has five humps. ## Alice the camel has five humps. ## Alice the camel has five humps. ## So go, Alice, go. ## Alice the camel has four humps. ## Alice the camel has four humps. ## Alice the camel has four humps. ## So go, Alice, go. ## Alice the camel has three humps. ## Alice the camel has three humps. ## Alice the camel has three humps. ## So go, Alice, go. ## Alice the camel has two humps. ## Alice the camel has two humps. ## Alice the camel has two humps. ## So go, Alice, go. ## Alice the camel has one humps. ## Alice the camel has one humps. ## Alice the camel has one humps. ## So go, Alice, go. ## Alice the camel has no humps. ## Alice the camel has no humps. ## Alice the camel has no humps. ## Now Alice is a horse Convert the nursery rhyme “ten in the bed” to a function. Generalise it to any number of people in any sleeping structure. n_in_the_bed &lt;- function(occupants = 10L) { for (i in seq(from = occupants, to = 1)) { if (i &gt; 1) { print(str_glue( &quot;There were {i} in a bed And the little one said &#39;Roll over, roll over&#39; So they all rolled over And one fell out &quot; )) } else if (i == 1) { print(str_glue(&quot;There was one in a bed And the little one said &#39;Good night!&#39;&quot;)) } } } n_in_the_bed() ## There were 10 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 9 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 8 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 7 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 6 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 5 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 4 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 3 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There were 2 in a bed ## And the little one said ## &#39;Roll over, roll over&#39; ## So they all rolled over ## And one fell out ## ## There was one in a bed ## And the little one said ## &#39;Good night!&#39; Convert the song “99 bottles of beer on the wall” to a function. Generalise to any number of any vessel containing any liquid on any surface. bottles_of_beer &lt;- function(bottles = 99L) { for (i in seq(from = bottles, to = 0)) { bottles_left &lt;- ifelse(i == 0, &quot;no more&quot;, i) print(str_glue( &quot;{i} bottle of beer on the wall, {i} bottle of beer. Take one down and pass it around, {bottles_left} bottles of beer on the wall.&quot; ) ) } } bottles_of_beer() ## 99 bottle of beer on the wall, 99 bottle of beer. ## Take one down and pass it around, 99 bottles of beer on the wall. ## 98 bottle of beer on the wall, 98 bottle of beer. ## Take one down and pass it around, 98 bottles of beer on the wall. ## 97 bottle of beer on the wall, 97 bottle of beer. ## Take one down and pass it around, 97 bottles of beer on the wall. ## 96 bottle of beer on the wall, 96 bottle of beer. ## Take one down and pass it around, 96 bottles of beer on the wall. ## 95 bottle of beer on the wall, 95 bottle of beer. ## Take one down and pass it around, 95 bottles of beer on the wall. ## 94 bottle of beer on the wall, 94 bottle of beer. ## Take one down and pass it around, 94 bottles of beer on the wall. ## 93 bottle of beer on the wall, 93 bottle of beer. ## Take one down and pass it around, 93 bottles of beer on the wall. ## 92 bottle of beer on the wall, 92 bottle of beer. ## Take one down and pass it around, 92 bottles of beer on the wall. ## 91 bottle of beer on the wall, 91 bottle of beer. ## Take one down and pass it around, 91 bottles of beer on the wall. ## 90 bottle of beer on the wall, 90 bottle of beer. ## Take one down and pass it around, 90 bottles of beer on the wall. ## 89 bottle of beer on the wall, 89 bottle of beer. ## Take one down and pass it around, 89 bottles of beer on the wall. ## 88 bottle of beer on the wall, 88 bottle of beer. ## Take one down and pass it around, 88 bottles of beer on the wall. ## 87 bottle of beer on the wall, 87 bottle of beer. ## Take one down and pass it around, 87 bottles of beer on the wall. ## 86 bottle of beer on the wall, 86 bottle of beer. ## Take one down and pass it around, 86 bottles of beer on the wall. ## 85 bottle of beer on the wall, 85 bottle of beer. ## Take one down and pass it around, 85 bottles of beer on the wall. ## 84 bottle of beer on the wall, 84 bottle of beer. ## Take one down and pass it around, 84 bottles of beer on the wall. ## 83 bottle of beer on the wall, 83 bottle of beer. ## Take one down and pass it around, 83 bottles of beer on the wall. ## 82 bottle of beer on the wall, 82 bottle of beer. ## Take one down and pass it around, 82 bottles of beer on the wall. ## 81 bottle of beer on the wall, 81 bottle of beer. ## Take one down and pass it around, 81 bottles of beer on the wall. ## 80 bottle of beer on the wall, 80 bottle of beer. ## Take one down and pass it around, 80 bottles of beer on the wall. ## 79 bottle of beer on the wall, 79 bottle of beer. ## Take one down and pass it around, 79 bottles of beer on the wall. ## 78 bottle of beer on the wall, 78 bottle of beer. ## Take one down and pass it around, 78 bottles of beer on the wall. ## 77 bottle of beer on the wall, 77 bottle of beer. ## Take one down and pass it around, 77 bottles of beer on the wall. ## 76 bottle of beer on the wall, 76 bottle of beer. ## Take one down and pass it around, 76 bottles of beer on the wall. ## 75 bottle of beer on the wall, 75 bottle of beer. ## Take one down and pass it around, 75 bottles of beer on the wall. ## 74 bottle of beer on the wall, 74 bottle of beer. ## Take one down and pass it around, 74 bottles of beer on the wall. ## 73 bottle of beer on the wall, 73 bottle of beer. ## Take one down and pass it around, 73 bottles of beer on the wall. ## 72 bottle of beer on the wall, 72 bottle of beer. ## Take one down and pass it around, 72 bottles of beer on the wall. ## 71 bottle of beer on the wall, 71 bottle of beer. ## Take one down and pass it around, 71 bottles of beer on the wall. ## 70 bottle of beer on the wall, 70 bottle of beer. ## Take one down and pass it around, 70 bottles of beer on the wall. ## 69 bottle of beer on the wall, 69 bottle of beer. ## Take one down and pass it around, 69 bottles of beer on the wall. ## 68 bottle of beer on the wall, 68 bottle of beer. ## Take one down and pass it around, 68 bottles of beer on the wall. ## 67 bottle of beer on the wall, 67 bottle of beer. ## Take one down and pass it around, 67 bottles of beer on the wall. ## 66 bottle of beer on the wall, 66 bottle of beer. ## Take one down and pass it around, 66 bottles of beer on the wall. ## 65 bottle of beer on the wall, 65 bottle of beer. ## Take one down and pass it around, 65 bottles of beer on the wall. ## 64 bottle of beer on the wall, 64 bottle of beer. ## Take one down and pass it around, 64 bottles of beer on the wall. ## 63 bottle of beer on the wall, 63 bottle of beer. ## Take one down and pass it around, 63 bottles of beer on the wall. ## 62 bottle of beer on the wall, 62 bottle of beer. ## Take one down and pass it around, 62 bottles of beer on the wall. ## 61 bottle of beer on the wall, 61 bottle of beer. ## Take one down and pass it around, 61 bottles of beer on the wall. ## 60 bottle of beer on the wall, 60 bottle of beer. ## Take one down and pass it around, 60 bottles of beer on the wall. ## 59 bottle of beer on the wall, 59 bottle of beer. ## Take one down and pass it around, 59 bottles of beer on the wall. ## 58 bottle of beer on the wall, 58 bottle of beer. ## Take one down and pass it around, 58 bottles of beer on the wall. ## 57 bottle of beer on the wall, 57 bottle of beer. ## Take one down and pass it around, 57 bottles of beer on the wall. ## 56 bottle of beer on the wall, 56 bottle of beer. ## Take one down and pass it around, 56 bottles of beer on the wall. ## 55 bottle of beer on the wall, 55 bottle of beer. ## Take one down and pass it around, 55 bottles of beer on the wall. ## 54 bottle of beer on the wall, 54 bottle of beer. ## Take one down and pass it around, 54 bottles of beer on the wall. ## 53 bottle of beer on the wall, 53 bottle of beer. ## Take one down and pass it around, 53 bottles of beer on the wall. ## 52 bottle of beer on the wall, 52 bottle of beer. ## Take one down and pass it around, 52 bottles of beer on the wall. ## 51 bottle of beer on the wall, 51 bottle of beer. ## Take one down and pass it around, 51 bottles of beer on the wall. ## 50 bottle of beer on the wall, 50 bottle of beer. ## Take one down and pass it around, 50 bottles of beer on the wall. ## 49 bottle of beer on the wall, 49 bottle of beer. ## Take one down and pass it around, 49 bottles of beer on the wall. ## 48 bottle of beer on the wall, 48 bottle of beer. ## Take one down and pass it around, 48 bottles of beer on the wall. ## 47 bottle of beer on the wall, 47 bottle of beer. ## Take one down and pass it around, 47 bottles of beer on the wall. ## 46 bottle of beer on the wall, 46 bottle of beer. ## Take one down and pass it around, 46 bottles of beer on the wall. ## 45 bottle of beer on the wall, 45 bottle of beer. ## Take one down and pass it around, 45 bottles of beer on the wall. ## 44 bottle of beer on the wall, 44 bottle of beer. ## Take one down and pass it around, 44 bottles of beer on the wall. ## 43 bottle of beer on the wall, 43 bottle of beer. ## Take one down and pass it around, 43 bottles of beer on the wall. ## 42 bottle of beer on the wall, 42 bottle of beer. ## Take one down and pass it around, 42 bottles of beer on the wall. ## 41 bottle of beer on the wall, 41 bottle of beer. ## Take one down and pass it around, 41 bottles of beer on the wall. ## 40 bottle of beer on the wall, 40 bottle of beer. ## Take one down and pass it around, 40 bottles of beer on the wall. ## 39 bottle of beer on the wall, 39 bottle of beer. ## Take one down and pass it around, 39 bottles of beer on the wall. ## 38 bottle of beer on the wall, 38 bottle of beer. ## Take one down and pass it around, 38 bottles of beer on the wall. ## 37 bottle of beer on the wall, 37 bottle of beer. ## Take one down and pass it around, 37 bottles of beer on the wall. ## 36 bottle of beer on the wall, 36 bottle of beer. ## Take one down and pass it around, 36 bottles of beer on the wall. ## 35 bottle of beer on the wall, 35 bottle of beer. ## Take one down and pass it around, 35 bottles of beer on the wall. ## 34 bottle of beer on the wall, 34 bottle of beer. ## Take one down and pass it around, 34 bottles of beer on the wall. ## 33 bottle of beer on the wall, 33 bottle of beer. ## Take one down and pass it around, 33 bottles of beer on the wall. ## 32 bottle of beer on the wall, 32 bottle of beer. ## Take one down and pass it around, 32 bottles of beer on the wall. ## 31 bottle of beer on the wall, 31 bottle of beer. ## Take one down and pass it around, 31 bottles of beer on the wall. ## 30 bottle of beer on the wall, 30 bottle of beer. ## Take one down and pass it around, 30 bottles of beer on the wall. ## 29 bottle of beer on the wall, 29 bottle of beer. ## Take one down and pass it around, 29 bottles of beer on the wall. ## 28 bottle of beer on the wall, 28 bottle of beer. ## Take one down and pass it around, 28 bottles of beer on the wall. ## 27 bottle of beer on the wall, 27 bottle of beer. ## Take one down and pass it around, 27 bottles of beer on the wall. ## 26 bottle of beer on the wall, 26 bottle of beer. ## Take one down and pass it around, 26 bottles of beer on the wall. ## 25 bottle of beer on the wall, 25 bottle of beer. ## Take one down and pass it around, 25 bottles of beer on the wall. ## 24 bottle of beer on the wall, 24 bottle of beer. ## Take one down and pass it around, 24 bottles of beer on the wall. ## 23 bottle of beer on the wall, 23 bottle of beer. ## Take one down and pass it around, 23 bottles of beer on the wall. ## 22 bottle of beer on the wall, 22 bottle of beer. ## Take one down and pass it around, 22 bottles of beer on the wall. ## 21 bottle of beer on the wall, 21 bottle of beer. ## Take one down and pass it around, 21 bottles of beer on the wall. ## 20 bottle of beer on the wall, 20 bottle of beer. ## Take one down and pass it around, 20 bottles of beer on the wall. ## 19 bottle of beer on the wall, 19 bottle of beer. ## Take one down and pass it around, 19 bottles of beer on the wall. ## 18 bottle of beer on the wall, 18 bottle of beer. ## Take one down and pass it around, 18 bottles of beer on the wall. ## 17 bottle of beer on the wall, 17 bottle of beer. ## Take one down and pass it around, 17 bottles of beer on the wall. ## 16 bottle of beer on the wall, 16 bottle of beer. ## Take one down and pass it around, 16 bottles of beer on the wall. ## 15 bottle of beer on the wall, 15 bottle of beer. ## Take one down and pass it around, 15 bottles of beer on the wall. ## 14 bottle of beer on the wall, 14 bottle of beer. ## Take one down and pass it around, 14 bottles of beer on the wall. ## 13 bottle of beer on the wall, 13 bottle of beer. ## Take one down and pass it around, 13 bottles of beer on the wall. ## 12 bottle of beer on the wall, 12 bottle of beer. ## Take one down and pass it around, 12 bottles of beer on the wall. ## 11 bottle of beer on the wall, 11 bottle of beer. ## Take one down and pass it around, 11 bottles of beer on the wall. ## 10 bottle of beer on the wall, 10 bottle of beer. ## Take one down and pass it around, 10 bottles of beer on the wall. ## 9 bottle of beer on the wall, 9 bottle of beer. ## Take one down and pass it around, 9 bottles of beer on the wall. ## 8 bottle of beer on the wall, 8 bottle of beer. ## Take one down and pass it around, 8 bottles of beer on the wall. ## 7 bottle of beer on the wall, 7 bottle of beer. ## Take one down and pass it around, 7 bottles of beer on the wall. ## 6 bottle of beer on the wall, 6 bottle of beer. ## Take one down and pass it around, 6 bottles of beer on the wall. ## 5 bottle of beer on the wall, 5 bottle of beer. ## Take one down and pass it around, 5 bottles of beer on the wall. ## 4 bottle of beer on the wall, 4 bottle of beer. ## Take one down and pass it around, 4 bottles of beer on the wall. ## 3 bottle of beer on the wall, 3 bottle of beer. ## Take one down and pass it around, 3 bottles of beer on the wall. ## 2 bottle of beer on the wall, 2 bottle of beer. ## Take one down and pass it around, 2 bottles of beer on the wall. ## 1 bottle of beer on the wall, 1 bottle of beer. ## Take one down and pass it around, 1 bottles of beer on the wall. ## 0 bottle of beer on the wall, 0 bottle of beer. ## Take one down and pass it around, no more bottles of beer on the wall. Problem 4 It’s common to see for loops that don’t preallocate the output and instead increase the length of a vector at each step: output &lt;- vector(&quot;integer&quot;, 0) for (i in seq_along(x)) { output &lt;- c(output, lengths(x[[i]])) } output How does this affect performance? Design and execute an experiment. library(microbenchmark) grow_vector &lt;- function() { # create a character vector x &lt;- rep(&quot;abc&quot;, 1000) # create an empty vector of length 0 for the output output &lt;- vector(&quot;integer&quot;, 0) # find the length of each observation in x and grow and concatenate it to # output for (i in seq_along(x)) { output &lt;- c(output, lengths(x[[i]])) } output } microbenchmark(grow_vector()) ## Unit: milliseconds ## expr min lq mean median uq max neval ## grow_vector() 1.900363 2.13041 3.498677 2.936309 3.768595 32.02081 100 This first chunk grows a vector from length zero to length 1,000. preallocate_vector &lt;- function() { # create a character vector x &lt;- rep(&quot;abc&quot;, 1000) # create an empty vector of length length(x) for the output output &lt;- vector(&quot;integer&quot;, length(x)) # find the length of each observation in x and assignment it the corresponding # location in the output vector for (i in seq_along(x)) { output[i] &lt;- lengths(x[[i]]) } output } microbenchmark(preallocate_vector()) ## Unit: microseconds ## expr min lq mean median uq max ## preallocate_vector() 637.998 646.7515 749.7371 653.1365 670.594 5219.469 ## neval ## 100 This second chunk preallocates the space in the vector and then populates it. It is an order of magnitude faster. 21.3 - For loop variations Problem 1 Imagine you have a directory full of CSV files that you want to read in. You have their paths in a vector, files &lt;- dir(&quot;data/&quot;, pattern = &quot;\\\\.csv$&quot;, full.names = TRUE), and now want to read each one with read_csv(). Write the for loop that will load them into a single data frame. library(tidyverse) files &lt;- dir(&quot;data/&quot;, pattern = &quot;\\\\.csv$&quot;, full.names = TRUE) output &lt;- vector(&quot;list&quot;, length(files)) for (i in seq_along(files)) { output[[i]] &lt;- read_csv(files[[i]]) } output &lt;- flatten_df(output) Problem 2 What happens if you use for (nm in names(x)) and x has no names? x &lt;- c(1, 2, 3) for (nm in names(x)) { print(names(x[nm])) } What if only some of the elements are named? It does not matter. It still iterates along the entire vector. x &lt;- c(&quot;a&quot; = 1, 2, &quot;c&quot; = 3) for (nm in names(x)) { print(names(x[nm])) } ## [1] &quot;a&quot; ## [1] NA ## [1] &quot;c&quot; What if the names are not unique? It works. x &lt;- c(&quot;a&quot; = 1, &quot;a&quot; = 2, &quot;c&quot; = 3) for (nm in names(x)) { print(names(x[nm])) } ## [1] &quot;a&quot; ## [1] &quot;a&quot; ## [1] &quot;c&quot; Problem 3 Write a function that prints the mean of each numeric column in a data frame, along with its name. For example, show_mean(iris) would print: show_mean(iris) #&gt; Sepal.Length: 5.84 #&gt; Sepal.Width: 3.06 #&gt; Petal.Length: 3.76 #&gt; Petal.Width: 1.20 (Extra challenge: what function did I use to make sure that the numbers lined up nicely, even though the variable names had different lengths?) print_means &lt;- function(data = iris, digits = 2) { max_str_length &lt;- max(str_length(names(data))) for (i in seq_along(data)) { if (is.numeric(data[[i]])) { cat(&quot;#&gt; &quot;, str_pad(str_c(names(data)[[i]], &quot;: &quot;), width = max_str_length + 2, side = &quot;right&quot;), format(mean(data[[i]]), digits = digits, nsmall = 2), &quot;\\n&quot;, sep = &quot;&quot;) } } } print_means() ## #&gt; Sepal.Length: 5.84 ## #&gt; Sepal.Width: 3.06 ## #&gt; Petal.Length: 3.76 ## #&gt; Petal.Width: 1.20 Problem 4 What does this code do? How does it work? &gt;&gt;&gt;&gt;&gt;&gt;&gt; aaron trans &lt;- list( disp = function(x) x * 0.0163871, am = function(x) { factor(x, labels = c(&quot;auto&quot;, &quot;manual&quot;)) } ) for (var in names(trans)) { mtcars[[var]] &lt;- trans[[var]](mtcars[[var]]) } The list trans contains two functions: disp() and am(). disp() takes its input and multiplies by 0.0163871 and am() takes its input and creates a factor variable with the value “auto” or “manual.” The for loop loops over the two functions in the list, uses the variables “disp” and “am” in the dataset mtcars as inputs, and outputs a new mtcars dataset. 21.4 For loops vs. functionals Problem 1 Read the documentation for apply(). In the 2d case, what two for loops does it generalise? Read the documentation for apply(). In the 2d case, what two for loops does it generalise? It generalizes a for loop along a vector inside of a for loop along a series of columns in a data frame or matrix. Problem 2 Adapt col_summary() so that it only applies to numeric columns You might want to start with an is_numeric() function that returns a logical vector that has a TRUE corresponding to each numeric column. col_summary &lt;- function(df, fun) { out &lt;- vector(&quot;double&quot;, length(df)) for (i in seq_along(df)) { if (is_numeric(df[[i]])) { out[i] &lt;- fun(df[[i]]) } } out } col_summary(mtcars, median) ## [1] 19.200 6.000 196.300 123.000 3.695 3.325 17.710 0.000 ## [9] 0.000 4.000 2.000 21.5 The map functions &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Problem 1 Write code that uses one of the map functions to compute the mean of every column in mtcars. mtcars %&gt;% map_dbl(mean) ## mpg cyl disp hp drat wt ## 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 ## qsec vs am gear carb ## 17.848750 0.437500 0.406250 3.687500 2.812500 Write code that uses one of the map functions to determine the type of each column in nycflights13::flights nycflights13::flights %&gt;% map_chr(typeof) ## year month day dep_time sched_dep_time ## &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; ## dep_delay arr_time sched_arr_time arr_delay carrier ## &quot;double&quot; &quot;integer&quot; &quot;integer&quot; &quot;double&quot; &quot;character&quot; ## flight tailnum origin dest air_time ## &quot;integer&quot; &quot;character&quot; &quot;character&quot; &quot;character&quot; &quot;double&quot; ## distance hour minute time_hour ## &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; Write code that uses one of the map functions to compute the number of unique values in each column of iris iris %&gt;% map_int(~n_distinct(.)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 35 23 43 22 3 Write code that uses one of the map functions to generate 10 random normals for each of μ = -10, 0, 10, and 100. c(-10, 0, 10, 100) %&gt;% map(rnorm, n = 10) ## [[1]] ## [1] -8.613927 -10.861591 -10.509092 -9.621524 -11.265569 -9.559204 ## [7] -10.645219 -8.926115 -8.283552 -9.792644 ## ## [[2]] ## [1] 0.8410627 -0.5900651 -0.1973340 0.4830072 0.7880175 0.3395677 ## [7] 0.6817573 -0.2498184 -0.1152174 -0.3149770 ## ## [[3]] ## [1] 10.963085 9.409694 11.771349 11.784008 11.862400 11.362329 10.703007 ## [8] 10.791937 9.934156 9.021313 ## ## [[4]] ## [1] 100.50982 100.82160 100.64492 99.57490 101.21460 101.74406 100.68118 ## [8] 102.20611 98.92326 100.68888 0.0.1 Problem 2 How can you create a single vector that for each column in a data frame indicates whether or not it’s a factor? iris %&gt;% map_lgl(is.factor) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## FALSE FALSE FALSE FALSE TRUE 0.0.2 Problem 3 What happens when you use the map functions on vectors that aren’t lists? What does map(1:5, runif) do? Why? The function iterates across each value, 1:5, in the vector and returns a list with five vectors containing between one and five random deviates: map(1:5, runif) ## [[1]] ## [1] 0.6802404 ## ## [[2]] ## [1] 0.1940716 0.4242075 ## ## [[3]] ## [1] 0.5138952 0.4181993 0.9047920 ## ## [[4]] ## [1] 0.097138551 0.095828098 0.167626012 0.002122607 ## ## [[5]] ## [1] 0.67009965 0.81967810 0.46746453 0.41498014 0.06425946 If the vector 1:5 is a list, the function does not iterate across five values but rather takes one value, the length five vector, as its sole input. Since the input is not a single value, the map function uses the length of the vector as its input: map(list(1:5), runif) ## [[1]] ## [1] 0.90291553 0.59047650 0.04802083 0.28696725 0.74672489 And as a result, the above function is equivalent to: map(list(5), runif) map(5, runif) map(list(5:9), runif) 0.0.3 Problem 4 What does map(-2:2, rnorm, n = 5) do? Why? What does map_dbl(-2:2, rnorm, n = 5) do? Why? map(-2:2, rnorm, n = 5) returns a list with five vectors of length five with values draw from the standard normal distribution with means ranging from -2 to 2. map_dbl(-2:2, rnorm, n = 5) returns the error Error: Result 1 is not a length 1 atomic vector because vectors can’t be nested inside of vectors. The first works because map() returns a list and the second doesn’t work because map_dbl() returns a vector. 0.0.4 Problem 5 Rewrite map(x, function(df) lm(mpg ~ wt, data = df)) to eliminate the anonymous function. map(x, ~lm(mpg ~ wt, data = .)) 21.9 Other patterns of for loops 0.0.5 Problem 1 Implement your own version of every() using a for loop. Compare it with purrr::every(). What does purrr’s version do that your version doesn’t? x &lt;- list(1:5, letters, list(10)) my_every &lt;- function(x, f) { out &lt;- vector(&quot;logical&quot;, 1) for (i in seq_along(x)) { out[[i]] &lt;- f(x[[i]]) } !FALSE %in% out } x %&gt;% my_every(is.numeric) ## [1] FALSE purrr:every() is clever. It doesn’t create a vector and store output. Instead, it tests every object and then returns a FALSE when the first vector fails the test. This is more efficient than my code. Unlike dplyr’s every(), my function does not support shortcuts for anonymous functions iris %&gt;% select_if(is.numeric) %&gt;% every(~mean(.) &gt; 3) 0.0.6 Problem 2 Create an enhanced col_sum() that applies a summary function to every numeric column in a data frame. col_summary &lt;- function(df, fun) { df_num &lt;- keep(df, is.numeric) map_dbl(df_num, fun) } col_summary(iris, mean) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 5.843333 3.057333 3.758000 1.199333 Problem 3 A possible base R equivalent of col_sum() is: col_sum3 &lt;- function(df, f) { is_num &lt;- sapply(df, is.numeric) df_num &lt;- df[, is_num] sapply(df_num, f) } But it has a number of bugs as illustrated with the following inputs: df &lt;- tibble( x = 1:3, y = 3:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) # OK col_sum3(df, mean) # Has problems: don&#39;t always return numeric vector col_sum3(df[1:2], mean) col_sum3(df[1], mean) col_sum3(df[0], mean) What causes the bugs? The bug stems from sapply, which returns a list rather than a vector when given a dataframe with no variables. Here is a more consistent approach in base R: df &lt;- tibble( x = 1:3, y = 3:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) col_sum3 &lt;- function(df, f) { is_num &lt;- vapply(df, is.numeric, logical(1)) df_num &lt;- df[, is_num] sapply(df_num, f) } col_sum3(df, mean) ## x y ## 2 2 "],
["chapter-23-model-basics.html", "Chapter 23 - Model basics 23.2 - A simple model 23.3 Visualizing models 23.4 Formulas and model families", " Chapter 23 - Model basics library(tidyverse) 23.2 - A simple model Problem 1 One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the simulated data below, and visualise the results. Rerun a few times to generate different simulated datasets. What do you notice about the model? sim1a &lt;- tibble( x = rep(1:10, each = 3), y = x * 1.5 + 6 + rt(length(x), df = 2) ) set.seed(20180315) sim1a &lt;- tibble( x = rep(rep(1:10, each = 3), 4), y = x * 1.5 + 6 + rt(length(x), df = 2), model = rep(c(&quot;model1&quot;, &quot;model2&quot;, &quot;model3&quot;, &quot;model4&quot;), each = length(x) / 4) ) sim1a %&gt;% ggplot(aes(x, y)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + facet_wrap(~model) The fitted line is surprsingly stable, but it doesn’t do a good job accounting for values that are far from the fitted line. Problem 2 One way to make linear models more robust is to use a different distance measure. For example, instead of root-mean-squared distance, you could use mean-absolute distance: measure_distance &lt;- function(mod, data) { diff &lt;- data$y - make_prediction(mod, data) mean(abs(diff)) } Use optim() to fit this model to the simulated data above and compare it to the linear model. library(modelr) model1 &lt;- function(a, data) { a[1] + data$x * a[2] } measure_distance &lt;- function(mod, data) { diff &lt;- data$y - model1(mod, data) mean(abs(diff)) } best &lt;- optim(c(0, 0), measure_distance, data = sim1a) ggplot(sim1a, aes(x, y)) + geom_point(size = 2, colour = &quot;grey30&quot;) + geom_abline(intercept = best$par[1], slope = best$par[2], color = &quot;red&quot;) Problem 3 One challenge with performing numerical optimisation is that it’s only guaranteed to find one local optima. What’s the problem with optimising a three parameter model like this? model1 &lt;- function(a, data) { a[1] + data$x * a[2] + a[3] } 23.3 Visualizing models Instead of using lm() to fit a straight line, you can use loess() to fit a smooth curve. Repeat the process of model fitting, grid generation, predictions, and visualisation on sim1 using loess() instead of lm(). How does the result compare to geom_smooth()? sim1_loess &lt;- loess(y ~ x, data = sim1) grid &lt;- sim1 %&gt;% data_grid(x) %&gt;% add_predictions(sim1_loess) ggplot(sim1, aes(x)) + geom_point(aes(y = y)) + geom_line(aes(y = pred), data = grid, colour = &quot;red&quot;, size = 1) + geom_smooth(aes(y = y)) The result is identical to geom_smooth() without the standard error shading. Problem 3 add_predictions() is paired with gather_predictions() and spread_predictions(). How do these three functions differ? gather_predictions() and spread_predictions() work with multiple models and add_predictions() only works with one model. gather_predictions() adds each prediction as a new row with a column for model name and a column for prediction. spread_predictions() adds a new column for the predictions from each model. Problem 3 What does geom_ref_line() do? What package does it come from? Why is displaying a reference line in plots showing residuals useful and important? geom_ref_line(), from library(modelr), can add horizontal and vertical reference lines. This could be useful for visually partitioning points or comparing the slope or slopes from models against levels lines. Problem 4 Why might you want to look at a frequency polygon of absolute residuals? What are the pros and cons compared to looking at the raw residuals? A frequency polygon of absolute residuals is useful for exploring the magnitudes of errors from a model. A problem is that is can obscure real differences between residuals from above the fitted model and residuals below the fitted model. 23.4 Formulas and model families Problem 1 What happens if you repeat the analysis of sim2 using a model without an intercept. What happens to the model equation? What happens to the predictions? mod2 &lt;- lm(y ~ x - 1, data = sim2) grid &lt;- sim2 %&gt;% data_grid(x) %&gt;% add_predictions(mod2) ggplot(sim2, aes(x)) + geom_point(aes(y = y)) + geom_point(data = grid, aes(y = pred), colour = &quot;red&quot;, size = 4) The model equation changes from y = a_0 + a_1 * xb + a_2 * xc + a_3 * xd to y = a_1 * xa + a_2 * xb + a_3 * xc + a_4 * xd. Basically, the first model replaces one level of the equation with the y-intercept. The second model has no intercept and all four levels of the discrete variable. The predictions don’t change. Problem 2 Use model_matrix() to explore the equations generated for the models I fit to sim3 and sim4. Why is * a good shorthand for interaction? mod1 &lt;- lm(y ~ x1 + x2, data = sim3) mod2 &lt;- lm(y ~ x1 * x2, data = sim3) model_matrix(y ~ x1 * x2, data = sim3) ## # A tibble: 120 x 8 ## `(Intercept)` x1 x2b x2c x2d `x1:x2b` `x1:x2c` `x1:x2d` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 0 0 0 ## 2 1 1 0 0 0 0 0 0 ## 3 1 1 0 0 0 0 0 0 ## 4 1 1 1 0 0 1 0 0 ## 5 1 1 1 0 0 1 0 0 ## 6 1 1 1 0 0 1 0 0 ## 7 1 1 0 1 0 0 1 0 ## 8 1 1 0 1 0 0 1 0 ## 9 1 1 0 1 0 0 1 0 ## 10 1 1 0 0 1 0 0 1 ## # ... with 110 more rows mod1 &lt;- lm(y ~ x1 + x2, data = sim4) mod2 &lt;- lm(y ~ x1 * x2, data = sim4) "],
["chapter-24-model-building.html", "Chapter 24 - Model building 24.2 - Why are low quality diamonds more expensive? 24.3 - What affects the number of daily flights?", " Chapter 24 - Model building library(tidyverse) library(modelr) 24.2 - Why are low quality diamonds more expensive? Problem 1 In the plot of lcarat vs. lprice, there are some bright vertical strips. What do they represent? The carats of the diamonds bunch at key values like 0.5 carats and 1 carat. This bunching shows up as bright vertical stripes when using geom_hex(). Problem 2 If log(price) = a_0 + a_1 * log(carat), what does that say about the relationship between price and carat? A one log-unit increase in carat increases log-price by a_1. A zero-carat diamond has log-price of a_0. Problem 3 Extract the diamonds that have very high and very low residuals. Is there anything unusual about these diamonds? Are the particularly bad or good, or do you think these are pricing errors? Most of the errors are predictions that are lower than the sale price. There could be some unobserved characteristic that explains why these diamonds are more valuable than the model suggests. diamonds2 &lt;- diamonds %&gt;% filter(carat &lt;= 2.5) %&gt;% mutate(lprice = log2(price), lcarat = log2(carat)) mod_diamond2 &lt;- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2) diamonds2 &lt;- diamonds2 %&gt;% add_residuals(mod_diamond2, &quot;lresid2&quot;) diamonds2 %&gt;% filter(abs(lresid2) &gt; 1) %&gt;% add_predictions(mod_diamond2) %&gt;% mutate(pred = round(2 ^ pred)) %&gt;% select(price, pred, carat:table, x:z) %&gt;% arrange(price) %&gt;% mutate(error = ifelse(price &gt; pred, &quot;too low&quot;, &quot;too high&quot;)) ## # A tibble: 16 x 12 ## price pred carat cut color clarity depth table x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1013 264 0.25 Fair F SI2 54.4 64 4.3 4.23 2.32 ## 2 1186 284 0.25 Premium G SI2 59 60 5.33 5.28 3.12 ## 3 1186 284 0.25 Premium G SI2 58.8 60 5.33 5.28 3.12 ## 4 1262 2644 1.03 Fair E I1 78.2 54 5.72 5.59 4.42 ## 5 1415 639 0.35 Fair G VS2 65.9 54 5.57 5.53 3.66 ## 6 1415 639 0.35 Fair G VS2 65.9 54 5.57 5.53 3.66 ## 7 1715 576 0.32 Fair F VS2 59.6 60 4.42 4.34 2.61 ## 8 1776 412 0.290 Fair F SI1 55.8 60 4.48 4.41 2.48 ## 9 2160 314 0.34 Fair F I1 55.8 62 4.72 4.6 2.6 ## 10 2366 774 0.3 Very Good D VVS2 60.6 58 4.33 4.35 2.63 ## 11 3360 1373 0.51 Premium F SI1 62.7 62 5.09 4.96 3.15 ## 12 3807 1540 0.61 Good F SI2 62.5 65 5.36 5.29 3.33 ## 13 3920 1705 0.51 Fair F VVS2 65.4 60 4.98 4.9 3.23 ## 14 4368 1705 0.51 Fair F VVS2 60.7 66 5.21 5.11 3.13 ## 15 10011 4048 1.01 Fair D SI2 64.6 58 6.25 6.2 4.02 ## 16 10470 23622 2.46 Premium E SI2 59.7 59 8.82 8.76 5.25 ## # ... with 1 more variable: error &lt;chr&gt; Problem 4 Does the final model, mod_diamonds2, do a good job of predicting diamond prices? Would you trust it to tell you how much to spend if you were buying a diamond? mod_diamonds2 was estimated on a large data set with substantial variation and does a good job capturing the variance in the data with a relatively parsimonious specification. The residuals from this model are heteroskedasticitic which suggests there isn’t a significant confounding variable missing from the model. I would trust it to to get me in the ball-park but wouldn’t trust it the dollar. 24.3 - What affects the number of daily flights? Problem 1 Use your Google sleuthing skills to brainstorm why there were fewer than expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the same explanation.) How would these days generalise to another year? January 20th was the Saturday before Martin Luther King Jr. day. May 26th was the Saturday before Memorial Day. September 1st was the Saturday before Labor Day. This could be generalized to other years as the Saturdays before MLK Jr. day, Memorial Day, and Labor Day. Problem 2 What do the three days with high positive residuals represent? How would these days generalise to another year? November 30th was the Saturday after Thanksgiving, December 1st was the Sunday after Thanksgiving, and December 28th was the Saturday after Christmas. These could be generalized to another year as the Saturday and Sunday after Thanksgiving and the Saturday after Christmas. Problem 3 Create a new variable that splits the wday variable into terms, but only for Saturdays, i.e. it should have Thurs, Fri, but Sat-summer, Sat-spring, Sat-fall. How does this model compare with the model with every combination of wday and term? The new model is less accurate than the old model in the spring and summer. The old model has 20 predictors and the new model has 8 predictors. library(nycflights13) library(lubridate) term &lt;- function(date) { cut(date, breaks = ymd(20130101, 20130605, 20130825, 20140101), labels = c(&quot;spring&quot;, &quot;summer&quot;, &quot;fall&quot;) ) } daily &lt;- flights %&gt;% mutate(date = make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(n = n()) %&gt;% mutate(wday = wday(date, label = TRUE)) %&gt;% mutate(term = term(date)) %&gt;% mutate(date_combined = case_when( wday == &quot;Sat&quot; &amp; term == &quot;spring&quot; ~ &quot;Sat-spring&quot;, wday == &quot;Sat&quot; &amp; term == &quot;summer&quot; ~ &quot;Sat-summer&quot;, wday == &quot;Sat&quot; &amp; term == &quot;fall&quot; ~ &quot;Sat-fall&quot;, TRUE ~ as.character(wday) )) %&gt;% mutate(date_combined = as.factor(date_combined)) old_model &lt;- lm(n ~ wday * term, data = daily) new_model &lt;- lm(n ~ date_combined, data = daily) daily %&gt;% gather_residuals(old_model = old_model, new_model = new_model) %&gt;% ggplot(aes(date, resid, colour = model)) + geom_line(alpha = 0.75) Problem 4 Create a new wday variable that combines the day of week, term (for Saturdays), and public holidays. What do the residuals of that model look like? "]
]
